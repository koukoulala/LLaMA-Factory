nohup: ignoring input
[2024-05-26 10:33:16,391] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
05/26/2024 10:33:17 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2106] 2024-05-26 10:33:17,802 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2106] 2024-05-26 10:33:17,802 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2106] 2024-05-26 10:33:17,802 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2106] 2024-05-26 10:33:17,802 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2106] 2024-05-26 10:33:17,802 >> loading file tokenizer_config.json
05/26/2024 10:33:17 - INFO - llamafactory.data.template - Add pad token: </s>
05/26/2024 10:33:17 - INFO - llamafactory.data.loader - Loading dataset AssetGeneration/test.json...
Converting format of dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 47758.39 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 28401.11 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 313/5000 [00:00<00:03, 1373.94 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 1878/5000 [00:00<00:00, 6792.33 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 3752/5000 [00:00<00:00, 10991.29 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 8478.58 examples/s] 
[INFO|configuration_utils.py:731] 2024-05-26 10:33:19,325 >> loading configuration file /data/xiaoyukou/alignment-handbook/ckpts/Mistral-7B-Instruct-v0.2/config.json
[INFO|configuration_utils.py:796] 2024-05-26 10:33:19,326 >> Model config MistralConfig {
  "_name_or_path": "/data/xiaoyukou/alignment-handbook/ckpts/Mistral-7B-Instruct-v0.2",
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

input_ids:
[1, 28705, 733, 16289, 28793, 5919, 8270, 28705, 28770, 1964, 9655, 1081, 297, 4300, 3842, 28725, 2818, 356, 272, 2296, 1871, 28747, 13, 13, 17500, 5140, 28747, 4449, 1508, 2849, 28723, 20243, 21819, 28723, 675, 28748, 1237, 270, 411, 28748, 3253, 28733, 28708, 469, 262, 28748, 20243, 21819, 28733, 28713, 1881, 21387, 28733, 28719, 1109, 3611, 28705, 13, 12075, 28747, 7132, 21819, 28723, 675, 28705, 13, 9633, 28747, 20214, 1939, 20370, 567, 320, 25655, 1939, 23208, 415, 17244, 28705, 13, 22971, 288, 4068, 28747, 28705, 842, 23208, 19725, 560, 17870, 28725, 7826, 342, 17133, 21819, 3658, 21387, 351, 1109, 3611, 28745, 28705, 842, 17133, 21819, 3658, 21387, 351, 1109, 3611, 28745, 28705, 842, 8610, 4593, 842, 524, 969, 11857, 367, 5904, 28705, 28781, 842, 384, 1802, 28747, 2914, 6005, 842, 12185, 272, 4041, 842, 2236, 357, 3239, 842, 11357, 28712, 3494, 842, 7481, 393, 497, 365, 291, 13917, 842, 7409, 1471, 2047, 28747, 2387, 7481, 842, 22404, 3239, 3663, 1190, 842, 12623, 18748, 842, 5311, 433, 6353, 842, 27970, 15573, 842, 451, 15016, 24556, 28745, 28705, 842, 8784, 842, 320, 1139, 842, 7842, 842, 542, 1726, 842, 401, 373, 842, 10586, 842, 7057, 842, 3217, 842, 3301, 298, 11933, 3231, 842, 27793, 28705, 28740, 15384, 28705, 28770, 28781, 1187, 842, 1343, 28705, 13, 15962, 13063, 28747, 1444, 28705, 28740, 28734, 298, 28705, 28750, 28734, 6128, 28723, 28705, 13, 733, 28748, 16289, 28793]
inputs:
<s>  [INST] Please generate 3 Ad Headline in English language, based on the following information:

FinalUrl: https://www.cinemark.com/theatres/tx-austin/cinemark-southpark-meadows 
Domain: cinemark.com 
Category: Entertainment -- Events & Tickets -- Movie Theaters 
LandingPage:  . Movie Theater In Austin, Texas | Cinemark Southpark Meadows;  . Cinemark Southpark Meadows;  . Showtimes . Kung Fu Panda 4 . Dune: Part Two . Arthur the King . Imaginary . Cabrini . Love Lies Bleeding . Bob Marley: One Love . Ordinary Angels . Standard Format . Madame Web . Poor Things . Oppenheimer;  . Today . Tues . Wed . Thurs . Fri . Sat . Sun . Mon . Add to Watch List . PG 1 hr 34 min . De 
CharacterLimit: between 10 to 20 characters. 
 [/INST]
05/26/2024 10:33:19 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.
[INFO|modeling_utils.py:3460] 2024-05-26 10:33:19,342 >> loading weights file /data/xiaoyukou/alignment-handbook/ckpts/Mistral-7B-Instruct-v0.2/model.safetensors.index.json
[INFO|modeling_utils.py:1508] 2024-05-26 10:33:19,342 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:962] 2024-05-26 10:33:19,343 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.52s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.19it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]
[INFO|modeling_utils.py:4269] 2024-05-26 10:33:22,362 >> All model checkpoint weights were used when initializing MistralForCausalLM.

[INFO|modeling_utils.py:4277] 2024-05-26 10:33:22,362 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /data/xiaoyukou/alignment-handbook/ckpts/Mistral-7B-Instruct-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.
[INFO|configuration_utils.py:915] 2024-05-26 10:33:22,364 >> loading configuration file /data/xiaoyukou/alignment-handbook/ckpts/Mistral-7B-Instruct-v0.2/generation_config.json
[INFO|configuration_utils.py:962] 2024-05-26 10:33:22,364 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

05/26/2024 10:33:22 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.
05/26/2024 10:33:22 - INFO - llamafactory.model.adapter - Adapter is not found at evaluation, load the base model.
05/26/2024 10:33:22 - INFO - llamafactory.model.loader - all params: 7241732096
05/26/2024 10:33:22 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.
[INFO|trainer.py:3719] 2024-05-26 10:33:22,465 >> ***** Running Prediction *****
[INFO|trainer.py:3721] 2024-05-26 10:33:22,465 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-26 10:33:22,465 >>   Batch size = 28
  0%|          | 0/179 [00:00<?, ?it/s]  1%|          | 2/179 [00:30<44:44, 15.16s/it]  2%|▏         | 3/179 [00:59<1:01:08, 20.84s/it]  2%|▏         | 4/179 [01:40<1:23:20, 28.57s/it]  3%|▎         | 5/179 [02:12<1:26:16, 29.75s/it]  3%|▎         | 6/179 [02:35<1:19:04, 27.43s/it]  4%|▍         | 7/179 [03:19<1:33:33, 32.64s/it]  4%|▍         | 8/179 [03:42<1:24:39, 29.70s/it]  5%|▌         | 9/179 [04:10<1:22:46, 29.21s/it]  6%|▌         | 10/179 [04:35<1:18:37, 27.91s/it]  6%|▌         | 11/179 [05:24<1:35:47, 34.21s/it]  7%|▋         | 12/179 [06:12<1:47:24, 38.59s/it]  7%|▋         | 13/179 [06:49<1:45:34, 38.16s/it]  8%|▊         | 14/179 [07:22<1:40:10, 36.43s/it]  8%|▊         | 15/179 [07:46<1:29:42, 32.82s/it]  9%|▉         | 16/179 [08:36<1:43:01, 37.92s/it]  9%|▉         | 17/179 [09:14<1:42:15, 37.88s/it] 10%|█         | 18/179 [09:36<1:29:19, 33.29s/it] 11%|█         | 19/179 [10:03<1:23:37, 31.36s/it] 11%|█         | 20/179 [10:28<1:17:52, 29.38s/it] 12%|█▏        | 21/179 [11:09<1:26:50, 32.98s/it] 12%|█▏        | 22/179 [12:51<2:20:02, 53.52s/it] 13%|█▎        | 23/179 [13:11<1:53:21, 43.60s/it] 13%|█▎        | 24/179 [13:39<1:40:19, 38.84s/it] 14%|█▍        | 25/179 [14:16<1:38:03, 38.20s/it] 15%|█▍        | 26/179 [14:56<1:38:46, 38.73s/it] 15%|█▌        | 27/179 [15:20<1:26:52, 34.29s/it] 16%|█▌        | 28/179 [15:41<1:16:48, 30.52s/it] 16%|█▌        | 29/179 [16:18<1:20:45, 32.30s/it] 17%|█▋        | 30/179 [17:01<1:28:25, 35.61s/it] 17%|█▋        | 31/179 [17:47<1:35:31, 38.73s/it] 18%|█▊        | 32/179 [18:20<1:30:36, 36.98s/it] 18%|█▊        | 33/179 [19:04<1:35:05, 39.08s/it] 19%|█▉        | 34/179 [20:00<1:46:42, 44.16s/it] 20%|█▉        | 35/179 [20:21<1:29:25, 37.26s/it] 20%|██        | 36/179 [20:46<1:20:12, 33.65s/it] 21%|██        | 37/179 [21:14<1:15:02, 31.71s/it] 21%|██        | 38/179 [21:47<1:15:36, 32.17s/it] 22%|██▏       | 39/179 [22:10<1:09:03, 29.60s/it] 22%|██▏       | 40/179 [22:55<1:19:04, 34.13s/it] 23%|██▎       | 41/179 [23:17<1:10:09, 30.51s/it] 23%|██▎       | 42/179 [23:36<1:02:00, 27.15s/it] 24%|██▍       | 43/179 [23:57<56:52, 25.09s/it]   25%|██▍       | 44/179 [24:20<55:03, 24.47s/it] 25%|██▌       | 45/179 [24:45<55:06, 24.68s/it] 26%|██▌       | 46/179 [25:10<54:44, 24.70s/it] 26%|██▋       | 47/179 [26:04<1:13:48, 33.55s/it] 27%|██▋       | 48/179 [26:37<1:13:03, 33.46s/it] 27%|██▋       | 49/179 [27:27<1:23:23, 38.49s/it] 28%|██▊       | 50/179 [28:05<1:22:24, 38.33s/it] 28%|██▊       | 51/179 [28:27<1:11:24, 33.47s/it] 29%|██▉       | 52/179 [28:50<1:03:41, 30.09s/it] 30%|██▉       | 53/179 [29:15<1:00:09, 28.65s/it] 30%|███       | 54/179 [30:00<1:09:39, 33.44s/it] 31%|███       | 55/179 [30:48<1:18:19, 37.90s/it] 31%|███▏      | 56/179 [31:27<1:18:27, 38.27s/it] 32%|███▏      | 57/179 [31:59<1:14:12, 36.49s/it] 32%|███▏      | 58/179 [32:38<1:14:40, 37.03s/it] 33%|███▎      | 59/179 [33:13<1:12:54, 36.46s/it] 34%|███▎      | 60/179 [33:41<1:07:26, 34.00s/it] 34%|███▍      | 61/179 [34:09<1:03:24, 32.24s/it] 35%|███▍      | 62/179 [34:33<57:54, 29.70s/it]   35%|███▌      | 63/179 [35:09<1:01:03, 31.58s/it] 36%|███▌      | 64/179 [35:34<56:57, 29.72s/it]   36%|███▋      | 65/179 [36:03<56:06, 29.53s/it] 37%|███▋      | 66/179 [36:48<1:04:08, 34.06s/it] 37%|███▋      | 67/179 [37:20<1:02:30, 33.48s/it] 38%|███▊      | 68/179 [37:40<54:26, 29.43s/it]   39%|███▊      | 69/179 [38:00<48:46, 26.60s/it] 39%|███▉      | 70/179 [38:28<49:11, 27.08s/it] 40%|███▉      | 71/179 [38:57<49:39, 27.59s/it] 40%|████      | 72/179 [39:12<42:22, 23.76s/it] 41%|████      | 73/179 [39:47<47:52, 27.10s/it] 41%|████▏     | 74/179 [40:15<48:03, 27.47s/it] 42%|████▏     | 75/179 [40:45<48:51, 28.19s/it] 42%|████▏     | 76/179 [41:04<43:43, 25.47s/it] 43%|████▎     | 77/179 [41:42<49:41, 29.23s/it] 44%|████▎     | 78/179 [42:12<49:39, 29.50s/it] 44%|████▍     | 79/179 [43:11<1:03:42, 38.22s/it] 45%|████▍     | 80/179 [43:58<1:07:37, 40.99s/it] 45%|████▌     | 81/179 [44:28<1:01:29, 37.65s/it] 46%|████▌     | 82/179 [45:13<1:04:19, 39.79s/it] 46%|████▋     | 83/179 [45:44<59:36, 37.26s/it]   47%|████▋     | 84/179 [46:32<1:04:08, 40.51s/it] 47%|████▋     | 85/179 [47:07<1:00:43, 38.76s/it] 48%|████▊     | 86/179 [48:58<1:33:49, 60.53s/it] 49%|████▊     | 87/179 [49:18<1:14:08, 48.35s/it] 49%|████▉     | 88/179 [49:59<1:09:44, 45.98s/it] 50%|████▉     | 89/179 [50:27<1:01:01, 40.68s/it] 50%|█████     | 90/179 [51:11<1:01:48, 41.67s/it] 51%|█████     | 91/179 [51:30<51:14, 34.94s/it]   51%|█████▏    | 92/179 [51:49<43:31, 30.02s/it] 52%|█████▏    | 93/179 [52:13<40:45, 28.43s/it] 53%|█████▎    | 94/179 [53:57<1:12:02, 50.85s/it] 53%|█████▎    | 95/179 [54:50<1:12:25, 51.73s/it] 54%|█████▎    | 96/179 [55:33<1:07:46, 49.00s/it] 54%|█████▍    | 97/179 [56:15<1:04:04, 46.88s/it] 55%|█████▍    | 98/179 [56:49<58:16, 43.16s/it]   55%|█████▌    | 99/179 [57:20<52:18, 39.23s/it] 56%|█████▌    | 100/179 [57:45<46:18, 35.17s/it] 56%|█████▋    | 101/179 [58:08<41:03, 31.58s/it] 57%|█████▋    | 102/179 [58:29<36:07, 28.15s/it] 58%|█████▊    | 103/179 [59:14<42:09, 33.29s/it] 58%|█████▊    | 104/179 [59:52<43:23, 34.71s/it] 59%|█████▊    | 105/179 [1:00:29<43:51, 35.56s/it] 59%|█████▉    | 106/179 [1:02:11<1:07:24, 55.40s/it] 60%|█████▉    | 107/179 [1:02:39<56:24, 47.01s/it]   60%|██████    | 108/179 [1:03:25<55:33, 46.96s/it] 61%|██████    | 109/179 [1:03:48<46:17, 39.67s/it] 61%|██████▏   | 110/179 [1:04:23<44:06, 38.35s/it] 62%|██████▏   | 111/179 [1:05:01<43:13, 38.13s/it] 63%|██████▎   | 112/179 [1:05:35<41:14, 36.94s/it] 63%|██████▎   | 113/179 [1:06:07<38:51, 35.32s/it] 64%|██████▎   | 114/179 [1:06:55<42:29, 39.23s/it] 64%|██████▍   | 115/179 [1:07:36<42:23, 39.74s/it] 65%|██████▍   | 116/179 [1:08:15<41:30, 39.53s/it] 65%|██████▌   | 117/179 [1:09:24<50:03, 48.44s/it] 66%|██████▌   | 118/179 [1:11:11<1:06:57, 65.86s/it] 66%|██████▋   | 119/179 [1:11:35<53:18, 53.31s/it]   67%|██████▋   | 120/179 [1:11:58<43:31, 44.27s/it] 68%|██████▊   | 121/179 [1:12:24<37:25, 38.72s/it] 68%|██████▊   | 122/179 [1:12:54<34:28, 36.29s/it] 69%|██████▊   | 123/179 [1:13:36<35:20, 37.86s/it] 69%|██████▉   | 124/179 [1:14:13<34:24, 37.54s/it] 70%|██████▉   | 125/179 [1:14:37<30:11, 33.54s/it] 70%|███████   | 126/179 [1:15:20<32:12, 36.47s/it] 71%|███████   | 127/179 [1:15:56<31:33, 36.42s/it] 72%|███████▏  | 128/179 [1:16:29<30:00, 35.31s/it] 72%|███████▏  | 129/179 [1:17:13<31:39, 38.00s/it] 73%|███████▎  | 130/179 [1:17:54<31:36, 38.71s/it] 73%|███████▎  | 131/179 [1:18:34<31:26, 39.29s/it] 74%|███████▎  | 132/179 [1:18:56<26:29, 33.81s/it] 74%|███████▍  | 133/179 [1:19:40<28:18, 36.92s/it] 75%|███████▍  | 134/179 [1:20:12<26:37, 35.49s/it] 75%|███████▌  | 135/179 [1:20:52<26:59, 36.81s/it] 76%|███████▌  | 136/179 [1:21:15<23:24, 32.66s/it] 77%|███████▋  | 137/179 [1:21:50<23:24, 33.45s/it] 77%|███████▋  | 138/179 [1:22:16<21:17, 31.16s/it] 78%|███████▊  | 139/179 [1:22:46<20:31, 30.78s/it] 78%|███████▊  | 140/179 [1:23:19<20:24, 31.40s/it] 79%|███████▉  | 141/179 [1:23:45<18:59, 30.00s/it] 79%|███████▉  | 142/179 [1:24:06<16:51, 27.33s/it] 80%|███████▉  | 143/179 [1:24:33<16:18, 27.18s/it] 80%|████████  | 144/179 [1:24:52<14:27, 24.77s/it] 81%|████████  | 145/179 [1:25:15<13:41, 24.17s/it] 82%|████████▏ | 146/179 [1:25:48<14:42, 26.75s/it] 82%|████████▏ | 147/179 [1:26:13<13:57, 26.16s/it] 83%|████████▎ | 148/179 [1:26:41<13:48, 26.73s/it] 83%|████████▎ | 149/179 [1:27:15<14:28, 28.94s/it] 84%|████████▍ | 150/179 [1:27:40<13:29, 27.90s/it] 84%|████████▍ | 151/179 [1:28:10<13:17, 28.49s/it] 85%|████████▍ | 152/179 [1:28:40<13:01, 28.93s/it] 85%|████████▌ | 153/179 [1:29:08<12:20, 28.49s/it] 86%|████████▌ | 154/179 [1:29:28<10:48, 25.94s/it] 87%|████████▋ | 155/179 [1:29:58<10:56, 27.34s/it] 87%|████████▋ | 156/179 [1:30:16<09:22, 24.45s/it] 88%|████████▊ | 157/179 [1:30:40<08:56, 24.38s/it] 88%|████████▊ | 158/179 [1:31:05<08:33, 24.43s/it] 89%|████████▉ | 159/179 [1:31:36<08:52, 26.63s/it] 89%|████████▉ | 160/179 [1:31:54<07:34, 23.93s/it] 90%|████████▉ | 161/179 [1:32:29<08:12, 27.35s/it] 91%|█████████ | 162/179 [1:33:57<12:51, 45.36s/it] 91%|█████████ | 163/179 [1:34:25<10:45, 40.36s/it] 92%|█████████▏| 164/179 [1:34:53<09:08, 36.58s/it] 92%|█████████▏| 165/179 [1:35:24<08:09, 34.97s/it] 93%|█████████▎| 166/179 [1:35:59<07:34, 34.95s/it] 93%|█████████▎| 167/179 [1:36:32<06:50, 34.17s/it] 94%|█████████▍| 168/179 [1:37:39<08:05, 44.17s/it] 94%|█████████▍| 169/179 [1:38:35<07:57, 47.74s/it] 95%|█████████▍| 170/179 [1:40:07<09:08, 60.98s/it] 96%|█████████▌| 171/179 [1:40:45<07:11, 53.89s/it] 96%|█████████▌| 172/179 [1:41:18<05:33, 47.66s/it] 97%|█████████▋| 173/179 [1:41:48<04:15, 42.51s/it] 97%|█████████▋| 174/179 [1:42:24<03:22, 40.53s/it] 98%|█████████▊| 175/179 [1:42:58<02:33, 38.46s/it] 98%|█████████▊| 176/179 [1:43:34<01:53, 37.80s/it] 99%|█████████▉| 177/179 [1:44:01<01:08, 34.48s/it] 99%|█████████▉| 178/179 [1:45:07<00:43, 43.94s/it]100%|██████████| 179/179 [1:45:21<00:00, 35.20s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.500 seconds.
Prefix dict has been built successfully.
100%|██████████| 179/179 [1:45:40<00:00, 35.42s/it]
***** predict metrics *****
  predict_bleu-4             =    16.0757
  predict_rouge-1            =    18.2976
  predict_rouge-2            =     3.7461
  predict_rouge-l            =     13.138
  predict_runtime            = 1:46:10.20
  predict_samples_per_second =      0.785
  predict_steps_per_second   =      0.028
05/26/2024 12:19:32 - INFO - llamafactory.train.sft.trainer - Saving prediction results to saves/mistral/Instruct-v0.2/predict/generated_predictions.jsonl
