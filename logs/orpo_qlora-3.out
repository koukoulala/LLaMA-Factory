nohup: ignoring input
[2024-07-22 01:51:25,972] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
07/22/2024 01:51:27 - WARNING - llamafactory.hparams.parser - Evaluating model in 4/8-bit mode may cause lower scores.
07/22/2024 01:51:27 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2106] 2024-07-22 01:51:27,504 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2106] 2024-07-22 01:51:27,504 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2106] 2024-07-22 01:51:27,504 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2106] 2024-07-22 01:51:27,504 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2106] 2024-07-22 01:51:27,504 >> loading file tokenizer_config.json
07/22/2024 01:51:27 - INFO - llamafactory.data.template - Add pad token: </s>
07/22/2024 01:51:27 - INFO - llamafactory.data.loader - Loading dataset AssetGeneration/test.json...
Converting format of dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 29059.87 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 313/5000 [00:00<00:03, 1341.10 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 2191/5000 [00:00<00:00, 7809.22 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 4064/5000 [00:00<00:00, 11579.67 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 8728.50 examples/s] 
[INFO|configuration_utils.py:731] 2024-07-22 01:51:29,131 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/config.json
[INFO|configuration_utils.py:796] 2024-07-22 01:51:29,132 >> Model config MistralConfig {
  "_name_or_path": "/data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2",
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

input_ids:
[1, 28705, 733, 16289, 28793, 5919, 8270, 28705, 28770, 1964, 10220, 297, 4300, 3842, 28725, 2818, 356, 272, 2296, 1871, 28747, 13, 13, 17500, 5140, 28747, 4449, 1508, 2849, 28723, 3423, 1466, 16210, 404, 28723, 675, 28748, 28726, 7041, 28733, 2031, 288, 28748, 8830, 2951, 28733, 28726, 24681, 28723, 2842, 28804, 3457, 28770, 28746, 28740, 28734, 28734, 28784, 28782, 28774, 28800, 3457, 28782, 28746, 28750, 28782, 28740, 28787, 28782, 28800, 3457, 28770, 28770, 28770, 28746, 28750, 28782, 28740, 28774, 28784, 28800, 3457, 28770, 28770, 28784, 28746, 28750, 28782, 28740, 28787, 28750, 28800, 3457, 28770, 28770, 28787, 28746, 28750, 28782, 28740, 28787, 28770, 28800, 3457, 28770, 28770, 28783, 28746, 28750, 28782, 28740, 28787, 28781, 28800, 3457, 28770, 28781, 28783, 28746, 28770, 28782, 28782, 28783, 28740, 28800, 5646, 28730, 313, 28746, 28781, 28783, 28781, 28800, 23114, 28730, 9974, 28746, 11155, 28705, 13, 12075, 28747, 1679, 1466, 16210, 404, 28723, 675, 28705, 13, 9633, 28747, 365, 28750, 28743, 8074, 1939, 12860, 8074, 1939, 13281, 288, 567, 26999, 28705, 13, 22971, 288, 4068, 28747, 28705, 842, 12670, 2951, 365, 24681, 387, 7973, 7809, 1962, 365, 7041, 13281, 288, 342, 8580, 12422, 28765, 346, 404, 28745, 28705, 842, 7497, 27074, 28735, 842, 16123, 28790, 22285, 842, 12670, 2951, 365, 24681, 842, 13341, 13281, 19641, 842, 21013, 25181, 842, 12670, 2951, 365, 24681, 28747, 12948, 1590, 4922, 2956, 297, 4922, 816, 1223, 842, 21815, 272, 24443, 13909, 12670, 2951, 9315, 28713, 304, 365, 24681, 842, 8420, 522, 12670, 2951, 15210, 354, 1756, 11019, 442, 4655, 9405, 5938, 842, 382, 6185, 16970, 18945, 842, 26406, 354, 8648, 288, 16782, 495, 12670, 2951, 365, 24681, 842, 2483, 680, 10636, 28747, 842, 995, 993, 835, 737, 28747, 842, 28705, 13, 15962, 13063, 28747, 1444, 28705, 28783, 28781, 298, 28705, 28774, 28734, 6128, 28723, 28705, 13, 733, 28748, 16289, 28793]
inputs:
<s>  [INST] Please generate 3 Ad Description in English language, based on the following information:

FinalUrl: https://www.nextdayflyers.com/banner-printing/vinyl-banners.php?attr3=100659&attr5=25175&attr333=25196&attr336=25172&attr337=25173&attr338=25174&attr348=35581&product_id=484&calc_variant=LIST 
Domain: nextdayflyers.com 
Category: B2C Services -- Personal Services -- Printing & Publishing 
LandingPage:  . Vinyl Banners - Custom Premium Banner Printing | NextDayFlyers;  . PRODUCTS . SERVICES . Vinyl Banners . Select Print Options . Overall Rating . Vinyl Banners: Promote Anywhere in Any Weather . Choose the Perfect Size Vinyl Signs and Banners . Durable Vinyl Material for Indoor or Outdoor Use . Hanging Made Easy . Tips for Designing Effective Vinyl Banners . Get more tips: . You may also like: . 
CharacterLimit: between 84 to 90 characters. 
 [/INST]
07/22/2024 01:51:29 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.
07/22/2024 01:51:29 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.
[INFO|modeling_utils.py:3460] 2024-07-22 01:51:29,164 >> loading weights file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/model.safetensors.index.json
[INFO|modeling_utils.py:1508] 2024-07-22 01:51:29,164 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:962] 2024-07-22 01:51:29,165 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.21it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
[INFO|modeling_utils.py:4269] 2024-07-22 01:51:31,735 >> All model checkpoint weights were used when initializing MistralForCausalLM.

[INFO|modeling_utils.py:4277] 2024-07-22 01:51:31,735 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.
[INFO|configuration_utils.py:915] 2024-07-22 01:51:31,738 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/generation_config.json
[INFO|configuration_utils.py:962] 2024-07-22 01:51:31,738 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

07/22/2024 01:51:31 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.
07/22/2024 01:51:31 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.
07/22/2024 01:51:31 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA
07/22/2024 01:51:32 - INFO - llamafactory.model.adapter - Loaded adapter(s): saves/mistral/orpo_qlora_continue_3
07/22/2024 01:51:32 - INFO - llamafactory.model.loader - all params: 7262703616
[INFO|trainer.py:3719] 2024-07-22 01:51:32,266 >> ***** Running Prediction *****
[INFO|trainer.py:3721] 2024-07-22 01:51:32,267 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-07-22 01:51:32,267 >>   Batch size = 20
  0%|          | 0/250 [00:00<?, ?it/s]  1%|          | 2/250 [02:10<4:30:04, 65.34s/it]  1%|          | 3/250 [02:36<3:21:18, 48.90s/it]  2%|▏         | 4/250 [02:49<2:25:27, 35.48s/it]  2%|▏         | 5/250 [03:11<2:06:00, 30.86s/it]  2%|▏         | 6/250 [03:28<1:46:58, 26.31s/it]  3%|▎         | 7/250 [03:45<1:34:11, 23.26s/it]  3%|▎         | 8/250 [03:58<1:20:41, 20.01s/it]  4%|▎         | 9/250 [04:33<1:38:59, 24.64s/it]  4%|▍         | 10/250 [04:48<1:26:47, 21.70s/it]  4%|▍         | 11/250 [05:08<1:24:47, 21.29s/it]  5%|▍         | 12/250 [05:30<1:25:07, 21.46s/it]  5%|▌         | 13/250 [05:45<1:16:55, 19.48s/it]  6%|▌         | 14/250 [05:58<1:08:26, 17.40s/it]  6%|▌         | 15/250 [07:56<3:07:28, 47.87s/it]  6%|▋         | 16/250 [08:19<2:37:17, 40.33s/it]  7%|▋         | 17/250 [08:37<2:10:26, 33.59s/it]  7%|▋         | 18/250 [10:32<3:44:46, 58.13s/it]  8%|▊         | 19/250 [12:29<4:51:00, 75.58s/it]  8%|▊         | 20/250 [12:59<3:57:31, 61.97s/it]  8%|▊         | 21/250 [13:23<3:13:22, 50.67s/it]  9%|▉         | 22/250 [13:44<2:38:08, 41.62s/it]  9%|▉         | 23/250 [14:07<2:16:22, 36.05s/it] 10%|▉         | 24/250 [14:26<1:56:26, 30.91s/it] 10%|█         | 25/250 [14:43<1:40:48, 26.88s/it] 10%|█         | 26/250 [15:02<1:31:05, 24.40s/it] 11%|█         | 27/250 [15:25<1:29:35, 24.11s/it] 11%|█         | 28/250 [15:47<1:26:23, 23.35s/it] 12%|█▏        | 29/250 [16:13<1:29:11, 24.21s/it] 12%|█▏        | 30/250 [16:33<1:24:34, 23.07s/it] 12%|█▏        | 31/250 [18:29<3:05:56, 50.94s/it] 13%|█▎        | 32/250 [18:43<2:24:03, 39.65s/it] 13%|█▎        | 33/250 [19:02<2:01:49, 33.69s/it] 14%|█▎        | 34/250 [19:21<1:45:08, 29.21s/it] 14%|█▍        | 35/250 [19:43<1:37:03, 27.09s/it] 14%|█▍        | 36/250 [21:38<3:10:42, 53.47s/it] 15%|█▍        | 37/250 [22:01<2:37:22, 44.33s/it] 15%|█▌        | 38/250 [22:24<2:13:10, 37.69s/it] 16%|█▌        | 39/250 [22:43<1:53:37, 32.31s/it] 16%|█▌        | 40/250 [23:17<1:54:09, 32.62s/it] 16%|█▋        | 41/250 [23:41<1:44:54, 30.12s/it] 17%|█▋        | 42/250 [24:07<1:40:03, 28.86s/it] 17%|█▋        | 43/250 [24:31<1:35:04, 27.56s/it] 18%|█▊        | 44/250 [24:49<1:24:23, 24.58s/it] 18%|█▊        | 45/250 [25:10<1:20:25, 23.54s/it] 18%|█▊        | 46/250 [25:39<1:25:56, 25.28s/it] 19%|█▉        | 47/250 [27:46<3:08:12, 55.63s/it] 19%|█▉        | 48/250 [28:09<2:34:15, 45.82s/it] 20%|█▉        | 49/250 [28:21<2:00:03, 35.84s/it] 20%|██        | 50/250 [28:42<1:44:24, 31.32s/it] 20%|██        | 51/250 [29:10<1:40:13, 30.22s/it] 21%|██        | 52/250 [29:26<1:25:56, 26.04s/it] 21%|██        | 53/250 [29:54<1:27:47, 26.74s/it] 22%|██▏       | 54/250 [30:10<1:16:15, 23.34s/it] 22%|██▏       | 55/250 [30:35<1:17:30, 23.85s/it] 22%|██▏       | 56/250 [32:41<2:55:48, 54.37s/it] 23%|██▎       | 57/250 [33:01<2:22:32, 44.32s/it] 23%|██▎       | 58/250 [33:22<1:59:25, 37.32s/it] 24%|██▎       | 59/250 [33:48<1:47:26, 33.75s/it] 24%|██▍       | 60/250 [34:17<1:42:24, 32.34s/it] 24%|██▍       | 61/250 [34:35<1:28:04, 27.96s/it] 25%|██▍       | 62/250 [34:59<1:24:16, 26.89s/it] 25%|██▌       | 63/250 [35:15<1:13:26, 23.56s/it] 26%|██▌       | 64/250 [35:43<1:17:31, 25.01s/it] 26%|██▌       | 65/250 [35:59<1:08:55, 22.36s/it] 26%|██▋       | 66/250 [36:13<1:00:53, 19.85s/it] 27%|██▋       | 67/250 [38:07<2:26:41, 48.10s/it] 27%|██▋       | 68/250 [38:27<2:00:18, 39.66s/it] 28%|██▊       | 69/250 [38:50<1:44:07, 34.52s/it] 28%|██▊       | 70/250 [39:10<1:30:18, 30.10s/it] 28%|██▊       | 71/250 [39:28<1:19:20, 26.60s/it] 29%|██▉       | 72/250 [39:51<1:15:22, 25.41s/it] 29%|██▉       | 73/250 [40:16<1:14:36, 25.29s/it] 30%|██▉       | 74/250 [40:38<1:11:58, 24.54s/it] 30%|███       | 75/250 [40:57<1:06:37, 22.84s/it] 30%|███       | 76/250 [43:06<2:38:22, 54.61s/it] 31%|███       | 77/250 [45:14<3:41:04, 76.67s/it] 31%|███       | 78/250 [45:35<2:51:26, 59.81s/it] 32%|███▏      | 79/250 [45:55<2:17:01, 48.08s/it] 32%|███▏      | 80/250 [46:12<1:49:46, 38.74s/it] 32%|███▏      | 81/250 [46:29<1:30:21, 32.08s/it] 33%|███▎      | 82/250 [46:46<1:17:16, 27.60s/it] 33%|███▎      | 83/250 [47:13<1:16:20, 27.43s/it] 34%|███▎      | 84/250 [47:40<1:15:11, 27.18s/it] 34%|███▍      | 85/250 [48:04<1:12:19, 26.30s/it] 34%|███▍      | 86/250 [50:05<2:29:44, 54.78s/it] 35%|███▍      | 87/250 [50:19<1:55:28, 42.51s/it] 35%|███▌      | 88/250 [50:38<1:35:47, 35.48s/it] 36%|███▌      | 89/250 [50:53<1:18:41, 29.32s/it] 36%|███▌      | 90/250 [51:14<1:11:42, 26.89s/it] 36%|███▋      | 91/250 [51:31<1:02:57, 23.76s/it] 37%|███▋      | 92/250 [53:38<2:24:27, 54.85s/it] 37%|███▋      | 93/250 [53:58<1:56:15, 44.43s/it] 38%|███▊      | 94/250 [54:43<1:55:43, 44.51s/it] 38%|███▊      | 95/250 [55:01<1:34:39, 36.64s/it] 38%|███▊      | 96/250 [55:21<1:21:03, 31.58s/it] 39%|███▉      | 97/250 [57:24<2:30:39, 59.08s/it] 39%|███▉      | 98/250 [57:43<1:59:20, 47.11s/it] 40%|███▉      | 99/250 [58:05<1:39:19, 39.47s/it] 40%|████      | 100/250 [58:37<1:32:40, 37.07s/it] 40%|████      | 101/250 [58:51<1:15:24, 30.36s/it] 41%|████      | 102/250 [59:03<1:01:06, 24.78s/it] 41%|████      | 103/250 [1:01:12<2:16:59, 55.91s/it] 42%|████▏     | 104/250 [1:03:21<3:09:44, 77.97s/it] 42%|████▏     | 105/250 [1:05:17<3:36:03, 89.40s/it] 42%|████▏     | 106/250 [1:07:13<3:53:51, 97.44s/it] 43%|████▎     | 107/250 [1:07:38<3:00:18, 75.66s/it] 43%|████▎     | 108/250 [1:07:57<2:19:05, 58.77s/it] 44%|████▎     | 109/250 [1:10:00<3:02:45, 77.77s/it] 44%|████▍     | 110/250 [1:10:27<2:26:28, 62.77s/it] 44%|████▍     | 111/250 [1:10:48<1:56:09, 50.14s/it] 45%|████▍     | 112/250 [1:11:14<1:38:28, 42.82s/it] 45%|████▌     | 113/250 [1:11:32<1:20:37, 35.31s/it] 46%|████▌     | 114/250 [1:11:54<1:10:59, 31.32s/it] 46%|████▌     | 115/250 [1:14:01<2:15:07, 60.06s/it] 46%|████▋     | 116/250 [1:16:08<2:59:24, 80.33s/it] 47%|████▋     | 117/250 [1:16:28<2:17:49, 62.17s/it] 47%|████▋     | 118/250 [1:16:53<1:51:55, 50.87s/it] 48%|████▊     | 119/250 [1:17:04<1:25:18, 39.07s/it] 48%|████▊     | 120/250 [1:17:20<1:09:23, 32.03s/it] 48%|████▊     | 121/250 [1:17:32<56:05, 26.09s/it]   49%|████▉     | 122/250 [1:19:37<1:58:57, 55.76s/it] 49%|████▉     | 123/250 [1:20:00<1:37:06, 45.88s/it] 50%|████▉     | 124/250 [1:20:23<1:22:19, 39.20s/it] 50%|█████     | 125/250 [1:20:43<1:09:06, 33.17s/it] 50%|█████     | 126/250 [1:21:07<1:03:14, 30.60s/it] 51%|█████     | 127/250 [1:21:33<59:49, 29.19s/it]   51%|█████     | 128/250 [1:21:45<48:39, 23.93s/it] 52%|█████▏    | 129/250 [1:22:09<48:40, 24.13s/it] 52%|█████▏    | 130/250 [1:22:31<46:52, 23.44s/it] 52%|█████▏    | 131/250 [1:24:36<1:46:58, 53.94s/it] 53%|█████▎    | 132/250 [1:26:42<2:28:19, 75.42s/it] 53%|█████▎    | 133/250 [1:27:01<1:54:25, 58.68s/it] 54%|█████▎    | 134/250 [1:27:28<1:34:47, 49.03s/it] 54%|█████▍    | 135/250 [1:27:48<1:17:38, 40.51s/it] 54%|█████▍    | 136/250 [1:28:18<1:10:56, 37.33s/it] 55%|█████▍    | 137/250 [1:28:33<57:35, 30.58s/it]   55%|█████▌    | 138/250 [1:28:58<53:50, 28.84s/it] 56%|█████▌    | 139/250 [1:29:19<49:10, 26.58s/it] 56%|█████▌    | 140/250 [1:29:37<43:37, 23.80s/it] 56%|█████▋    | 141/250 [1:29:55<40:02, 22.04s/it] 57%|█████▋    | 142/250 [1:30:31<47:24, 26.34s/it] 57%|█████▋    | 143/250 [1:30:50<42:59, 24.11s/it] 58%|█████▊    | 144/250 [1:31:01<35:34, 20.13s/it] 58%|█████▊    | 145/250 [1:31:13<31:10, 17.81s/it] 58%|█████▊    | 146/250 [1:31:39<35:18, 20.37s/it] 59%|█████▉    | 147/250 [1:32:02<36:16, 21.14s/it] 59%|█████▉    | 148/250 [1:32:16<32:07, 18.89s/it] 60%|█████▉    | 149/250 [1:34:13<1:21:10, 48.23s/it] 60%|██████    | 150/250 [1:36:06<1:52:51, 67.72s/it] 60%|██████    | 151/250 [1:36:28<1:29:05, 53.99s/it] 61%|██████    | 152/250 [1:36:55<1:15:02, 45.94s/it] 61%|██████    | 153/250 [1:37:25<1:06:38, 41.22s/it] 62%|██████▏   | 154/250 [1:37:50<58:11, 36.37s/it]   62%|██████▏   | 155/250 [1:38:02<46:02, 29.08s/it] 62%|██████▏   | 156/250 [1:38:16<38:23, 24.50s/it] 63%|██████▎   | 157/250 [1:38:37<36:22, 23.46s/it] 63%|██████▎   | 158/250 [1:40:42<1:22:43, 53.95s/it] 64%|██████▎   | 159/250 [1:40:56<1:03:30, 41.88s/it] 64%|██████▍   | 160/250 [1:41:16<53:08, 35.43s/it]   64%|██████▍   | 161/250 [1:41:42<48:06, 32.44s/it] 65%|██████▍   | 162/250 [1:41:59<40:57, 27.93s/it] 65%|██████▌   | 163/250 [1:42:30<41:50, 28.86s/it] 66%|██████▌   | 164/250 [1:42:43<34:16, 23.91s/it] 66%|██████▌   | 165/250 [1:43:07<34:12, 24.15s/it] 66%|██████▋   | 166/250 [1:43:20<29:07, 20.80s/it] 67%|██████▋   | 167/250 [1:45:25<1:12:01, 52.07s/it] 67%|██████▋   | 168/250 [1:45:50<1:00:02, 43.93s/it] 68%|██████▊   | 169/250 [1:46:09<49:05, 36.37s/it]   68%|██████▊   | 170/250 [1:46:31<42:50, 32.13s/it] 68%|██████▊   | 171/250 [1:46:56<39:17, 29.84s/it] 69%|██████▉   | 172/250 [1:47:09<32:11, 24.76s/it] 69%|██████▉   | 173/250 [1:49:17<1:11:36, 55.79s/it] 70%|██████▉   | 174/250 [1:49:40<58:10, 45.92s/it]   70%|███████   | 175/250 [1:50:08<50:50, 40.68s/it] 70%|███████   | 176/250 [1:50:26<41:39, 33.78s/it] 71%|███████   | 177/250 [1:50:48<36:55, 30.35s/it] 71%|███████   | 178/250 [1:51:04<31:06, 25.93s/it] 72%|███████▏  | 179/250 [1:51:26<29:22, 24.83s/it] 72%|███████▏  | 180/250 [1:51:49<28:25, 24.36s/it] 72%|███████▏  | 181/250 [1:52:05<25:07, 21.84s/it] 73%|███████▎  | 182/250 [1:52:18<21:48, 19.24s/it] 73%|███████▎  | 183/250 [1:52:42<23:02, 20.64s/it] 74%|███████▎  | 184/250 [1:53:08<24:13, 22.02s/it] 74%|███████▍  | 185/250 [1:55:17<58:37, 54.12s/it] 74%|███████▍  | 186/250 [1:55:36<46:43, 43.80s/it] 75%|███████▍  | 187/250 [1:55:51<36:53, 35.14s/it] 75%|███████▌  | 188/250 [1:56:17<33:14, 32.18s/it] 76%|███████▌  | 189/250 [1:56:39<29:47, 29.31s/it] 76%|███████▌  | 190/250 [1:56:51<24:04, 24.07s/it] 76%|███████▋  | 191/250 [1:57:10<22:10, 22.54s/it] 77%|███████▋  | 192/250 [1:57:29<20:51, 21.58s/it] 77%|███████▋  | 193/250 [1:57:45<18:47, 19.79s/it] 78%|███████▊  | 194/250 [1:58:18<22:17, 23.89s/it] 78%|███████▊  | 195/250 [1:58:37<20:19, 22.17s/it] 78%|███████▊  | 196/250 [1:58:59<20:05, 22.32s/it] 79%|███████▉  | 197/250 [1:59:25<20:32, 23.26s/it] 79%|███████▉  | 198/250 [2:01:21<44:14, 51.04s/it] 80%|███████▉  | 199/250 [2:01:50<37:58, 44.67s/it] 80%|████████  | 200/250 [2:02:14<32:04, 38.49s/it] 80%|████████  | 201/250 [2:02:34<26:43, 32.72s/it] 81%|████████  | 202/250 [2:02:49<21:56, 27.42s/it] 81%|████████  | 203/250 [2:04:55<44:39, 57.01s/it] 82%|████████▏ | 204/250 [2:05:19<36:08, 47.13s/it] 82%|████████▏ | 205/250 [2:05:42<29:55, 39.89s/it] 82%|████████▏ | 206/250 [2:06:11<26:56, 36.74s/it] 83%|████████▎ | 207/250 [2:06:31<22:46, 31.78s/it] 83%|████████▎ | 208/250 [2:06:47<18:49, 26.88s/it] 84%|████████▎ | 209/250 [2:07:03<16:03, 23.50s/it] 84%|████████▍ | 210/250 [2:07:17<13:50, 20.76s/it] 84%|████████▍ | 211/250 [2:07:42<14:20, 22.07s/it] 85%|████████▍ | 212/250 [2:07:57<12:34, 19.87s/it] 85%|████████▌ | 213/250 [2:08:11<11:09, 18.08s/it] 86%|████████▌ | 214/250 [2:08:27<10:27, 17.44s/it] 86%|████████▌ | 215/250 [2:08:42<09:46, 16.74s/it] 86%|████████▋ | 216/250 [2:08:59<09:36, 16.96s/it] 87%|████████▋ | 217/250 [2:10:59<26:18, 47.83s/it] 87%|████████▋ | 218/250 [2:11:12<19:51, 37.23s/it] 88%|████████▊ | 219/250 [2:13:07<31:17, 60.56s/it] 88%|████████▊ | 220/250 [2:13:28<24:21, 48.71s/it] 88%|████████▊ | 221/250 [2:13:44<18:51, 39.00s/it] 89%|████████▉ | 222/250 [2:14:02<15:15, 32.71s/it] 89%|████████▉ | 223/250 [2:14:27<13:38, 30.30s/it] 90%|████████▉ | 224/250 [2:14:49<12:09, 28.04s/it] 90%|█████████ | 225/250 [2:15:08<10:32, 25.31s/it] 90%|█████████ | 226/250 [2:15:24<08:55, 22.33s/it] 91%|█████████ | 227/250 [2:15:51<09:05, 23.73s/it] 91%|█████████ | 228/250 [2:16:10<08:11, 22.36s/it] 92%|█████████▏| 229/250 [2:16:29<07:29, 21.38s/it] 92%|█████████▏| 230/250 [2:16:53<07:25, 22.25s/it] 92%|█████████▏| 231/250 [2:17:18<07:19, 23.11s/it] 93%|█████████▎| 232/250 [2:17:34<06:13, 20.77s/it] 93%|█████████▎| 233/250 [2:18:19<07:58, 28.15s/it] 94%|█████████▎| 234/250 [2:18:35<06:32, 24.55s/it] 94%|█████████▍| 235/250 [2:18:54<05:43, 22.93s/it] 94%|█████████▍| 236/250 [2:19:23<05:46, 24.76s/it] 95%|█████████▍| 237/250 [2:19:42<04:57, 22.86s/it] 95%|█████████▌| 238/250 [2:20:04<04:31, 22.58s/it] 96%|█████████▌| 239/250 [2:20:28<04:13, 23.01s/it] 96%|█████████▌| 240/250 [2:21:06<04:36, 27.62s/it] 96%|█████████▋| 241/250 [2:21:25<03:45, 25.04s/it] 97%|█████████▋| 242/250 [2:21:34<02:41, 20.24s/it] 97%|█████████▋| 243/250 [2:21:52<02:15, 19.40s/it] 98%|█████████▊| 244/250 [2:22:13<02:00, 20.01s/it] 98%|█████████▊| 245/250 [2:22:29<01:34, 18.90s/it] 98%|█████████▊| 246/250 [2:24:30<03:17, 49.41s/it] 99%|█████████▉| 247/250 [2:24:52<02:03, 41.32s/it] 99%|█████████▉| 248/250 [2:25:22<01:15, 37.84s/it]100%|█████████▉| 249/250 [2:25:55<00:36, 36.37s/it]100%|██████████| 250/250 [2:26:13<00:00, 30.74s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.496 seconds.
Prefix dict has been built successfully.
100%|██████████| 250/250 [2:26:24<00:00, 35.14s/it]
***** predict metrics *****
  predict_bleu-4             =    44.4914
  predict_rouge-1            =    47.1154
  predict_rouge-2            =    30.4931
  predict_rouge-l            =    44.2138
  predict_runtime            = 2:26:43.52
  predict_samples_per_second =      0.568
  predict_steps_per_second   =      0.028
07/22/2024 04:18:15 - INFO - llamafactory.train.sft.trainer - Saving prediction results to saves/mistral/orpo_qlora_continue_3/predict/generated_predictions.jsonl
