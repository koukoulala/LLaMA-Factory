nohup: ignoring input
[2024-07-06 04:20:45,317] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
07/06/2024 04:20:46 - WARNING - llamafactory.hparams.parser - Evaluating model in 4/8-bit mode may cause lower scores.
07/06/2024 04:20:46 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None
[INFO|tokenization_utils_base.py:2106] 2024-07-06 04:20:46,740 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2106] 2024-07-06 04:20:46,740 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2106] 2024-07-06 04:20:46,740 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2106] 2024-07-06 04:20:46,740 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2106] 2024-07-06 04:20:46,740 >> loading file tokenizer_config.json
07/06/2024 04:20:46 - INFO - llamafactory.data.template - Add pad token: </s>
07/06/2024 04:20:46 - INFO - llamafactory.data.loader - Loading dataset AssetGeneration/test.json...
Converting format of dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 28587.37 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/5000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 313/5000 [00:00<00:03, 1319.87 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 2191/5000 [00:00<00:00, 7790.19 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 4064/5000 [00:00<00:00, 11345.95 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 8737.52 examples/s] 
[INFO|configuration_utils.py:731] 2024-07-06 04:20:48,309 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/config.json
[INFO|configuration_utils.py:796] 2024-07-06 04:20:48,310 >> Model config MistralConfig {
  "_name_or_path": "/data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2",
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

input_ids:
[1, 28705, 733, 16289, 28793, 5919, 8270, 28705, 28770, 1964, 10220, 297, 4300, 3842, 28725, 2818, 356, 272, 2296, 1871, 28747, 13, 13, 17500, 5140, 28747, 4449, 1508, 2849, 28723, 3423, 1466, 16210, 404, 28723, 675, 28748, 28726, 7041, 28733, 2031, 288, 28748, 8830, 2951, 28733, 28726, 24681, 28723, 2842, 28804, 3457, 28770, 28746, 28740, 28734, 28734, 28784, 28782, 28774, 28800, 3457, 28782, 28746, 28750, 28782, 28740, 28787, 28782, 28800, 3457, 28770, 28770, 28770, 28746, 28750, 28782, 28740, 28774, 28784, 28800, 3457, 28770, 28770, 28784, 28746, 28750, 28782, 28740, 28787, 28750, 28800, 3457, 28770, 28770, 28787, 28746, 28750, 28782, 28740, 28787, 28770, 28800, 3457, 28770, 28770, 28783, 28746, 28750, 28782, 28740, 28787, 28781, 28800, 3457, 28770, 28781, 28783, 28746, 28770, 28782, 28782, 28783, 28740, 28800, 5646, 28730, 313, 28746, 28781, 28783, 28781, 28800, 23114, 28730, 9974, 28746, 11155, 28705, 13, 12075, 28747, 1679, 1466, 16210, 404, 28723, 675, 28705, 13, 9633, 28747, 365, 28750, 28743, 8074, 1939, 12860, 8074, 1939, 13281, 288, 567, 26999, 28705, 13, 22971, 288, 4068, 28747, 28705, 842, 12670, 2951, 365, 24681, 387, 7973, 7809, 1962, 365, 7041, 13281, 288, 342, 8580, 12422, 28765, 346, 404, 28745, 28705, 842, 7497, 27074, 28735, 842, 16123, 28790, 22285, 842, 12670, 2951, 365, 24681, 842, 13341, 13281, 19641, 842, 21013, 25181, 842, 12670, 2951, 365, 24681, 28747, 12948, 1590, 4922, 2956, 297, 4922, 816, 1223, 842, 21815, 272, 24443, 13909, 12670, 2951, 9315, 28713, 304, 365, 24681, 842, 8420, 522, 12670, 2951, 15210, 354, 1756, 11019, 442, 4655, 9405, 5938, 842, 382, 6185, 16970, 18945, 842, 26406, 354, 8648, 288, 16782, 495, 12670, 2951, 365, 24681, 842, 2483, 680, 10636, 28747, 842, 995, 993, 835, 737, 28747, 842, 28705, 13, 15962, 13063, 28747, 1444, 28705, 28783, 28781, 298, 28705, 28774, 28734, 6128, 28723, 28705, 13, 733, 28748, 16289, 28793]
inputs:
<s>  [INST] Please generate 3 Ad Description in English language, based on the following information:

FinalUrl: https://www.nextdayflyers.com/banner-printing/vinyl-banners.php?attr3=100659&attr5=25175&attr333=25196&attr336=25172&attr337=25173&attr338=25174&attr348=35581&product_id=484&calc_variant=LIST 
Domain: nextdayflyers.com 
Category: B2C Services -- Personal Services -- Printing & Publishing 
LandingPage:  . Vinyl Banners - Custom Premium Banner Printing | NextDayFlyers;  . PRODUCTS . SERVICES . Vinyl Banners . Select Print Options . Overall Rating . Vinyl Banners: Promote Anywhere in Any Weather . Choose the Perfect Size Vinyl Signs and Banners . Durable Vinyl Material for Indoor or Outdoor Use . Hanging Made Easy . Tips for Designing Effective Vinyl Banners . Get more tips: . You may also like: . 
CharacterLimit: between 84 to 90 characters. 
 [/INST]
07/06/2024 04:20:48 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.
07/06/2024 04:20:48 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.
[INFO|modeling_utils.py:3460] 2024-07-06 04:20:48,323 >> loading weights file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/model.safetensors.index.json
[INFO|modeling_utils.py:1508] 2024-07-06 04:20:48,323 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:962] 2024-07-06 04:20:48,324 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.23it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]
[INFO|modeling_utils.py:4269] 2024-07-06 04:20:50,929 >> All model checkpoint weights were used when initializing MistralForCausalLM.

[INFO|modeling_utils.py:4277] 2024-07-06 04:20:50,929 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.
[INFO|configuration_utils.py:915] 2024-07-06 04:20:50,931 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/generation_config.json
[INFO|configuration_utils.py:962] 2024-07-06 04:20:50,931 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

07/06/2024 04:20:51 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.
07/06/2024 04:20:51 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.
07/06/2024 04:20:51 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA
07/06/2024 04:20:51 - INFO - llamafactory.model.adapter - Loaded adapter(s): saves/mistral/orpo_qlora/
07/06/2024 04:20:51 - INFO - llamafactory.model.loader - all params: 7262703616
07/06/2024 04:20:51 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.
[INFO|trainer.py:3719] 2024-07-06 04:20:51,453 >> ***** Running Prediction *****
[INFO|trainer.py:3721] 2024-07-06 04:20:51,453 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-07-06 04:20:51,453 >>   Batch size = 20
  0%|          | 0/250 [00:00<?, ?it/s]  1%|          | 2/250 [00:32<1:07:50, 16.41s/it]  1%|          | 3/250 [00:57<1:22:15, 19.98s/it]  2%|▏         | 4/250 [01:12<1:13:33, 17.94s/it]  2%|▏         | 5/250 [03:20<3:49:38, 56.24s/it]  2%|▏         | 6/250 [03:37<2:55:22, 43.13s/it]  3%|▎         | 7/250 [03:54<2:20:56, 34.80s/it]  3%|▎         | 8/250 [04:07<1:53:04, 28.03s/it]  4%|▎         | 9/250 [04:43<2:02:38, 30.53s/it]  4%|▍         | 10/250 [04:58<1:42:29, 25.62s/it]  4%|▍         | 11/250 [05:15<1:32:15, 23.16s/it]  5%|▍         | 12/250 [05:39<1:32:25, 23.30s/it]  5%|▌         | 13/250 [05:54<1:21:52, 20.73s/it]  6%|▌         | 14/250 [06:08<1:13:51, 18.78s/it]  6%|▌         | 15/250 [06:21<1:07:01, 17.11s/it]  6%|▋         | 16/250 [06:45<1:14:43, 19.16s/it]  7%|▋         | 17/250 [07:05<1:15:17, 19.39s/it]  7%|▋         | 18/250 [07:26<1:16:23, 19.76s/it]  8%|▊         | 19/250 [08:02<1:34:55, 24.66s/it]  8%|▊         | 20/250 [10:08<3:31:51, 55.27s/it]  8%|▊         | 21/250 [10:33<2:56:13, 46.17s/it]  9%|▉         | 22/250 [10:55<2:27:14, 38.75s/it]  9%|▉         | 23/250 [11:19<2:10:10, 34.41s/it] 10%|▉         | 24/250 [11:37<1:50:49, 29.42s/it] 10%|█         | 25/250 [11:54<1:36:18, 25.68s/it] 10%|█         | 26/250 [12:12<1:27:05, 23.33s/it] 11%|█         | 27/250 [12:32<1:22:50, 22.29s/it] 11%|█         | 28/250 [12:56<1:24:25, 22.82s/it] 12%|█▏        | 29/250 [13:21<1:27:02, 23.63s/it] 12%|█▏        | 30/250 [13:40<1:21:30, 22.23s/it] 12%|█▏        | 31/250 [13:59<1:17:52, 21.33s/it] 13%|█▎        | 32/250 [14:16<1:12:20, 19.91s/it] 13%|█▎        | 33/250 [14:39<1:15:56, 21.00s/it] 14%|█▎        | 34/250 [14:58<1:13:26, 20.40s/it] 14%|█▍        | 35/250 [15:21<1:15:46, 21.15s/it] 14%|█▍        | 36/250 [15:45<1:18:25, 21.99s/it] 15%|█▍        | 37/250 [16:07<1:17:49, 21.92s/it] 15%|█▌        | 38/250 [16:29<1:17:32, 21.95s/it] 16%|█▌        | 39/250 [16:49<1:14:48, 21.27s/it] 16%|█▌        | 40/250 [17:21<1:26:10, 24.62s/it] 16%|█▋        | 41/250 [19:31<3:15:19, 56.07s/it] 17%|█▋        | 42/250 [19:58<2:44:02, 47.32s/it] 17%|█▋        | 43/250 [20:18<2:14:58, 39.12s/it] 18%|█▊        | 44/250 [20:37<1:54:18, 33.30s/it] 18%|█▊        | 45/250 [20:58<1:40:38, 29.46s/it] 18%|█▊        | 46/250 [22:56<3:10:19, 55.98s/it] 19%|█▉        | 47/250 [23:23<2:39:58, 47.28s/it] 19%|█▉        | 48/250 [23:42<2:10:46, 38.84s/it] 20%|█▉        | 49/250 [23:54<1:43:31, 30.90s/it] 20%|██        | 50/250 [24:14<1:32:21, 27.71s/it] 20%|██        | 51/250 [24:40<1:29:49, 27.08s/it] 21%|██        | 52/250 [24:56<1:18:24, 23.76s/it] 21%|██        | 53/250 [25:24<1:22:35, 25.15s/it] 22%|██▏       | 54/250 [25:42<1:14:23, 22.78s/it] 22%|██▏       | 55/250 [26:05<1:14:15, 22.85s/it] 22%|██▏       | 56/250 [26:36<1:22:22, 25.48s/it] 23%|██▎       | 57/250 [26:59<1:19:01, 24.57s/it] 23%|██▎       | 58/250 [27:20<1:15:29, 23.59s/it] 24%|██▎       | 59/250 [27:45<1:16:44, 24.11s/it] 24%|██▍       | 60/250 [28:14<1:20:09, 25.31s/it] 24%|██▍       | 61/250 [28:29<1:10:09, 22.27s/it] 25%|██▍       | 62/250 [28:51<1:09:56, 22.32s/it] 25%|██▌       | 63/250 [29:07<1:03:37, 20.42s/it] 26%|██▌       | 64/250 [29:35<1:09:58, 22.57s/it] 26%|██▌       | 65/250 [29:51<1:04:15, 20.84s/it] 26%|██▋       | 66/250 [30:07<58:50, 19.19s/it]   27%|██▋       | 67/250 [30:29<1:01:19, 20.11s/it] 27%|██▋       | 68/250 [30:51<1:02:36, 20.64s/it] 28%|██▊       | 69/250 [31:14<1:04:26, 21.36s/it] 28%|██▊       | 70/250 [31:35<1:04:07, 21.37s/it] 28%|██▊       | 71/250 [31:53<1:00:12, 20.18s/it] 29%|██▉       | 72/250 [32:17<1:03:15, 21.33s/it] 29%|██▉       | 73/250 [32:39<1:03:31, 21.54s/it] 30%|██▉       | 74/250 [33:03<1:05:10, 22.22s/it] 30%|███       | 75/250 [33:20<1:00:49, 20.85s/it] 30%|███       | 76/250 [33:43<1:02:20, 21.49s/it] 31%|███       | 77/250 [34:11<1:07:45, 23.50s/it] 31%|███       | 78/250 [34:34<1:06:08, 23.07s/it] 32%|███▏      | 79/250 [34:59<1:07:31, 23.69s/it] 32%|███▏      | 80/250 [35:15<1:01:16, 21.62s/it] 32%|███▏      | 81/250 [35:31<55:41, 19.77s/it]   33%|███▎      | 82/250 [35:49<53:33, 19.13s/it] 33%|███▎      | 83/250 [36:14<58:55, 21.17s/it] 34%|███▎      | 84/250 [36:39<1:01:33, 22.25s/it] 34%|███▍      | 85/250 [37:04<1:03:28, 23.08s/it] 34%|███▍      | 86/250 [37:27<1:02:57, 23.03s/it] 35%|███▍      | 87/250 [37:42<55:29, 20.43s/it]   35%|███▌      | 88/250 [38:00<53:39, 19.88s/it] 36%|███▌      | 89/250 [38:15<49:01, 18.27s/it] 36%|███▌      | 90/250 [38:39<53:11, 19.94s/it] 36%|███▋      | 91/250 [38:55<50:27, 19.04s/it] 37%|███▋      | 92/250 [41:03<2:15:41, 51.53s/it] 37%|███▋      | 93/250 [41:29<1:54:43, 43.84s/it] 38%|███▊      | 94/250 [42:10<1:51:42, 42.97s/it] 38%|███▊      | 95/250 [42:31<1:34:02, 36.40s/it] 38%|███▊      | 96/250 [42:51<1:20:43, 31.45s/it] 39%|███▉      | 97/250 [44:54<2:30:23, 58.98s/it] 39%|███▉      | 98/250 [45:16<2:01:33, 47.98s/it] 40%|███▉      | 99/250 [47:20<2:57:59, 70.73s/it] 40%|████      | 100/250 [47:50<2:26:33, 58.63s/it] 40%|████      | 101/250 [48:05<1:52:56, 45.48s/it] 41%|████      | 102/250 [50:01<2:44:30, 66.69s/it] 41%|████      | 103/250 [50:17<2:06:04, 51.46s/it] 42%|████▏     | 104/250 [50:38<1:42:55, 42.30s/it] 42%|████▏     | 105/250 [50:58<1:25:37, 35.43s/it] 42%|████▏     | 106/250 [51:23<1:17:55, 32.47s/it] 43%|████▎     | 107/250 [53:21<2:18:41, 58.19s/it] 43%|████▎     | 108/250 [53:42<1:51:15, 47.01s/it] 44%|████▎     | 109/250 [55:44<2:43:21, 69.51s/it] 44%|████▍     | 110/250 [56:11<2:12:24, 56.75s/it] 44%|████▍     | 111/250 [56:32<1:46:09, 45.83s/it] 45%|████▍     | 112/250 [56:57<1:31:07, 39.62s/it] 45%|████▌     | 113/250 [57:14<1:15:27, 33.05s/it] 46%|████▌     | 114/250 [57:39<1:09:22, 30.60s/it] 46%|████▌     | 115/250 [57:54<57:49, 25.70s/it]   46%|████▋     | 116/250 [1:00:01<2:05:48, 56.33s/it] 47%|████▋     | 117/250 [1:00:20<1:39:49, 45.03s/it] 47%|████▋     | 118/250 [1:00:46<1:26:28, 39.31s/it] 48%|████▊     | 119/250 [1:00:58<1:07:46, 31.04s/it] 48%|████▊     | 120/250 [1:01:13<57:13, 26.41s/it]   48%|████▊     | 121/250 [1:01:26<47:56, 22.30s/it] 49%|████▉     | 122/250 [1:01:56<52:14, 24.48s/it] 49%|████▉     | 123/250 [1:02:19<50:59, 24.09s/it] 50%|████▉     | 124/250 [1:02:42<49:57, 23.79s/it] 50%|█████     | 125/250 [1:03:01<46:55, 22.52s/it] 50%|█████     | 126/250 [1:03:22<45:29, 22.01s/it] 51%|█████     | 127/250 [1:03:48<47:14, 23.04s/it] 51%|█████     | 128/250 [1:04:00<40:03, 19.70s/it] 52%|█████▏    | 129/250 [1:04:21<40:50, 20.25s/it] 52%|█████▏    | 130/250 [1:04:41<40:22, 20.19s/it] 52%|█████▏    | 131/250 [1:05:03<40:57, 20.66s/it] 53%|█████▎    | 132/250 [1:05:23<40:05, 20.38s/it] 53%|█████▎    | 133/250 [1:05:42<38:49, 19.91s/it] 54%|█████▎    | 134/250 [1:06:04<39:45, 20.57s/it] 54%|█████▍    | 135/250 [1:06:24<39:27, 20.59s/it] 54%|█████▍    | 136/250 [1:06:53<43:47, 23.05s/it] 55%|█████▍    | 137/250 [1:07:06<37:50, 20.10s/it] 55%|█████▌    | 138/250 [1:07:32<40:32, 21.72s/it] 56%|█████▌    | 139/250 [1:07:56<41:27, 22.41s/it] 56%|█████▌    | 140/250 [1:08:12<37:56, 20.69s/it] 56%|█████▋    | 141/250 [1:08:29<35:05, 19.32s/it] 57%|█████▋    | 142/250 [1:09:05<44:09, 24.53s/it] 57%|█████▋    | 143/250 [1:09:25<41:13, 23.11s/it] 58%|█████▊    | 144/250 [1:09:37<34:54, 19.76s/it] 58%|█████▊    | 145/250 [1:09:50<31:01, 17.73s/it] 58%|█████▊    | 146/250 [1:11:56<1:26:55, 50.15s/it] 59%|█████▉    | 147/250 [1:12:19<1:12:21, 42.15s/it] 59%|█████▉    | 148/250 [1:12:34<57:40, 33.92s/it]   60%|█████▉    | 149/250 [1:12:53<49:23, 29.34s/it] 60%|██████    | 150/250 [1:13:18<46:51, 28.12s/it] 60%|██████    | 151/250 [1:14:11<58:31, 35.47s/it] 61%|██████    | 152/250 [1:14:35<52:37, 32.22s/it] 61%|██████    | 153/250 [1:15:05<51:03, 31.59s/it] 62%|██████▏   | 154/250 [1:15:32<48:08, 30.09s/it] 62%|██████▏   | 155/250 [1:15:44<38:59, 24.62s/it] 62%|██████▏   | 156/250 [1:15:58<33:33, 21.42s/it] 63%|██████▎   | 157/250 [1:16:19<32:57, 21.27s/it] 63%|██████▎   | 158/250 [1:16:43<33:55, 22.13s/it] 64%|██████▎   | 159/250 [1:16:56<29:30, 19.46s/it] 64%|██████▍   | 160/250 [1:17:18<30:14, 20.16s/it] 64%|██████▍   | 161/250 [1:17:44<32:40, 22.03s/it] 65%|██████▍   | 162/250 [1:18:02<30:15, 20.64s/it] 65%|██████▌   | 163/250 [1:18:29<32:57, 22.73s/it] 66%|██████▌   | 164/250 [1:18:41<28:02, 19.56s/it] 66%|██████▌   | 165/250 [1:19:06<29:43, 20.98s/it] 66%|██████▋   | 166/250 [1:19:19<26:09, 18.68s/it] 67%|██████▋   | 167/250 [1:21:24<1:10:03, 50.64s/it] 67%|██████▋   | 168/250 [1:21:53<1:00:24, 44.20s/it] 68%|██████▊   | 169/250 [1:23:56<1:31:28, 67.76s/it] 68%|██████▊   | 170/250 [1:24:17<1:11:43, 53.79s/it] 68%|██████▊   | 171/250 [1:24:38<57:44, 43.86s/it]   69%|██████▉   | 172/250 [1:24:51<44:58, 34.60s/it] 69%|██████▉   | 173/250 [1:25:19<41:54, 32.65s/it] 70%|██████▉   | 174/250 [1:25:40<36:48, 29.07s/it] 70%|███████   | 175/250 [1:26:07<35:32, 28.43s/it] 70%|███████   | 176/250 [1:26:24<31:06, 25.22s/it] 71%|███████   | 177/250 [1:26:50<30:39, 25.19s/it] 71%|███████   | 178/250 [1:27:05<26:34, 22.15s/it] 72%|███████▏  | 179/250 [1:27:28<26:36, 22.49s/it] 72%|███████▏  | 180/250 [1:27:51<26:35, 22.79s/it] 72%|███████▏  | 181/250 [1:28:09<24:22, 21.20s/it] 73%|███████▎  | 182/250 [1:28:24<21:55, 19.35s/it] 73%|███████▎  | 183/250 [1:28:50<23:50, 21.36s/it] 74%|███████▎  | 184/250 [1:29:18<25:41, 23.36s/it] 74%|███████▍  | 185/250 [1:31:27<59:39, 55.07s/it] 74%|███████▍  | 186/250 [1:31:46<47:11, 44.24s/it] 75%|███████▍  | 187/250 [1:32:00<36:52, 35.11s/it] 75%|███████▌  | 188/250 [1:32:24<32:49, 31.76s/it] 76%|███████▌  | 189/250 [1:32:47<29:45, 29.27s/it] 76%|███████▌  | 190/250 [1:33:00<24:13, 24.23s/it] 76%|███████▋  | 191/250 [1:33:18<22:13, 22.60s/it] 77%|███████▋  | 192/250 [1:33:38<20:55, 21.65s/it] 77%|███████▋  | 193/250 [1:33:52<18:31, 19.50s/it] 78%|███████▊  | 194/250 [1:34:22<21:01, 22.53s/it] 78%|███████▊  | 195/250 [1:34:41<19:32, 21.32s/it] 78%|███████▊  | 196/250 [1:35:04<19:50, 22.04s/it] 79%|███████▉  | 197/250 [1:35:30<20:26, 23.14s/it] 79%|███████▉  | 198/250 [1:35:54<20:11, 23.30s/it] 80%|███████▉  | 199/250 [1:37:57<45:17, 53.29s/it] 80%|████████  | 200/250 [1:38:21<37:12, 44.64s/it] 80%|████████  | 201/250 [1:38:39<29:52, 36.58s/it] 81%|████████  | 202/250 [1:38:53<23:55, 29.91s/it] 81%|████████  | 203/250 [1:39:25<23:52, 30.48s/it] 82%|████████▏ | 204/250 [1:41:24<43:37, 56.91s/it] 82%|████████▏ | 205/250 [1:41:48<35:16, 47.04s/it] 82%|████████▏ | 206/250 [1:42:18<30:47, 41.98s/it] 83%|████████▎ | 207/250 [1:42:36<25:00, 34.90s/it] 83%|████████▎ | 208/250 [1:42:52<20:25, 29.18s/it] 84%|████████▎ | 209/250 [1:43:10<17:31, 25.65s/it] 84%|████████▍ | 210/250 [1:43:25<15:01, 22.54s/it] 84%|████████▍ | 211/250 [1:43:52<15:27, 23.78s/it] 85%|████████▍ | 212/250 [1:44:05<13:08, 20.76s/it] 85%|████████▌ | 213/250 [1:44:18<11:23, 18.48s/it] 86%|████████▌ | 214/250 [1:44:33<10:25, 17.37s/it] 86%|████████▌ | 215/250 [1:44:49<09:50, 16.87s/it] 86%|████████▋ | 216/250 [1:45:07<09:49, 17.35s/it] 87%|████████▋ | 217/250 [1:45:40<12:01, 21.86s/it] 87%|████████▋ | 218/250 [1:45:52<10:08, 19.00s/it] 88%|████████▊ | 219/250 [1:46:12<09:52, 19.11s/it] 88%|████████▊ | 220/250 [1:46:30<09:25, 18.83s/it] 88%|████████▊ | 221/250 [1:46:46<08:43, 18.05s/it] 89%|████████▉ | 222/250 [1:47:02<08:09, 17.49s/it] 89%|████████▉ | 223/250 [1:47:24<08:28, 18.82s/it] 90%|████████▉ | 224/250 [1:47:45<08:24, 19.41s/it] 90%|█████████ | 225/250 [1:48:04<08:05, 19.43s/it] 90%|█████████ | 226/250 [1:48:20<07:18, 18.27s/it] 91%|█████████ | 227/250 [1:48:46<07:57, 20.76s/it] 91%|█████████ | 228/250 [1:49:06<07:31, 20.54s/it] 92%|█████████▏| 229/250 [1:49:27<07:08, 20.41s/it] 92%|█████████▏| 230/250 [1:49:48<06:56, 20.84s/it] 92%|█████████▏| 231/250 [1:50:11<06:45, 21.35s/it] 93%|█████████▎| 232/250 [1:50:25<05:45, 19.21s/it] 93%|█████████▎| 233/250 [1:51:01<06:53, 24.31s/it] 94%|█████████▎| 234/250 [1:51:18<05:50, 21.90s/it] 94%|█████████▍| 235/250 [1:51:37<05:19, 21.28s/it] 94%|█████████▍| 236/250 [1:52:06<05:30, 23.58s/it] 95%|█████████▍| 237/250 [1:52:25<04:48, 22.23s/it] 95%|█████████▌| 238/250 [1:52:50<04:33, 22.76s/it] 96%|█████████▌| 239/250 [1:53:12<04:08, 22.58s/it] 96%|█████████▌| 240/250 [1:53:48<04:28, 26.83s/it] 96%|█████████▋| 241/250 [1:54:07<03:38, 24.27s/it] 97%|█████████▋| 242/250 [1:54:16<02:38, 19.76s/it] 97%|█████████▋| 243/250 [1:54:31<02:09, 18.46s/it] 98%|█████████▊| 244/250 [1:54:54<01:59, 19.86s/it] 98%|█████████▊| 245/250 [1:55:12<01:35, 19.19s/it] 98%|█████████▊| 246/250 [1:57:13<03:18, 49.62s/it] 99%|█████████▉| 247/250 [1:57:34<02:03, 41.22s/it] 99%|█████████▉| 248/250 [1:59:42<02:14, 67.30s/it]100%|█████████▉| 249/250 [2:00:14<00:56, 56.46s/it]100%|██████████| 250/250 [2:00:31<00:00, 44.66s/it]Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.503 seconds.
Prefix dict has been built successfully.
100%|██████████| 250/250 [2:00:42<00:00, 28.97s/it]
***** predict metrics *****
  predict_bleu-4             =    43.3386
  predict_rouge-1            =    46.0822
  predict_rouge-2            =    29.3356
  predict_rouge-l            =     43.463
  predict_runtime            = 2:01:02.65
  predict_samples_per_second =      0.688
  predict_steps_per_second   =      0.034
07/06/2024 06:21:54 - INFO - llamafactory.train.sft.trainer - Saving prediction results to saves/mistral/orpo_qlora/predict/generated_predictions.jsonl
