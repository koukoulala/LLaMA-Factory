nohup: ignoring input
[2024-05-30 10:52:41,538] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-30 10:52:41,551] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
05/30/2024 10:52:42 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.
05/30/2024 10:52:42 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
05/30/2024 10:52:42 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2106] 2024-05-30 10:52:42,955 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2106] 2024-05-30 10:52:42,955 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2106] 2024-05-30 10:52:42,955 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2106] 2024-05-30 10:52:42,955 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2106] 2024-05-30 10:52:42,955 >> loading file tokenizer_config.json
05/30/2024 10:52:42 - INFO - llamafactory.data.template - Add pad token: </s>
05/30/2024 10:52:42 - INFO - llamafactory.data.loader - Loading dataset AssetGeneration/train.json...
05/30/2024 10:52:43 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.
05/30/2024 10:52:43 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
05/30/2024 10:52:43 - INFO - llamafactory.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
05/30/2024 10:52:43 - INFO - llamafactory.data.template - Add pad token: </s>
Converting format of dataset (num_proc=16):   0%|          | 0/1000000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   0%|          | 5000/1000000 [00:00<00:22, 43832.48 examples/s]Converting format of dataset (num_proc=16):  16%|█▌        | 160000/1000000 [00:00<00:01, 825706.90 examples/s]Converting format of dataset (num_proc=16):  34%|███▍      | 339000/1000000 [00:00<00:00, 1179118.34 examples/s]Converting format of dataset (num_proc=16):  52%|█████▏    | 519000/1000000 [00:00<00:00, 1351612.32 examples/s]Converting format of dataset (num_proc=16):  70%|██████▉   | 695000/1000000 [00:00<00:00, 1469458.84 examples/s]Converting format of dataset (num_proc=16):  84%|████████▍ | 845000/1000000 [00:00<00:00, 1474785.23 examples/s]Converting format of dataset (num_proc=16): 100%|█████████▉| 996500/1000000 [00:04<00:00, 125997.70 examples/s] Converting format of dataset (num_proc=16): 100%|██████████| 1000000/1000000 [00:04<00:00, 232992.89 examples/s]
05/30/2024 10:52:48 - INFO - llamafactory.data.loader - Loading dataset AssetGeneration/train.json...
Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   0%|          | 0/1000000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   0%|          | 4000/1000000 [00:00<00:29, 33975.04 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 1000/1000000 [00:00<09:32, 1744.48 examples/s]Converting format of dataset (num_proc=16):  12%|█▏        | 121000/1000000 [00:00<00:01, 595216.52 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 5000/1000000 [00:00<01:49, 9078.15 examples/s]Converting format of dataset (num_proc=16):  25%|██▍       | 247000/1000000 [00:00<00:00, 846524.05 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 10000/1000000 [00:00<00:55, 17787.50 examples/s]Converting format of dataset (num_proc=16):  36%|███▌      | 358000/1000000 [00:00<00:00, 939488.55 examples/s]Converting format of dataset (num_proc=16):  48%|████▊     | 479000/1000000 [00:00<00:00, 1002409.59 examples/s]Running tokenizer on dataset (num_proc=16):   1%|▏         | 14000/1000000 [00:00<00:45, 21567.24 examples/s]Converting format of dataset (num_proc=16):  60%|██████    | 601000/1000000 [00:00<00:00, 1072088.41 examples/s]Converting format of dataset (num_proc=16):  72%|███████▏  | 716000/1000000 [00:00<00:00, 1089482.21 examples/s]Running tokenizer on dataset (num_proc=16):   2%|▏         | 18000/1000000 [00:01<00:47, 20852.37 examples/s]Running tokenizer on dataset (num_proc=16):   2%|▏         | 21000/1000000 [00:01<00:46, 20982.18 examples/s]Converting format of dataset (num_proc=16):  83%|████████▎ | 826000/1000000 [00:00<00:00, 935722.28 examples/s] Running tokenizer on dataset (num_proc=16):   2%|▎         | 25000/1000000 [00:01<00:39, 24916.86 examples/s]Running tokenizer on dataset (num_proc=16):   3%|▎         | 29000/1000000 [00:01<00:34, 28287.98 examples/s]Converting format of dataset (num_proc=16):  92%|█████████▏| 924000/1000000 [00:01<00:00, 643747.55 examples/s]Running tokenizer on dataset (num_proc=16):   3%|▎         | 33000/1000000 [00:01<00:37, 25621.58 examples/s]Running tokenizer on dataset (num_proc=16):   4%|▎         | 36000/1000000 [00:01<00:38, 25162.11 examples/s]Running tokenizer on dataset (num_proc=16):   4%|▍         | 42000/1000000 [00:01<00:32, 29708.77 examples/s]Running tokenizer on dataset (num_proc=16):   5%|▍         | 47000/1000000 [00:02<00:33, 28865.34 examples/s]Running tokenizer on dataset (num_proc=16):   5%|▌         | 51000/1000000 [00:02<00:30, 31251.95 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▌         | 56000/1000000 [00:02<00:27, 34394.98 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▌         | 60000/1000000 [00:02<00:26, 34901.52 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 64000/1000000 [00:02<00:29, 31575.94 examples/s]Running tokenizer on dataset (num_proc=16):   7%|▋         | 68000/1000000 [00:02<00:30, 30946.99 examples/s]Running tokenizer on dataset (num_proc=16):   7%|▋         | 73000/1000000 [00:02<00:26, 35349.23 examples/s]Running tokenizer on dataset (num_proc=16):   8%|▊         | 78000/1000000 [00:02<00:25, 36816.84 examples/s]Running tokenizer on dataset (num_proc=16):   8%|▊         | 82000/1000000 [00:03<00:27, 32820.35 examples/s]Running tokenizer on dataset (num_proc=16):   9%|▊         | 86000/1000000 [00:03<00:26, 34030.18 examples/s]Running tokenizer on dataset (num_proc=16):   9%|▉         | 90000/1000000 [00:03<00:26, 34303.82 examples/s]Running tokenizer on dataset (num_proc=16):  10%|▉         | 95000/1000000 [00:03<00:29, 30296.54 examples/s]Running tokenizer on dataset (num_proc=16):  10%|█         | 100000/1000000 [00:03<00:28, 31359.87 examples/s]Running tokenizer on dataset (num_proc=16):  11%|█         | 106000/1000000 [00:03<00:24, 35949.62 examples/s]Running tokenizer on dataset (num_proc=16):  11%|█         | 111000/1000000 [00:04<00:27, 31853.05 examples/s]Running tokenizer on dataset (num_proc=16):  12%|█▏        | 116000/1000000 [00:04<00:27, 32307.64 examples/s]Running tokenizer on dataset (num_proc=16):  12%|█▏        | 122000/1000000 [00:04<00:23, 36771.21 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 126000/1000000 [00:04<00:23, 36969.02 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 130000/1000000 [00:04<00:26, 33089.39 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▎        | 135000/1000000 [00:04<00:24, 35509.05 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▍        | 139000/1000000 [00:04<00:24, 35787.65 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▍        | 143000/1000000 [00:04<00:28, 30310.16 examples/s]Running tokenizer on dataset (num_proc=16):  15%|█▍        | 148000/1000000 [00:05<00:26, 31841.97 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 1000000/1000000 [00:04<00:00, 206932.07 examples/s]
Running tokenizer on dataset (num_proc=16):  15%|█▌        | 153000/1000000 [00:05<00:24, 34095.02 examples/s]Running tokenizer on dataset (num_proc=16):  16%|█▌        | 158000/1000000 [00:05<00:23, 35281.88 examples/s]Running tokenizer on dataset (num_proc=16):  16%|█▌        | 162000/1000000 [00:05<00:26, 31274.84 examples/s]Running tokenizer on dataset (num_proc=16):  17%|█▋        | 167000/1000000 [00:05<00:24, 34444.60 examples/s]Running tokenizer on dataset (num_proc=16):  17%|█▋        | 172000/1000000 [00:05<00:23, 35002.62 examples/s]Running tokenizer on dataset (num_proc=16):  18%|█▊        | 176000/1000000 [00:05<00:26, 31623.35 examples/s]Running tokenizer on dataset (num_proc=16):  18%|█▊        | 180000/1000000 [00:06<00:26, 31150.16 examples/s]Running tokenizer on dataset (num_proc=16):  18%|█▊        | 185000/1000000 [00:06<00:23, 35125.77 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 189000/1000000 [00:06<00:22, 35904.10 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 193000/1000000 [00:06<00:25, 31244.74 examples/s]Running tokenizer on dataset (num_proc=16):  20%|█▉        | 197000/1000000 [00:06<00:24, 32173.77 examples/s]Running tokenizer on dataset (num_proc=16):  20%|██        | 203000/1000000 [00:06<00:21, 37761.99 examples/s]Running tokenizer on dataset (num_proc=16):  21%|██        | 207000/1000000 [00:06<00:25, 31035.05 examples/s]Running tokenizer on dataset (num_proc=16):  21%|██        | 211000/1000000 [00:06<00:23, 33073.48 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 216000/1000000 [00:07<00:21, 36085.56 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 220000/1000000 [00:07<00:21, 36273.93 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 224000/1000000 [00:07<00:24, 31315.88 examples/s]Running tokenizer on dataset (num_proc=16):  23%|██▎       | 228000/1000000 [00:07<00:24, 31675.11 examples/s]Running tokenizer on dataset (num_proc=16):  23%|██▎       | 233000/1000000 [00:07<00:21, 35600.39 examples/s]Running tokenizer on dataset (num_proc=16):  24%|██▎       | 237000/1000000 [00:07<00:21, 35800.57 examples/s]Running tokenizer on dataset (num_proc=16):  24%|██▍       | 241000/1000000 [00:07<00:23, 32079.77 examples/s]Running tokenizer on dataset (num_proc=16):  24%|██▍       | 245000/1000000 [00:07<00:23, 32304.43 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 251000/1000000 [00:08<00:19, 38497.78 examples/s]Running tokenizer on dataset (num_proc=16):  26%|██▌       | 256000/1000000 [00:08<00:23, 31770.67 examples/s]Running tokenizer on dataset (num_proc=16):  26%|██▌       | 260000/1000000 [00:08<00:22, 32317.90 examples/s]Running tokenizer on dataset (num_proc=16):  26%|██▋       | 265000/1000000 [00:08<00:20, 35688.90 examples/s]Running tokenizer on dataset (num_proc=16):  27%|██▋       | 269000/1000000 [00:08<00:20, 35439.79 examples/s]Running tokenizer on dataset (num_proc=16):  27%|██▋       | 273000/1000000 [00:08<00:22, 32110.14 examples/s]Running tokenizer on dataset (num_proc=16):  28%|██▊       | 277000/1000000 [00:08<00:23, 31288.80 examples/s]Running tokenizer on dataset (num_proc=16):  28%|██▊       | 283000/1000000 [00:09<00:18, 38087.17 examples/s]Running tokenizer on dataset (num_proc=16):  29%|██▉       | 288000/1000000 [00:09<00:22, 32083.48 examples/s]Running tokenizer on dataset (num_proc=16):  29%|██▉       | 292000/1000000 [00:09<00:21, 32259.14 examples/s]Running tokenizer on dataset (num_proc=16):  30%|██▉       | 297000/1000000 [00:09<00:20, 34752.31 examples/s]Running tokenizer on dataset (num_proc=16):  30%|███       | 301000/1000000 [00:09<00:19, 35615.83 examples/s]Running tokenizer on dataset (num_proc=16):  30%|███       | 305000/1000000 [00:09<00:21, 32127.56 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███       | 309000/1000000 [00:09<00:21, 31981.70 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 315000/1000000 [00:09<00:17, 38689.91 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 320000/1000000 [00:10<00:22, 30873.37 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 324000/1000000 [00:10<00:20, 32824.03 examples/s]Running tokenizer on dataset (num_proc=16):  33%|███▎      | 328000/1000000 [00:10<00:19, 33778.54 examples/s]Running tokenizer on dataset (num_proc=16):  33%|███▎      | 332000/1000000 [00:10<00:19, 35096.32 examples/s]Running tokenizer on dataset (num_proc=16):  34%|███▎      | 336000/1000000 [00:10<00:21, 30548.74 examples/s]Running tokenizer on dataset (num_proc=16):  34%|███▍      | 341000/1000000 [00:10<00:20, 32918.37 examples/s]Running tokenizer on dataset (num_proc=16):  35%|███▍      | 347000/1000000 [00:10<00:16, 38785.77 examples/s]Running tokenizer on dataset (num_proc=16):  35%|███▌      | 352000/1000000 [00:11<00:20, 30961.06 examples/s]Running tokenizer on dataset (num_proc=16):  36%|███▌      | 357000/1000000 [00:11<00:19, 33046.17 examples/s]Running tokenizer on dataset (num_proc=16):  36%|███▋      | 363000/1000000 [00:11<00:16, 38291.48 examples/s]Running tokenizer on dataset (num_proc=16):  37%|███▋      | 368000/1000000 [00:11<00:21, 30087.23 examples/s]Running tokenizer on dataset (num_proc=16):  37%|███▋      | 373000/1000000 [00:11<00:18, 33483.90 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 379000/1000000 [00:11<00:16, 38206.47 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 384000/1000000 [00:12<00:20, 30537.55 examples/s]Running tokenizer on dataset (num_proc=16):  39%|███▉      | 389000/1000000 [00:12<00:18, 32487.68 examples/s]Running tokenizer on dataset (num_proc=16):  40%|███▉      | 395000/1000000 [00:12<00:16, 37284.56 examples/s]Running tokenizer on dataset (num_proc=16):  40%|████      | 400000/1000000 [00:12<00:21, 27275.61 examples/s]Running tokenizer on dataset (num_proc=16):  40%|████      | 404000/1000000 [00:12<00:25, 23800.95 examples/s]Running tokenizer on dataset (num_proc=16):  41%|████      | 408000/1000000 [00:13<00:23, 25373.84 examples/s]Running tokenizer on dataset (num_proc=16):  41%|████      | 412000/1000000 [00:13<00:21, 27481.66 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▏     | 416000/1000000 [00:13<00:20, 28644.07 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▏     | 420000/1000000 [00:13<00:18, 30634.80 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▏     | 424000/1000000 [00:13<00:18, 30350.21 examples/s]Running tokenizer on dataset (num_proc=16):  43%|████▎     | 428000/1000000 [00:13<00:17, 31931.27 examples/s]Running tokenizer on dataset (num_proc=16):  43%|████▎     | 432000/1000000 [00:13<00:17, 31943.81 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▎     | 436000/1000000 [00:13<00:16, 33268.57 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 440000/1000000 [00:14<00:17, 32406.71 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 444000/1000000 [00:14<00:16, 33588.81 examples/s]Running tokenizer on dataset (num_proc=16):  45%|████▍     | 448000/1000000 [00:14<00:16, 32507.71 examples/s]Running tokenizer on dataset (num_proc=16):  45%|████▌     | 452000/1000000 [00:14<00:16, 33641.53 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▌     | 456000/1000000 [00:14<00:16, 33522.97 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▌     | 460000/1000000 [00:14<00:15, 33870.88 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▋     | 464000/1000000 [00:14<00:16, 32511.27 examples/s]Running tokenizer on dataset (num_proc=16):  47%|████▋     | 468000/1000000 [00:14<00:16, 33107.16 examples/s]Running tokenizer on dataset (num_proc=16):  47%|████▋     | 472000/1000000 [00:14<00:15, 33709.33 examples/s]Running tokenizer on dataset (num_proc=16):  48%|████▊     | 476000/1000000 [00:15<00:15, 34358.95 examples/s]Running tokenizer on dataset (num_proc=16):  48%|████▊     | 480000/1000000 [00:15<00:15, 32507.98 examples/s]Running tokenizer on dataset (num_proc=16):  48%|████▊     | 484000/1000000 [00:15<00:15, 33068.25 examples/s]Running tokenizer on dataset (num_proc=16):  49%|████▉     | 488000/1000000 [00:15<00:15, 33543.56 examples/s]Running tokenizer on dataset (num_proc=16):  49%|████▉     | 492000/1000000 [00:15<00:15, 33865.49 examples/s]Running tokenizer on dataset (num_proc=16):  50%|████▉     | 496000/1000000 [00:15<00:15, 32335.17 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 500000/1000000 [00:15<00:14, 33517.62 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 504000/1000000 [00:15<00:14, 34064.60 examples/s]Running tokenizer on dataset (num_proc=16):  51%|█████     | 508000/1000000 [00:16<00:14, 33888.71 examples/s]Running tokenizer on dataset (num_proc=16):  51%|█████     | 512000/1000000 [00:16<00:14, 32656.63 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 516000/1000000 [00:16<00:14, 33803.60 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 520000/1000000 [00:16<00:14, 34247.99 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 524000/1000000 [00:16<00:14, 33768.70 examples/s]Running tokenizer on dataset (num_proc=16):  53%|█████▎    | 528000/1000000 [00:16<00:14, 32422.49 examples/s]Running tokenizer on dataset (num_proc=16):  53%|█████▎    | 532000/1000000 [00:16<00:13, 34330.59 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▎    | 536000/1000000 [00:16<00:13, 34074.95 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▍    | 540000/1000000 [00:16<00:13, 33701.49 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▍    | 544000/1000000 [00:17<00:13, 33157.73 examples/s]Running tokenizer on dataset (num_proc=16):  55%|█████▍    | 548000/1000000 [00:17<00:13, 34571.69 examples/s]Running tokenizer on dataset (num_proc=16):  55%|█████▌    | 552000/1000000 [00:17<00:13, 33726.23 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 556000/1000000 [00:17<00:13, 33266.78 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 560000/1000000 [00:17<00:13, 33446.75 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 564000/1000000 [00:17<00:12, 33858.79 examples/s]Running tokenizer on dataset (num_proc=16):  57%|█████▋    | 568000/1000000 [00:17<00:12, 33812.37 examples/s]Running tokenizer on dataset (num_proc=16):  57%|█████▋    | 572000/1000000 [00:17<00:12, 33143.37 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 576000/1000000 [00:18<00:12, 33168.20 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 580000/1000000 [00:18<00:12, 33549.31 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 584000/1000000 [00:18<00:12, 34250.45 examples/s]Running tokenizer on dataset (num_proc=16):  59%|█████▉    | 588000/1000000 [00:18<00:12, 32691.10 examples/s]Running tokenizer on dataset (num_proc=16):  59%|█████▉    | 592000/1000000 [00:18<00:12, 33719.05 examples/s]Running tokenizer on dataset (num_proc=16):  60%|█████▉    | 596000/1000000 [00:18<00:11, 34175.76 examples/s]Running tokenizer on dataset (num_proc=16):  60%|██████    | 600000/1000000 [00:18<00:11, 34489.78 examples/s]Running tokenizer on dataset (num_proc=16):  60%|██████    | 604000/1000000 [00:18<00:12, 32266.60 examples/s]Running tokenizer on dataset (num_proc=16):  61%|██████    | 608000/1000000 [00:19<00:11, 34208.37 examples/s]Running tokenizer on dataset (num_proc=16):  61%|██████    | 612000/1000000 [00:19<00:11, 34174.17 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 616000/1000000 [00:19<00:11, 34106.07 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 620000/1000000 [00:19<00:11, 31727.00 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▎   | 625000/1000000 [00:19<00:10, 35605.98 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 629000/1000000 [00:19<00:12, 29659.79 examples/s]Running tokenizer on dataset (num_proc=16):  64%|██████▎   | 636000/1000000 [00:19<00:11, 33074.46 examples/s]Running tokenizer on dataset (num_proc=16):  64%|██████▍   | 641000/1000000 [00:19<00:09, 36124.71 examples/s]Running tokenizer on dataset (num_proc=16):  64%|██████▍   | 645000/1000000 [00:20<00:11, 30620.56 examples/s]Running tokenizer on dataset (num_proc=16):  65%|██████▌   | 651000/1000000 [00:20<00:09, 36823.58 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▌   | 656000/1000000 [00:20<00:10, 34388.60 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▌   | 660000/1000000 [00:20<00:09, 34411.07 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▋   | 664000/1000000 [00:20<00:09, 34290.39 examples/s]Running tokenizer on dataset (num_proc=16):  67%|██████▋   | 668000/1000000 [00:20<00:10, 31453.92 examples/s]Running tokenizer on dataset (num_proc=16):  67%|██████▋   | 673000/1000000 [00:20<00:09, 35810.68 examples/s]Running tokenizer on dataset (num_proc=16):  68%|██████▊   | 677000/1000000 [00:21<00:10, 29578.64 examples/s]Running tokenizer on dataset (num_proc=16):  68%|██████▊   | 683000/1000000 [00:21<00:08, 35718.21 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 688000/1000000 [00:21<00:09, 34606.64 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 692000/1000000 [00:21<00:09, 33661.41 examples/s]Running tokenizer on dataset (num_proc=16):  70%|██████▉   | 696000/1000000 [00:21<00:08, 34080.24 examples/s]Running tokenizer on dataset (num_proc=16):  70%|███████   | 700000/1000000 [00:21<00:09, 32255.03 examples/s]Running tokenizer on dataset (num_proc=16):  70%|███████   | 705000/1000000 [00:21<00:08, 35674.29 examples/s]Running tokenizer on dataset (num_proc=16):  71%|███████   | 709000/1000000 [00:22<00:09, 29508.96 examples/s]Running tokenizer on dataset (num_proc=16):  72%|███████▏  | 715000/1000000 [00:22<00:08, 34583.59 examples/s]Running tokenizer on dataset (num_proc=16):  72%|███████▏  | 720000/1000000 [00:22<00:07, 35352.14 examples/s]Running tokenizer on dataset (num_proc=16):  72%|███████▏  | 724000/1000000 [00:22<00:08, 34011.39 examples/s]Running tokenizer on dataset (num_proc=16):  73%|███████▎  | 728000/1000000 [00:22<00:08, 33939.08 examples/s]Running tokenizer on dataset (num_proc=16):  73%|███████▎  | 732000/1000000 [00:22<00:08, 32153.43 examples/s]Running tokenizer on dataset (num_proc=16):  74%|███████▎  | 737000/1000000 [00:22<00:07, 35913.10 examples/s]Running tokenizer on dataset (num_proc=16):  74%|███████▍  | 741000/1000000 [00:23<00:08, 29675.35 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▍  | 746000/1000000 [00:23<00:07, 33396.18 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 752000/1000000 [00:23<00:06, 36669.54 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▌  | 756000/1000000 [00:23<00:07, 34155.71 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▌  | 760000/1000000 [00:23<00:06, 34289.67 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▋  | 764000/1000000 [00:23<00:07, 31664.08 examples/s]Running tokenizer on dataset (num_proc=16):  77%|███████▋  | 769000/1000000 [00:23<00:06, 35228.32 examples/s]Running tokenizer on dataset (num_proc=16):  77%|███████▋  | 773000/1000000 [00:23<00:07, 29929.08 examples/s]Running tokenizer on dataset (num_proc=16):  78%|███████▊  | 778000/1000000 [00:24<00:06, 32950.90 examples/s]Running tokenizer on dataset (num_proc=16):  78%|███████▊  | 784000/1000000 [00:24<00:05, 37719.97 examples/s]Running tokenizer on dataset (num_proc=16):  79%|███████▉  | 788000/1000000 [00:24<00:06, 33953.42 examples/s]Running tokenizer on dataset (num_proc=16):  79%|███████▉  | 792000/1000000 [00:24<00:05, 35011.54 examples/s]Running tokenizer on dataset (num_proc=16):  80%|███████▉  | 796000/1000000 [00:24<00:06, 31552.12 examples/s]Running tokenizer on dataset (num_proc=16):  80%|████████  | 801000/1000000 [00:24<00:05, 35696.76 examples/s]Running tokenizer on dataset (num_proc=16):  80%|████████  | 805000/1000000 [00:24<00:06, 29196.47 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████  | 810000/1000000 [00:25<00:05, 32421.63 examples/s]Running tokenizer on dataset (num_proc=16):  82%|████████▏ | 816000/1000000 [00:25<00:04, 38858.07 examples/s]Running tokenizer on dataset (num_proc=16):  82%|████████▏ | 821000/1000000 [00:25<00:05, 30083.97 examples/s]Running tokenizer on dataset (num_proc=16):  83%|████████▎ | 826000/1000000 [00:25<00:05, 32334.99 examples/s]Running tokenizer on dataset (num_proc=16):  83%|████████▎ | 833000/1000000 [00:25<00:04, 36850.11 examples/s]Running tokenizer on dataset (num_proc=16):  84%|████████▍ | 838000/1000000 [00:25<00:05, 32152.90 examples/s]Running tokenizer on dataset (num_proc=16):  84%|████████▍ | 842000/1000000 [00:26<00:04, 32366.18 examples/s]Running tokenizer on dataset (num_proc=16):  85%|████████▍ | 849000/1000000 [00:26<00:04, 36780.81 examples/s]Running tokenizer on dataset (num_proc=16):  85%|████████▌ | 853000/1000000 [00:26<00:04, 30370.02 examples/s]Running tokenizer on dataset (num_proc=16):  86%|████████▌ | 858000/1000000 [00:26<00:04, 32692.55 examples/s]Running tokenizer on dataset (num_proc=16):  86%|████████▋ | 865000/1000000 [00:26<00:03, 36797.14 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 869000/1000000 [00:26<00:04, 30871.49 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 874000/1000000 [00:26<00:03, 33318.30 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 881000/1000000 [00:27<00:03, 37081.98 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 885000/1000000 [00:27<00:03, 31264.35 examples/s]Running tokenizer on dataset (num_proc=16):  89%|████████▉ | 890000/1000000 [00:27<00:03, 33258.47 examples/s]Running tokenizer on dataset (num_proc=16):  90%|████████▉ | 897000/1000000 [00:27<00:02, 37199.67 examples/s]Running tokenizer on dataset (num_proc=16):  90%|█████████ | 901000/1000000 [00:27<00:03, 31209.02 examples/s]Running tokenizer on dataset (num_proc=16):  91%|█████████ | 906000/1000000 [00:27<00:02, 33285.07 examples/s]Running tokenizer on dataset (num_proc=16):  91%|█████████ | 912000/1000000 [00:28<00:02, 38890.08 examples/s]Running tokenizer on dataset (num_proc=16):  92%|█████████▏| 917000/1000000 [00:28<00:02, 30818.94 examples/s]Running tokenizer on dataset (num_proc=16):  92%|█████████▏| 922000/1000000 [00:28<00:02, 32668.04 examples/s]Running tokenizer on dataset (num_proc=16):  93%|█████████▎| 929000/1000000 [00:28<00:01, 37570.68 examples/s]Running tokenizer on dataset (num_proc=16):  93%|█████████▎| 934000/1000000 [00:28<00:02, 30854.16 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 938000/1000000 [00:28<00:01, 32446.16 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 945000/1000000 [00:28<00:01, 37896.62 examples/s]Running tokenizer on dataset (num_proc=16):  95%|█████████▌| 950000/1000000 [00:29<00:01, 30895.10 examples/s]Running tokenizer on dataset (num_proc=16):  96%|█████████▌| 955000/1000000 [00:29<00:01, 33109.34 examples/s]Running tokenizer on dataset (num_proc=16):  96%|█████████▌| 961000/1000000 [00:29<00:01, 38014.30 examples/s]Running tokenizer on dataset (num_proc=16):  97%|█████████▋| 966000/1000000 [00:29<00:01, 30803.44 examples/s]Running tokenizer on dataset (num_proc=16):  97%|█████████▋| 970000/1000000 [00:29<00:00, 32550.32 examples/s]Running tokenizer on dataset (num_proc=16):  98%|█████████▊| 976000/1000000 [00:29<00:00, 37575.92 examples/s]Running tokenizer on dataset (num_proc=16):  98%|█████████▊| 980500/1000000 [00:30<00:00, 31023.32 examples/s]Running tokenizer on dataset (num_proc=16):  99%|█████████▊| 986000/1000000 [00:30<00:00, 34916.02 examples/s]Running tokenizer on dataset (num_proc=16):  99%|█████████▉| 993000/1000000 [00:30<00:00, 39005.07 examples/s]Running tokenizer on dataset (num_proc=16): 100%|█████████▉| 997500/1000000 [00:30<00:00, 32269.48 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 1000000/1000000 [00:44<00:00, 22424.72 examples/s]
input_ids:
[1, 28705, 733, 16289, 28793, 5919, 8270, 28705, 28740, 28770, 1964, 9655, 1081, 297, 4300, 3842, 28725, 2818, 356, 272, 2296, 1871, 28747, 13, 13, 17500, 5140, 28747, 9404, 28723, 28738, 24067, 28723, 675, 28705, 13, 12075, 28747, 9166, 28718, 28723, 675, 28705, 13, 9633, 28747, 18199, 25079, 1939, 560, 8974, 294, 18199, 25079, 1939, 560, 8974, 294, 4902, 1074, 1939, 689, 5638, 547, 28705, 13, 7301, 2862, 3261, 2035, 7242, 28747, 9166, 28718, 349, 264, 3526, 5181, 10496, 486, 367, 7600, 15960, 742, 369, 5751, 12711, 286, 11282, 28723, 28705, 13, 15962, 13063, 28747, 1444, 28705, 28740, 28734, 298, 28705, 28770, 28734, 6128, 28723, 28705, 13, 733, 28748, 16289, 28793, 1964, 28747, 28760, 926, 426, 7993, 28747, 9166, 28718, 13, 3261, 28747, 28760, 4533, 18863, 297, 264, 10213, 13, 3261, 28747, 3278, 3649, 3489, 935, 1651, 661, 7940, 13, 3261, 28747, 6228, 1896, 2351, 18260, 13, 3261, 28747, 6022, 10634, 8784, 13, 3261, 28747, 28738, 614, 2455, 1343, 973, 28725, 3194, 354, 995, 13, 3261, 28747, 28749, 3616, 28742, 28713, 6375, 5111, 26909, 13, 3261, 28747, 28760, 671, 331, 3489, 13079, 2961, 13, 3261, 28747, 28738, 24067, 28747, 18945, 11210, 742, 13, 3261, 28747, 12822, 28733, 15864, 472, 438, 13091, 1921, 1214, 13, 3261, 28747, 26315, 3984, 404, 28725, 365, 4079, 11210, 742, 13, 3261, 28747, 11343, 6375, 2326, 9166, 28718, 13, 3261, 28747, 3278, 3649, 12860, 1332, 11210, 742, 13, 2]
inputs:
<s>  [INST] Please generate 13 Ad Headline in English language, based on the following information:

FinalUrl: www.Temu.com 
Domain: Temu.com 
Category: Chemicals -- Inorganic Chemicals -- Inorganic Salts -- Chloride 
DescriptionOfAdvertiser: Temu is a global platform owned by PDD Holdings that offers discounted goods. 
CharacterLimit: between 10 to 30 characters. 
 [/INST] Ad:Bargain Central: Temu
Ad:Buy Button in a Click
Ad:Discover Our Unique Items
Ad:Top Brands Available
Ad:Order Online Today
Ad:Tailored Deals, Just for You
Ad:Earth's Biggest Selection
Ad:Browse Our Collection Now
Ad:Temu: Easy Savings
Ad:High-Quality at Low Prices
Ad:Great Offers, Bigger Savings
Ad:Save Big With Temu
Ad:Discover Personalized Savings
</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1964, 28747, 28760, 926, 426, 7993, 28747, 9166, 28718, 13, 3261, 28747, 28760, 4533, 18863, 297, 264, 10213, 13, 3261, 28747, 3278, 3649, 3489, 935, 1651, 661, 7940, 13, 3261, 28747, 6228, 1896, 2351, 18260, 13, 3261, 28747, 6022, 10634, 8784, 13, 3261, 28747, 28738, 614, 2455, 1343, 973, 28725, 3194, 354, 995, 13, 3261, 28747, 28749, 3616, 28742, 28713, 6375, 5111, 26909, 13, 3261, 28747, 28760, 671, 331, 3489, 13079, 2961, 13, 3261, 28747, 28738, 24067, 28747, 18945, 11210, 742, 13, 3261, 28747, 12822, 28733, 15864, 472, 438, 13091, 1921, 1214, 13, 3261, 28747, 26315, 3984, 404, 28725, 365, 4079, 11210, 742, 13, 3261, 28747, 11343, 6375, 2326, 9166, 28718, 13, 3261, 28747, 3278, 3649, 12860, 1332, 11210, 742, 13, 2]
labels:
Ad:Bargain Central: Temu
Ad:Buy Button in a Click
Ad:Discover Our Unique Items
Ad:Top Brands Available
Ad:Order Online Today
Ad:Tailored Deals, Just for You
Ad:Earth's Biggest Selection
Ad:Browse Our Collection Now
Ad:Temu: Easy Savings
Ad:High-Quality at Low Prices
Ad:Great Offers, Bigger Savings
Ad:Save Big With Temu
Ad:Discover Personalized Savings
</s>
[INFO|configuration_utils.py:731] 2024-05-30 10:53:33,316 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/config.json
[INFO|configuration_utils.py:796] 2024-05-30 10:53:33,316 >> Model config MistralConfig {
  "_name_or_path": "/data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2",
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.0.dev0",
  "use_cache": true,
  "vocab_size": 32000
}

05/30/2024 10:53:33 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.
[INFO|quantizer_bnb_4bit.py:244] 2024-05-30 10:53:33,331 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[INFO|modeling_utils.py:3460] 2024-05-30 10:53:33,331 >> loading weights file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/model.safetensors.index.json
[INFO|modeling_utils.py:1508] 2024-05-30 10:53:33,332 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:962] 2024-05-30 10:53:33,332 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 1000/1000000 [00:00<09:14, 1802.79 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 7000/1000000 [00:00<01:15, 13178.01 examples/s]Running tokenizer on dataset (num_proc=16):   1%|▏         | 13000/1000000 [00:00<00:42, 23259.83 examples/s]Running tokenizer on dataset (num_proc=16):   2%|▏         | 18000/1000000 [00:01<00:48, 20446.65 examples/s]Running tokenizer on dataset (num_proc=16):   2%|▎         | 25000/1000000 [00:01<00:33, 29044.66 examples/s]Running tokenizer on dataset (num_proc=16):   3%|▎         | 31000/1000000 [00:01<00:27, 35432.11 examples/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Running tokenizer on dataset (num_proc=16):   4%|▎         | 36000/1000000 [00:01<00:36, 26337.07 examples/s]Running tokenizer on dataset (num_proc=16):   4%|▍         | 42000/1000000 [00:01<00:30, 31484.05 examples/s]Running tokenizer on dataset (num_proc=16):   5%|▍         | 49000/1000000 [00:01<00:33, 28521.80 examples/s]Running tokenizer on dataset (num_proc=16):   5%|▌         | 54000/1000000 [00:02<00:29, 31880.06 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▌         | 60000/1000000 [00:02<00:25, 37258.45 examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 65000/1000000 [00:02<00:31, 29257.83 examples/s]Running tokenizer on dataset (num_proc=16):   7%|▋         | 70000/1000000 [00:02<00:28, 32730.09 examples/s]Running tokenizer on dataset (num_proc=16):   8%|▊         | 76000/1000000 [00:02<00:24, 37913.15 examples/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]Running tokenizer on dataset (num_proc=16):   8%|▊         | 81000/1000000 [00:02<00:31, 29325.79 examples/s]Running tokenizer on dataset (num_proc=16):   9%|▊         | 87000/1000000 [00:03<00:26, 34017.84 examples/s]Running tokenizer on dataset (num_proc=16):   9%|▉         | 93000/1000000 [00:03<00:24, 36886.78 examples/s]Running tokenizer on dataset (num_proc=16):  10%|▉         | 98000/1000000 [00:03<00:29, 30898.13 examples/s]Running tokenizer on dataset (num_proc=16):  10%|█         | 103000/1000000 [00:03<00:26, 33937.00 examples/s]Running tokenizer on dataset (num_proc=16):  11%|█         | 108000/1000000 [00:03<00:25, 35403.28 examples/s]Running tokenizer on dataset (num_proc=16):  11%|█         | 112000/1000000 [00:03<00:27, 32227.64 examples/s]Running tokenizer on dataset (num_proc=16):  12%|█▏        | 116000/1000000 [00:03<00:28, 30712.49 examples/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.30s/it]Running tokenizer on dataset (num_proc=16):  12%|█▏        | 121000/1000000 [00:04<00:25, 33854.96 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 128000/1000000 [00:04<00:27, 31582.28 examples/s]Running tokenizer on dataset (num_proc=16):  13%|█▎        | 132000/1000000 [00:04<00:26, 32156.18 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▎        | 137000/1000000 [00:04<00:24, 35056.55 examples/s]Running tokenizer on dataset (num_proc=16):  14%|█▍        | 143000/1000000 [00:04<00:23, 37098.76 examples/s]Running tokenizer on dataset (num_proc=16):  15%|█▍        | 147000/1000000 [00:04<00:26, 32398.26 examples/s]Running tokenizer on dataset (num_proc=16):  15%|█▌        | 152000/1000000 [00:04<00:23, 36264.96 examples/s]Running tokenizer on dataset (num_proc=16):  16%|█▌        | 156000/1000000 [00:05<00:24, 35142.70 examples/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
[INFO|modeling_utils.py:4269] 2024-05-30 10:53:38,661 >> All model checkpoint weights were used when initializing MistralForCausalLM.

[INFO|modeling_utils.py:4277] 2024-05-30 10:53:38,661 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.
[INFO|configuration_utils.py:915] 2024-05-30 10:53:38,664 >> loading configuration file /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2/generation_config.json
[INFO|configuration_utils.py:962] 2024-05-30 10:53:38,664 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

05/30/2024 10:53:38 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.
05/30/2024 10:53:38 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.
05/30/2024 10:53:38 - INFO - llamafactory.model.adapter - ZeRO3/FSDP/PureBF16/BAdam detected, remaining trainable params as their original precision.
05/30/2024 10:53:38 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA
Running tokenizer on dataset (num_proc=16):  16%|█▌        | 160000/1000000 [00:05<00:28, 28996.41 examples/s]05/30/2024 10:53:38 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 7262703616 || trainable%: 0.2888
Running tokenizer on dataset (num_proc=16):  17%|█▋        | 167000/1000000 [00:05<00:24, 34575.71 examples/s][INFO|trainer.py:641] 2024-05-30 10:53:38,964 >> Using auto half precision backend
05/30/2024 10:53:38 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.
Running tokenizer on dataset (num_proc=16):  17%|█▋        | 172000/1000000 [00:05<00:22, 36027.48 examples/s]Running tokenizer on dataset (num_proc=16):  18%|█▊        | 176000/1000000 [00:05<00:27, 29727.50 examples/s]Running tokenizer on dataset (num_proc=16):  18%|█▊        | 183000/1000000 [00:05<00:23, 34974.69 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▊        | 187000/1000000 [00:06<00:22, 35799.00 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 191000/1000000 [00:06<00:25, 31873.70 examples/s]Running tokenizer on dataset (num_proc=16):  20%|█▉        | 195000/1000000 [00:06<00:25, 31955.88 examples/s]Running tokenizer on dataset (num_proc=16):  20%|██        | 201000/1000000 [00:06<00:22, 35263.71 examples/s]Running tokenizer on dataset (num_proc=16):  21%|██        | 207000/1000000 [00:06<00:24, 32670.19 examples/s]Running tokenizer on dataset (num_proc=16):  21%|██        | 211000/1000000 [00:06<00:24, 32517.15 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 216000/1000000 [00:06<00:21, 36168.57 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 220000/1000000 [00:07<00:21, 36075.16 examples/s]Running tokenizer on dataset (num_proc=16):  22%|██▏       | 224000/1000000 [00:07<00:25, 30675.38 examples/s]Running tokenizer on dataset (num_proc=16):  23%|██▎       | 229000/1000000 [00:07<00:22, 34303.28 examples/s]Running tokenizer on dataset (num_proc=16):  23%|██▎       | 233000/1000000 [00:07<00:21, 35657.14 examples/s]Running tokenizer on dataset (num_proc=16):  24%|██▍       | 238000/1000000 [00:07<00:19, 39223.34 examples/s]Running tokenizer on dataset (num_proc=16):  24%|██▍       | 243000/1000000 [00:07<00:24, 30678.14 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▍       | 248000/1000000 [00:07<00:21, 34294.28 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 253000/1000000 [00:07<00:20, 36297.30 examples/s]Running tokenizer on dataset (num_proc=16):  26%|██▌       | 257000/1000000 [00:08<00:26, 28570.22 examples/s]Running tokenizer on dataset (num_proc=16):  26%|██▋       | 264000/1000000 [00:08<00:21, 35039.38 examples/s]Running tokenizer on dataset (num_proc=16):  27%|██▋       | 269000/1000000 [00:08<00:19, 36999.19 examples/s]Running tokenizer on dataset (num_proc=16):  27%|██▋       | 274000/1000000 [00:08<00:23, 30741.19 examples/s]Running tokenizer on dataset (num_proc=16):  28%|██▊       | 280000/1000000 [00:08<00:20, 34379.43 examples/s]Running tokenizer on dataset (num_proc=16):  28%|██▊       | 285000/1000000 [00:08<00:19, 36353.29 examples/s]Running tokenizer on dataset (num_proc=16):  29%|██▉       | 289000/1000000 [00:09<00:24, 29355.25 examples/s]Running tokenizer on dataset (num_proc=16):  30%|██▉       | 296000/1000000 [00:09<00:20, 34982.15 examples/s]Running tokenizer on dataset (num_proc=16):  30%|███       | 301000/1000000 [00:09<00:19, 36271.27 examples/s]Running tokenizer on dataset (num_proc=16):  30%|███       | 305000/1000000 [00:09<00:23, 29954.56 examples/s]Running tokenizer on dataset (num_proc=16):  31%|███       | 312000/1000000 [00:09<00:19, 34623.78 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 317000/1000000 [00:09<00:18, 36705.07 examples/s]Running tokenizer on dataset (num_proc=16):  32%|███▏      | 321000/1000000 [00:10<00:22, 30484.80 examples/s]Running tokenizer on dataset (num_proc=16):  33%|███▎      | 328000/1000000 [00:10<00:19, 34136.05 examples/s]Running tokenizer on dataset (num_proc=16):  33%|███▎      | 333000/1000000 [00:10<00:18, 36626.50 examples/s]Running tokenizer on dataset (num_proc=16):  34%|███▎      | 337000/1000000 [00:10<00:21, 30617.45 examples/s]Running tokenizer on dataset (num_proc=16):  34%|███▍      | 344000/1000000 [00:10<00:19, 33795.93 examples/s]Running tokenizer on dataset (num_proc=16):  35%|███▍      | 349000/1000000 [00:10<00:17, 36496.64 examples/s]Running tokenizer on dataset (num_proc=16):  35%|███▌      | 353000/1000000 [00:11<00:20, 30889.87 examples/s]Running tokenizer on dataset (num_proc=16):  36%|███▌      | 360000/1000000 [00:11<00:18, 33870.10 examples/s]Running tokenizer on dataset (num_proc=16):  36%|███▋      | 365000/1000000 [00:11<00:17, 35526.96 examples/s]Running tokenizer on dataset (num_proc=16):  37%|███▋      | 369000/1000000 [00:11<00:20, 31287.12 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 375000/1000000 [00:11<00:16, 37021.74 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 380000/1000000 [00:11<00:17, 34535.08 examples/s]Running tokenizer on dataset (num_proc=16):  38%|███▊      | 384000/1000000 [00:11<00:19, 31981.68 examples/s]Running tokenizer on dataset (num_proc=16):  39%|███▉      | 388000/1000000 [00:12<00:19, 31024.07 examples/s]Running tokenizer on dataset (num_proc=16):  39%|███▉      | 393000/1000000 [00:12<00:17, 33765.27 examples/s]Running tokenizer on dataset (num_proc=16):  40%|███▉      | 397000/1000000 [00:12<00:17, 34490.99 examples/s]Running tokenizer on dataset (num_proc=16):  40%|████      | 401000/1000000 [00:12<00:18, 32276.85 examples/s]Running tokenizer on dataset (num_proc=16):  40%|████      | 405000/1000000 [00:12<00:17, 33535.72 examples/s]Running tokenizer on dataset (num_proc=16):  41%|████      | 409000/1000000 [00:12<00:17, 34489.40 examples/s]Running tokenizer on dataset (num_proc=16):  41%|████▏     | 413000/1000000 [00:12<00:17, 34500.75 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▏     | 417000/1000000 [00:12<00:17, 32860.80 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▏     | 421000/1000000 [00:13<00:17, 33286.77 examples/s]Running tokenizer on dataset (num_proc=16):  42%|████▎     | 425000/1000000 [00:13<00:16, 34838.75 examples/s]Running tokenizer on dataset (num_proc=16):  43%|████▎     | 429000/1000000 [00:13<00:17, 33548.02 examples/s]Running tokenizer on dataset (num_proc=16):  43%|████▎     | 433000/1000000 [00:13<00:17, 33323.90 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▎     | 437000/1000000 [00:13<00:17, 33066.61 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 441000/1000000 [00:13<00:16, 34673.72 examples/s]Running tokenizer on dataset (num_proc=16):  44%|████▍     | 445000/1000000 [00:13<00:16, 33195.83 examples/s]Running tokenizer on dataset (num_proc=16):  45%|████▍     | 449000/1000000 [00:13<00:16, 33594.54 examples/s]Running tokenizer on dataset (num_proc=16):  45%|████▌     | 453000/1000000 [00:13<00:16, 33154.46 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▌     | 457000/1000000 [00:14<00:15, 34124.16 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▌     | 461000/1000000 [00:14<00:16, 32584.00 examples/s]Running tokenizer on dataset (num_proc=16):  46%|████▋     | 465000/1000000 [00:14<00:15, 33919.50 examples/s]Running tokenizer on dataset (num_proc=16):  47%|████▋     | 469000/1000000 [00:14<00:16, 33171.60 examples/s]Running tokenizer on dataset (num_proc=16):  47%|████▋     | 473000/1000000 [00:14<00:15, 33603.62 examples/s]Running tokenizer on dataset (num_proc=16):  48%|████▊     | 477000/1000000 [00:14<00:16, 31774.30 examples/s]Running tokenizer on dataset (num_proc=16):  48%|████▊     | 482000/1000000 [00:14<00:15, 33214.99 examples/s]Running tokenizer on dataset (num_proc=16):  49%|████▊     | 487000/1000000 [00:14<00:13, 37062.68 examples/s]Running tokenizer on dataset (num_proc=16):  49%|████▉     | 491000/1000000 [00:15<00:14, 36268.83 examples/s]Running tokenizer on dataset (num_proc=16):  50%|████▉     | 495000/1000000 [00:15<00:15, 32786.45 examples/s]Running tokenizer on dataset (num_proc=16):  50%|████▉     | 499000/1000000 [00:15<00:15, 32215.56 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 504000/1000000 [00:15<00:15, 31902.28 examples/s]Running tokenizer on dataset (num_proc=16):  51%|█████     | 508000/1000000 [00:15<00:14, 33724.22 examples/s]Running tokenizer on dataset (num_proc=16):  51%|█████     | 512000/1000000 [00:15<00:14, 34817.94 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 516000/1000000 [00:15<00:14, 33565.85 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 520000/1000000 [00:15<00:14, 32034.36 examples/s]Running tokenizer on dataset (num_proc=16):  52%|█████▏    | 524000/1000000 [00:16<00:14, 33325.42 examples/s]Running tokenizer on dataset (num_proc=16):  53%|█████▎    | 528000/1000000 [00:16<00:14, 31850.94 examples/s]Running tokenizer on dataset (num_proc=16):  53%|█████▎    | 532000/1000000 [00:16<00:21, 21843.94 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▎    | 536000/1000000 [00:16<00:19, 23841.21 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▍    | 540000/1000000 [00:16<00:17, 26492.72 examples/s]Running tokenizer on dataset (num_proc=16):  54%|█████▍    | 544000/1000000 [00:16<00:15, 29312.32 examples/s]Running tokenizer on dataset (num_proc=16):  55%|█████▍    | 548000/1000000 [00:17<00:15, 29939.31 examples/s]Running tokenizer on dataset (num_proc=16):  55%|█████▌    | 552000/1000000 [00:17<00:15, 29202.71 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 556000/1000000 [00:17<00:14, 31410.69 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▌    | 560000/1000000 [00:17<00:13, 33042.39 examples/s]Running tokenizer on dataset (num_proc=16):  56%|█████▋    | 564000/1000000 [00:17<00:13, 31760.73 examples/s]Running tokenizer on dataset (num_proc=16):  57%|█████▋    | 568000/1000000 [00:17<00:13, 31085.63 examples/s]Running tokenizer on dataset (num_proc=16):  57%|█████▋    | 572000/1000000 [00:17<00:12, 33092.03 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 576000/1000000 [00:17<00:12, 34209.43 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 580000/1000000 [00:17<00:12, 33183.64 examples/s]Running tokenizer on dataset (num_proc=16):  58%|█████▊    | 584000/1000000 [00:18<00:13, 30695.94 examples/s]Running tokenizer on dataset (num_proc=16):  59%|█████▉    | 589000/1000000 [00:18<00:11, 34490.05 examples/s]Running tokenizer on dataset (num_proc=16):  59%|█████▉    | 593000/1000000 [00:18<00:11, 35160.89 examples/s]Running tokenizer on dataset (num_proc=16):  60%|█████▉    | 597000/1000000 [00:18<00:11, 35644.01 examples/s]Running tokenizer on dataset (num_proc=16):  60%|██████    | 601000/1000000 [00:18<00:12, 31244.36 examples/s]Running tokenizer on dataset (num_proc=16):  61%|██████    | 606000/1000000 [00:18<00:11, 33915.54 examples/s]Running tokenizer on dataset (num_proc=16):  61%|██████    | 611000/1000000 [00:18<00:11, 33765.63 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 615000/1000000 [00:19<00:12, 29811.91 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▏   | 621000/1000000 [00:19<00:10, 35537.81 examples/s]Running tokenizer on dataset (num_proc=16):  62%|██████▎   | 625000/1000000 [00:19<00:10, 34429.26 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 629000/1000000 [00:19<00:10, 35113.72 examples/s]Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 633000/1000000 [00:19<00:11, 31303.38 examples/s]Running tokenizer on dataset (num_proc=16):  64%|██████▍   | 638000/1000000 [00:19<00:10, 35010.97 examples/s]Running tokenizer on dataset (num_proc=16):  64%|██████▍   | 642000/1000000 [00:19<00:10, 34545.06 examples/s]Running tokenizer on dataset (num_proc=16):  65%|██████▍   | 646000/1000000 [00:19<00:10, 32483.50 examples/s]Running tokenizer on dataset (num_proc=16):  65%|██████▌   | 650000/1000000 [00:20<00:10, 32810.36 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▌   | 655000/1000000 [00:20<00:09, 34964.33 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▌   | 659000/1000000 [00:20<00:10, 33820.48 examples/s]Running tokenizer on dataset (num_proc=16):  66%|██████▋   | 663000/1000000 [00:20<00:11, 28582.39 examples/s]Running tokenizer on dataset (num_proc=16):  67%|██████▋   | 670000/1000000 [00:20<00:09, 35516.47 examples/s]Running tokenizer on dataset (num_proc=16):  67%|██████▋   | 674000/1000000 [00:20<00:09, 34564.93 examples/s]Running tokenizer on dataset (num_proc=16):  68%|██████▊   | 678000/1000000 [00:20<00:09, 32786.19 examples/s]Running tokenizer on dataset (num_proc=16):  68%|██████▊   | 682000/1000000 [00:21<00:09, 32473.81 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▊   | 687000/1000000 [00:21<00:08, 35271.97 examples/s]Running tokenizer on dataset (num_proc=16):  69%|██████▉   | 691000/1000000 [00:21<00:08, 35329.30 examples/s]Running tokenizer on dataset (num_proc=16):  70%|██████▉   | 695000/1000000 [00:21<00:10, 29349.99 examples/s]Running tokenizer on dataset (num_proc=16):  70%|███████   | 701000/1000000 [00:21<00:08, 35980.33 examples/s]Running tokenizer on dataset (num_proc=16):  70%|███████   | 705000/1000000 [00:21<00:08, 34132.85 examples/s]Running tokenizer on dataset (num_proc=16):  71%|███████   | 710000/1000000 [00:21<00:08, 32370.33 examples/s]Running tokenizer on dataset (num_proc=16):  71%|███████▏  | 714000/1000000 [00:22<00:08, 32352.04 examples/s]Running tokenizer on dataset (num_proc=16):  72%|███████▏  | 719000/1000000 [00:22<00:07, 35982.18 examples/s]Running tokenizer on dataset (num_proc=16):  72%|███████▏  | 723000/1000000 [00:22<00:07, 36040.21 examples/s]Running tokenizer on dataset (num_proc=16):  73%|███████▎  | 727000/1000000 [00:22<00:09, 28966.84 examples/s]Running tokenizer on dataset (num_proc=16):  73%|███████▎  | 734000/1000000 [00:22<00:07, 36010.58 examples/s]Running tokenizer on dataset (num_proc=16):  74%|███████▍  | 738000/1000000 [00:22<00:07, 33626.74 examples/s]Running tokenizer on dataset (num_proc=16):  74%|███████▍  | 742000/1000000 [00:22<00:07, 32352.09 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▍  | 746000/1000000 [00:22<00:07, 32163.33 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 751000/1000000 [00:23<00:06, 36234.50 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▌  | 755000/1000000 [00:23<00:06, 35172.54 examples/s]Running tokenizer on dataset (num_proc=16):  76%|███████▌  | 759000/1000000 [00:23<00:08, 28306.36 examples/s]Running tokenizer on dataset (num_proc=16):  77%|███████▋  | 766000/1000000 [00:23<00:06, 37034.09 examples/s]Running tokenizer on dataset (num_proc=16):  77%|███████▋  | 771000/1000000 [00:23<00:06, 34836.95 examples/s]Running tokenizer on dataset (num_proc=16):  78%|███████▊  | 775000/1000000 [00:23<00:07, 29153.08 examples/s]Running tokenizer on dataset (num_proc=16):  78%|███████▊  | 782000/1000000 [00:23<00:05, 37082.80 examples/s]Running tokenizer on dataset (num_proc=16):  79%|███████▊  | 787000/1000000 [00:24<00:06, 34862.34 examples/s]Running tokenizer on dataset (num_proc=16):  79%|███████▉  | 791000/1000000 [00:24<00:07, 29441.43 examples/s]Running tokenizer on dataset (num_proc=16):  80%|███████▉  | 798000/1000000 [00:24<00:05, 37276.60 examples/s]Running tokenizer on dataset (num_proc=16):  80%|████████  | 803000/1000000 [00:24<00:05, 34800.22 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████  | 807000/1000000 [00:24<00:06, 29216.35 examples/s]Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 814000/1000000 [00:24<00:05, 37161.90 examples/s]Running tokenizer on dataset (num_proc=16):  82%|████████▏ | 819000/1000000 [00:25<00:05, 34895.23 examples/s]Running tokenizer on dataset (num_proc=16):  82%|████████▏ | 823000/1000000 [00:25<00:06, 29206.10 examples/s]Running tokenizer on dataset (num_proc=16):  83%|████████▎ | 830000/1000000 [00:25<00:04, 37316.46 examples/s]Running tokenizer on dataset (num_proc=16):  84%|████████▎ | 835000/1000000 [00:25<00:04, 34785.17 examples/s]Running tokenizer on dataset (num_proc=16):  84%|████████▍ | 839000/1000000 [00:25<00:05, 29287.98 examples/s]Running tokenizer on dataset (num_proc=16):  85%|████████▍ | 846000/1000000 [00:25<00:04, 36932.92 examples/s]Running tokenizer on dataset (num_proc=16):  85%|████████▌ | 851000/1000000 [00:26<00:04, 34721.24 examples/s]Running tokenizer on dataset (num_proc=16):  86%|████████▌ | 855000/1000000 [00:26<00:05, 28938.27 examples/s]Running tokenizer on dataset (num_proc=16):  86%|████████▌ | 861000/1000000 [00:26<00:03, 35001.67 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 866000/1000000 [00:26<00:03, 34737.85 examples/s]Running tokenizer on dataset (num_proc=16):  87%|████████▋ | 870000/1000000 [00:26<00:04, 30520.18 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 875000/1000000 [00:26<00:03, 34260.73 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 880000/1000000 [00:26<00:03, 37865.17 examples/s]Running tokenizer on dataset (num_proc=16):  88%|████████▊ | 885000/1000000 [00:27<00:03, 34806.00 examples/s]Running tokenizer on dataset (num_proc=16):  89%|████████▉ | 889000/1000000 [00:27<00:03, 30048.19 examples/s]Running tokenizer on dataset (num_proc=16):  90%|████████▉ | 896000/1000000 [00:27<00:02, 37321.13 examples/s]Running tokenizer on dataset (num_proc=16):  90%|█████████ | 901000/1000000 [00:27<00:02, 34553.14 examples/s]Running tokenizer on dataset (num_proc=16):  90%|█████████ | 905000/1000000 [00:27<00:03, 30120.78 examples/s]Running tokenizer on dataset (num_proc=16):  91%|█████████ | 912000/1000000 [00:27<00:02, 36566.33 examples/s]Running tokenizer on dataset (num_proc=16):  92%|█████████▏| 916000/1000000 [00:27<00:02, 35857.86 examples/s]Running tokenizer on dataset (num_proc=16):  92%|█████████▏| 920000/1000000 [00:28<00:02, 28642.90 examples/s]Running tokenizer on dataset (num_proc=16):  93%|█████████▎| 926000/1000000 [00:28<00:02, 35021.45 examples/s]Running tokenizer on dataset (num_proc=16):  93%|█████████▎| 931000/1000000 [00:28<00:01, 36113.85 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▎| 935000/1000000 [00:28<00:02, 29196.36 examples/s]Running tokenizer on dataset (num_proc=16):  94%|█████████▍| 940000/1000000 [00:28<00:01, 33134.66 examples/s]Running tokenizer on dataset (num_proc=16):  95%|█████████▍| 946000/1000000 [00:28<00:01, 35205.82 examples/s]Running tokenizer on dataset (num_proc=16):  95%|█████████▌| 950000/1000000 [00:29<00:01, 29839.54 examples/s]Running tokenizer on dataset (num_proc=16):  96%|█████████▌| 956000/1000000 [00:29<00:01, 34475.32 examples/s]Running tokenizer on dataset (num_proc=16):  96%|█████████▌| 962000/1000000 [00:29<00:01, 36082.59 examples/s]Running tokenizer on dataset (num_proc=16):  97%|█████████▋| 966000/1000000 [00:29<00:01, 30041.13 examples/s]Running tokenizer on dataset (num_proc=16):  97%|█████████▋| 972000/1000000 [00:29<00:00, 34848.72 examples/s]Running tokenizer on dataset (num_proc=16):  98%|█████████▊| 977000/1000000 [00:29<00:00, 38178.21 examples/s]Running tokenizer on dataset (num_proc=16):  98%|█████████▊| 981500/1000000 [00:29<00:00, 36084.84 examples/s]Running tokenizer on dataset (num_proc=16):  99%|█████████▊| 985500/1000000 [00:30<00:00, 32657.07 examples/s]Running tokenizer on dataset (num_proc=16):  99%|█████████▉| 990500/1000000 [00:30<00:00, 36001.66 examples/s]Running tokenizer on dataset (num_proc=16): 100%|█████████▉| 995000/1000000 [00:30<00:00, 36167.11 examples/s]Running tokenizer on dataset (num_proc=16): 100%|█████████▉| 999000/1000000 [00:30<00:00, 32275.95 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 1000000/1000000 [00:44<00:00, 22401.09 examples/s]
05/30/2024 10:54:18 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]
05/30/2024 10:54:23 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.
05/30/2024 10:54:23 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.
05/30/2024 10:54:23 - INFO - llamafactory.model.adapter - ZeRO3/FSDP/PureBF16/BAdam detected, remaining trainable params as their original precision.
05/30/2024 10:54:23 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA
05/30/2024 10:54:23 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 7262703616 || trainable%: 0.2888
[INFO|trainer.py:2078] 2024-05-30 10:54:25,361 >> ***** Running training *****
[INFO|trainer.py:2079] 2024-05-30 10:54:25,361 >>   Num examples = 995,000
[INFO|trainer.py:2080] 2024-05-30 10:54:25,361 >>   Num Epochs = 1
[INFO|trainer.py:2081] 2024-05-30 10:54:25,361 >>   Instantaneous batch size per device = 24
[INFO|trainer.py:2084] 2024-05-30 10:54:25,361 >>   Total train batch size (w. parallel, distributed & accumulation) = 96
[INFO|trainer.py:2085] 2024-05-30 10:54:25,361 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:2086] 2024-05-30 10:54:25,361 >>   Total optimization steps = 10,365
[INFO|trainer.py:2087] 2024-05-30 10:54:25,364 >>   Number of trainable parameters = 10,485,760
  0%|          | 0/10365 [00:00<?, ?it/s]  0%|          | 1/10365 [00:22<63:44:41, 22.14s/it]  0%|          | 2/10365 [00:41<59:44:18, 20.75s/it]  0%|          | 3/10365 [01:03<60:43:07, 21.10s/it]  0%|          | 4/10365 [01:31<68:29:01, 23.80s/it]  0%|          | 5/10365 [01:55<68:41:15, 23.87s/it]  0%|          | 6/10365 [02:21<70:53:43, 24.64s/it]  0%|          | 7/10365 [02:41<66:29:01, 23.11s/it]  0%|          | 8/10365 [02:58<60:58:16, 21.19s/it]  0%|          | 9/10365 [03:19<60:41:37, 21.10s/it]  0%|          | 10/10365 [03:36<56:50:03, 19.76s/it]                                                     {'loss': 2.8517, 'grad_norm': 1.34375, 'learning_rate': 9.999977489788032e-05, 'epoch': 0.0}
  0%|          | 10/10365 [03:36<56:50:03, 19.76s/it]  0%|          | 11/10365 [03:56<57:37:22, 20.04s/it]  0%|          | 12/10365 [04:13<54:20:44, 18.90s/it]  0%|          | 13/10365 [04:38<59:46:16, 20.79s/it]  0%|          | 14/10365 [05:00<60:58:13, 21.21s/it]  0%|          | 15/10365 [05:17<57:39:09, 20.05s/it]  0%|          | 16/10365 [05:42<61:16:22, 21.31s/it]  0%|          | 17/10365 [06:10<67:06:58, 23.35s/it]  0%|          | 18/10365 [06:29<63:55:57, 22.24s/it]  0%|          | 19/10365 [06:55<66:36:46, 23.18s/it]  0%|          | 20/10365 [07:21<69:09:11, 24.06s/it]                                                     {'loss': 1.5819, 'grad_norm': 0.95703125, 'learning_rate': 9.999909047559384e-05, 'epoch': 0.0}
  0%|          | 20/10365 [07:21<69:09:11, 24.06s/it]  0%|          | 21/10365 [07:37<62:19:42, 21.69s/it]  0%|          | 22/10365 [07:57<61:01:41, 21.24s/it]  0%|          | 23/10365 [08:18<60:36:52, 21.10s/it]  0%|          | 24/10365 [08:40<61:10:28, 21.30s/it]  0%|          | 25/10365 [09:00<60:41:56, 21.13s/it]  0%|          | 26/10365 [09:21<59:47:23, 20.82s/it]  0%|          | 27/10365 [09:37<56:24:44, 19.64s/it]  0%|          | 28/10365 [09:59<57:40:41, 20.09s/it]  0%|          | 29/10365 [10:17<56:23:00, 19.64s/it]  0%|          | 30/10365 [10:40<58:50:39, 20.50s/it]                                                     {'loss': 1.488, 'grad_norm': 0.9453125, 'learning_rate': 9.999794671646106e-05, 'epoch': 0.0}
  0%|          | 30/10365 [10:40<58:50:39, 20.50s/it]  0%|          | 31/10365 [11:00<58:40:31, 20.44s/it]  0%|          | 32/10365 [11:25<62:16:35, 21.70s/it]  0%|          | 33/10365 [11:47<62:29:41, 21.78s/it]  0%|          | 34/10365 [12:04<58:39:06, 20.44s/it]  0%|          | 35/10365 [12:26<59:45:42, 20.83s/it]  0%|          | 36/10365 [12:46<59:19:05, 20.67s/it]  0%|          | 37/10365 [13:06<58:35:45, 20.42s/it]  0%|          | 38/10365 [13:24<57:08:05, 19.92s/it]  0%|          | 39/10365 [13:40<53:40:56, 18.72s/it]  0%|          | 40/10365 [14:03<57:19:11, 19.99s/it]                                                     {'loss': 1.5019, 'grad_norm': 0.875, 'learning_rate': 9.999634363098953e-05, 'epoch': 0.0}
  0%|          | 40/10365 [14:03<57:19:11, 19.99s/it]  0%|          | 41/10365 [14:24<57:40:38, 20.11s/it]  0%|          | 42/10365 [14:42<56:18:02, 19.63s/it]  0%|          | 43/10365 [15:05<59:00:17, 20.58s/it]  0%|          | 44/10365 [15:26<59:36:08, 20.79s/it]  0%|          | 45/10365 [15:49<60:50:49, 21.23s/it]  0%|          | 46/10365 [16:07<58:10:13, 20.29s/it]  0%|          | 47/10365 [16:26<57:18:13, 19.99s/it]  0%|          | 48/10365 [16:47<57:59:45, 20.24s/it]  0%|          | 49/10365 [17:07<58:20:08, 20.36s/it]  0%|          | 50/10365 [17:32<62:09:46, 21.70s/it]                                                     {'loss': 1.4754, 'grad_norm': 0.7890625, 'learning_rate': 9.999428123390668e-05, 'epoch': 0.0}
  0%|          | 50/10365 [17:32<62:09:46, 21.70s/it]  0%|          | 51/10365 [17:57<64:49:46, 22.63s/it]  1%|          | 52/10365 [18:18<63:11:59, 22.06s/it]  1%|          | 53/10365 [18:39<62:45:29, 21.91s/it]  1%|          | 54/10365 [18:59<61:01:33, 21.31s/it]  1%|          | 55/10365 [19:18<59:01:00, 20.61s/it]  1%|          | 56/10365 [19:37<57:16:26, 20.00s/it]  1%|          | 57/10365 [19:57<57:16:53, 20.01s/it]  1%|          | 58/10365 [20:12<52:45:09, 18.43s/it]  1%|          | 59/10365 [20:29<52:04:17, 18.19s/it]  1%|          | 60/10365 [20:50<54:05:50, 18.90s/it]                                                     {'loss': 1.4493, 'grad_norm': 0.9765625, 'learning_rate': 9.999175954415954e-05, 'epoch': 0.01}
  1%|          | 60/10365 [20:50<54:05:50, 18.90s/it]  1%|          | 61/10365 [21:10<55:37:18, 19.43s/it]  1%|          | 62/10365 [21:30<56:03:15, 19.59s/it]  1%|          | 63/10365 [21:51<56:52:19, 19.87s/it]  1%|          | 64/10365 [22:10<56:23:44, 19.71s/it]  1%|          | 65/10365 [22:32<57:48:23, 20.20s/it]  1%|          | 66/10365 [22:49<55:14:07, 19.31s/it]  1%|          | 67/10365 [23:08<55:05:41, 19.26s/it]  1%|          | 68/10365 [23:28<55:54:56, 19.55s/it]  1%|          | 69/10365 [23:51<59:01:32, 20.64s/it]  1%|          | 70/10365 [24:15<61:46:49, 21.60s/it]                                                     {'loss': 1.4348, 'grad_norm': 0.86328125, 'learning_rate': 9.998877858491463e-05, 'epoch': 0.01}
  1%|          | 70/10365 [24:15<61:46:49, 21.60s/it]  1%|          | 71/10365 [24:38<62:48:29, 21.97s/it]  1%|          | 72/10365 [24:56<59:29:46, 20.81s/it]  1%|          | 73/10365 [25:23<64:16:47, 22.48s/it]  1%|          | 74/10365 [25:45<64:27:52, 22.55s/it]  1%|          | 75/10365 [26:01<58:28:02, 20.46s/it]  1%|          | 76/10365 [26:24<60:41:52, 21.24s/it]  1%|          | 77/10365 [26:50<64:35:38, 22.60s/it]  1%|          | 78/10365 [27:12<64:14:43, 22.48s/it]  1%|          | 79/10365 [27:33<63:20:19, 22.17s/it]  1%|          | 80/10365 [27:54<62:16:21, 21.80s/it]                                                     {'loss': 1.3993, 'grad_norm': 0.8984375, 'learning_rate': 9.998533838355775e-05, 'epoch': 0.01}
  1%|          | 80/10365 [27:54<62:16:21, 21.80s/it]  1%|          | 81/10365 [28:13<59:54:17, 20.97s/it]  1%|          | 82/10365 [28:31<56:55:06, 19.93s/it]  1%|          | 83/10365 [28:52<57:45:21, 20.22s/it]  1%|          | 84/10365 [29:11<56:40:48, 19.85s/it]  1%|          | 85/10365 [29:28<54:23:11, 19.05s/it]  1%|          | 86/10365 [29:47<54:45:36, 19.18s/it]  1%|          | 87/10365 [30:15<61:42:21, 21.61s/it]  1%|          | 88/10365 [30:34<59:31:42, 20.85s/it]  1%|          | 89/10365 [30:58<62:31:01, 21.90s/it]  1%|          | 90/10365 [31:18<60:28:38, 21.19s/it]                                                     {'loss': 1.3902, 'grad_norm': 0.8671875, 'learning_rate': 9.998143897169367e-05, 'epoch': 0.01}
  1%|          | 90/10365 [31:18<60:28:38, 21.19s/it]  1%|          | 91/10365 [31:36<58:24:15, 20.46s/it]  1%|          | 92/10365 [31:59<59:53:37, 20.99s/it]  1%|          | 93/10365 [32:18<58:57:51, 20.67s/it]  1%|          | 94/10365 [32:43<62:26:46, 21.89s/it]  1%|          | 95/10365 [32:59<57:10:01, 20.04s/it]  1%|          | 96/10365 [33:18<56:04:57, 19.66s/it]  1%|          | 97/10365 [33:38<56:41:20, 19.88s/it]  1%|          | 98/10365 [33:58<56:48:55, 19.92s/it]  1%|          | 99/10365 [34:21<58:57:44, 20.68s/it]  1%|          | 100/10365 [34:44<60:54:47, 21.36s/it]                                                      {'loss': 1.3833, 'grad_norm': 1.0703125, 'learning_rate': 9.997708038514595e-05, 'epoch': 0.01}
  1%|          | 100/10365 [34:44<60:54:47, 21.36s/it]  1%|          | 101/10365 [35:06<61:40:28, 21.63s/it]  1%|          | 102/10365 [35:28<62:03:54, 21.77s/it]  1%|          | 103/10365 [35:48<60:44:51, 21.31s/it]  1%|          | 104/10365 [36:07<58:56:22, 20.68s/it]  1%|          | 105/10365 [36:24<55:20:26, 19.42s/it]  1%|          | 106/10365 [36:48<59:09:00, 20.76s/it]  1%|          | 107/10365 [37:06<56:44:13, 19.91s/it]  1%|          | 108/10365 [37:26<57:18:30, 20.11s/it]  1%|          | 109/10365 [37:48<58:23:20, 20.50s/it]  1%|          | 110/10365 [38:10<60:12:44, 21.14s/it]                                                      {'loss': 1.4088, 'grad_norm': 0.94140625, 'learning_rate': 9.99722626639565e-05, 'epoch': 0.01}
  1%|          | 110/10365 [38:10<60:12:44, 21.14s/it]  1%|          | 111/10365 [38:30<58:54:23, 20.68s/it]  1%|          | 112/10365 [38:54<62:01:02, 21.78s/it]  1%|          | 113/10365 [39:15<61:23:52, 21.56s/it]  1%|          | 114/10365 [39:35<60:06:18, 21.11s/it]  1%|          | 115/10365 [39:55<59:20:24, 20.84s/it]  1%|          | 116/10365 [40:19<61:12:49, 21.50s/it]  1%|          | 117/10365 [40:36<57:41:02, 20.26s/it]  1%|          | 118/10365 [41:03<63:13:34, 22.21s/it]  1%|          | 119/10365 [41:24<62:24:47, 21.93s/it]  1%|          | 120/10365 [41:41<58:27:15, 20.54s/it]                                                      {'loss': 1.3793, 'grad_norm': 0.91796875, 'learning_rate': 9.996698585238523e-05, 'epoch': 0.01}
  1%|          | 120/10365 [41:41<58:27:15, 20.54s/it]  1%|          | 121/10365 [41:58<54:55:03, 19.30s/it]  1%|          | 122/10365 [42:19<56:51:06, 19.98s/it]  1%|          | 123/10365 [42:39<56:52:47, 19.99s/it]  1%|          | 124/10365 [42:59<56:55:30, 20.01s/it]  1%|          | 125/10365 [43:22<59:14:51, 20.83s/it]  1%|          | 126/10365 [43:48<63:16:09, 22.25s/it]  1%|          | 127/10365 [44:08<61:23:34, 21.59s/it]  1%|          | 128/10365 [44:30<61:55:17, 21.78s/it]  1%|          | 129/10365 [44:49<59:40:35, 20.99s/it]  1%|▏         | 130/10365 [45:13<62:24:48, 21.95s/it]                                                      {'loss': 1.3824, 'grad_norm': 0.95703125, 'learning_rate': 9.996124999890972e-05, 'epoch': 0.01}
  1%|▏         | 130/10365 [45:13<62:24:48, 21.95s/it]  1%|▏         | 131/10365 [45:33<60:56:22, 21.44s/it]  1%|▏         | 132/10365 [45:56<62:18:18, 21.92s/it]  1%|▏         | 133/10365 [46:21<64:48:10, 22.80s/it]  1%|▏         | 134/10365 [46:45<65:27:02, 23.03s/it]  1%|▏         | 135/10365 [47:10<67:36:44, 23.79s/it]  1%|▏         | 136/10365 [47:34<67:19:39, 23.70s/it]  1%|▏         | 137/10365 [47:57<66:27:59, 23.39s/it]  1%|▏         | 138/10365 [48:16<63:22:31, 22.31s/it]  1%|▏         | 139/10365 [48:38<62:20:56, 21.95s/it]  1%|▏         | 140/10365 [48:59<61:55:47, 21.80s/it]                                                      {'loss': 1.3446, 'grad_norm': 0.90625, 'learning_rate': 9.995505515622472e-05, 'epoch': 0.01}
  1%|▏         | 140/10365 [48:59<61:55:47, 21.80s/it]  1%|▏         | 141/10365 [49:27<66:58:15, 23.58s/it]  1%|▏         | 142/10365 [49:48<65:10:14, 22.95s/it]  1%|▏         | 143/10365 [50:03<58:38:16, 20.65s/it]  1%|▏         | 144/10365 [50:24<58:15:19, 20.52s/it]  1%|▏         | 145/10365 [50:44<57:57:41, 20.42s/it]  1%|▏         | 146/10365 [51:04<57:45:11, 20.35s/it]  1%|▏         | 147/10365 [51:28<61:04:30, 21.52s/it]  1%|▏         | 148/10365 [51:49<60:37:53, 21.36s/it]  1%|▏         | 149/10365 [52:09<59:26:00, 20.94s/it]  1%|▏         | 150/10365 [52:34<62:56:40, 22.18s/it]                                                      {'loss': 1.3273, 'grad_norm': 0.94140625, 'learning_rate': 9.994840138124164e-05, 'epoch': 0.01}
  1%|▏         | 150/10365 [52:34<62:56:40, 22.18s/it]  1%|▏         | 151/10365 [52:56<62:43:18, 22.11s/it]  1%|▏         | 152/10365 [53:18<62:07:17, 21.90s/it]  1%|▏         | 153/10365 [53:38<60:23:43, 21.29s/it]  1%|▏         | 154/10365 [54:01<62:19:15, 21.97s/it]  1%|▏         | 155/10365 [54:20<60:05:31, 21.19s/it]  2%|▏         | 156/10365 [54:40<58:54:05, 20.77s/it]  2%|▏         | 157/10365 [55:03<60:32:22, 21.35s/it]  2%|▏         | 158/10365 [55:24<60:21:06, 21.29s/it]  2%|▏         | 159/10365 [55:46<60:49:05, 21.45s/it]  2%|▏         | 160/10365 [56:08<60:55:12, 21.49s/it]                                                      {'loss': 1.3339, 'grad_norm': 0.94140625, 'learning_rate': 9.994128873508808e-05, 'epoch': 0.02}
  2%|▏         | 160/10365 [56:08<60:55:12, 21.49s/it]  2%|▏         | 161/10365 [56:30<61:51:02, 21.82s/it]  2%|▏         | 162/10365 [56:47<57:46:55, 20.39s/it]  2%|▏         | 163/10365 [57:16<65:17:46, 23.04s/it]  2%|▏         | 164/10365 [57:36<61:59:01, 21.87s/it]  2%|▏         | 165/10365 [57:58<62:40:32, 22.12s/it]  2%|▏         | 166/10365 [58:15<57:49:52, 20.41s/it]  2%|▏         | 167/10365 [58:31<54:15:33, 19.15s/it]  2%|▏         | 168/10365 [58:53<56:25:52, 19.92s/it]  2%|▏         | 169/10365 [59:14<57:26:29, 20.28s/it]  2%|▏         | 170/10365 [59:33<56:16:23, 19.87s/it]                                                      {'loss': 1.3491, 'grad_norm': 1.0078125, 'learning_rate': 9.993371728310723e-05, 'epoch': 0.02}
  2%|▏         | 170/10365 [59:33<56:16:23, 19.87s/it]  2%|▏         | 171/10365 [59:56<59:08:49, 20.89s/it]  2%|▏         | 172/10365 [1:00:14<56:45:33, 20.05s/it]  2%|▏         | 173/10365 [1:00:40<61:59:24, 21.90s/it]  2%|▏         | 174/10365 [1:00:59<59:27:26, 21.00s/it]  2%|▏         | 175/10365 [1:01:16<56:10:03, 19.84s/it]  2%|▏         | 176/10365 [1:01:35<54:51:42, 19.38s/it]  2%|▏         | 177/10365 [1:01:55<55:34:07, 19.64s/it]  2%|▏         | 178/10365 [1:02:14<55:32:07, 19.63s/it]  2%|▏         | 179/10365 [1:02:39<59:39:12, 21.08s/it]  2%|▏         | 180/10365 [1:03:02<61:24:39, 21.71s/it]                                                        {'loss': 1.342, 'grad_norm': 0.9140625, 'learning_rate': 9.992568709485729e-05, 'epoch': 0.02}
  2%|▏         | 180/10365 [1:03:02<61:24:39, 21.71s/it]  2%|▏         | 181/10365 [1:03:26<63:31:11, 22.45s/it]  2%|▏         | 182/10365 [1:03:47<62:10:12, 21.98s/it]  2%|▏         | 183/10365 [1:04:08<60:56:44, 21.55s/it]  2%|▏         | 184/10365 [1:04:28<60:20:34, 21.34s/it]  2%|▏         | 185/10365 [1:04:56<65:23:05, 23.12s/it]  2%|▏         | 186/10365 [1:05:14<60:52:52, 21.53s/it]  2%|▏         | 187/10365 [1:05:28<55:03:58, 19.48s/it]  2%|▏         | 188/10365 [1:05:51<57:36:26, 20.38s/it]  2%|▏         | 189/10365 [1:06:16<61:33:16, 21.78s/it]  2%|▏         | 190/10365 [1:06:43<66:07:51, 23.40s/it]                                                        {'loss': 1.3217, 'grad_norm': 0.8515625, 'learning_rate': 9.991719824411084e-05, 'epoch': 0.02}
  2%|▏         | 190/10365 [1:06:43<66:07:51, 23.40s/it]  2%|▏         | 191/10365 [1:07:03<62:53:57, 22.26s/it]  2%|▏         | 192/10365 [1:07:24<62:24:53, 22.09s/it]  2%|▏         | 193/10365 [1:07:40<56:52:42, 20.13s/it]  2%|▏         | 194/10365 [1:07:59<56:26:23, 19.98s/it]  2%|▏         | 195/10365 [1:08:21<57:59:34, 20.53s/it]  2%|▏         | 196/10365 [1:08:40<56:26:28, 19.98s/it]  2%|▏         | 197/10365 [1:09:03<58:45:56, 20.81s/it]  2%|▏         | 198/10365 [1:09:24<59:23:11, 21.03s/it]  2%|▏         | 199/10365 [1:09:47<60:39:26, 21.48s/it]  2%|▏         | 200/10365 [1:10:08<60:28:43, 21.42s/it]                                                        {'loss': 1.3352, 'grad_norm': 0.9453125, 'learning_rate': 9.990825080885413e-05, 'epoch': 0.02}
  2%|▏         | 200/10365 [1:10:08<60:28:43, 21.42s/it]  2%|▏         | 201/10365 [1:10:27<58:30:29, 20.72s/it]  2%|▏         | 202/10365 [1:10:53<62:40:24, 22.20s/it]  2%|▏         | 203/10365 [1:11:13<60:39:07, 21.49s/it]  2%|▏         | 204/10365 [1:11:38<64:10:30, 22.74s/it]  2%|▏         | 205/10365 [1:11:57<60:24:59, 21.41s/it]  2%|▏         | 206/10365 [1:12:14<57:16:01, 20.29s/it]  2%|▏         | 207/10365 [1:12:44<65:13:00, 23.11s/it]  2%|▏         | 208/10365 [1:13:04<62:38:01, 22.20s/it]  2%|▏         | 209/10365 [1:13:25<61:53:54, 21.94s/it]  2%|▏         | 210/10365 [1:13:54<67:09:55, 23.81s/it]                                                        {'loss': 1.3286, 'grad_norm': 0.90234375, 'learning_rate': 9.98988448712864e-05, 'epoch': 0.02}
  2%|▏         | 210/10365 [1:13:54<67:09:55, 23.81s/it]  2%|▏         | 211/10365 [1:14:16<66:08:39, 23.45s/it]  2%|▏         | 212/10365 [1:14:34<61:37:04, 21.85s/it]  2%|▏         | 213/10365 [1:14:56<61:36:31, 21.85s/it]  2%|▏         | 214/10365 [1:15:17<60:43:37, 21.54s/it]  2%|▏         | 215/10365 [1:15:38<60:12:42, 21.36s/it]  2%|▏         | 216/10365 [1:15:54<55:45:13, 19.78s/it]  2%|▏         | 217/10365 [1:16:13<55:27:56, 19.68s/it]  2%|▏         | 218/10365 [1:16:36<57:34:56, 20.43s/it]  2%|▏         | 219/10365 [1:16:54<55:28:44, 19.69s/it]  2%|▏         | 220/10365 [1:17:10<53:06:04, 18.84s/it]                                                        {'loss': 1.296, 'grad_norm': 0.9296875, 'learning_rate': 9.988898051781908e-05, 'epoch': 0.02}
  2%|▏         | 220/10365 [1:17:10<53:06:04, 18.84s/it]  2%|▏         | 221/10365 [1:17:40<61:48:06, 21.93s/it]  2%|▏         | 222/10365 [1:17:58<58:46:18, 20.86s/it]  2%|▏         | 223/10365 [1:18:19<59:22:02, 21.07s/it]  2%|▏         | 224/10365 [1:18:34<53:53:04, 19.13s/it]  2%|▏         | 225/10365 [1:18:57<56:58:50, 20.23s/it]  2%|▏         | 226/10365 [1:19:19<58:50:11, 20.89s/it]  2%|▏         | 227/10365 [1:19:44<61:41:23, 21.91s/it]  2%|▏         | 228/10365 [1:19:59<55:54:54, 19.86s/it]  2%|▏         | 229/10365 [1:20:23<59:35:00, 21.16s/it]  2%|▏         | 230/10365 [1:20:49<63:43:48, 22.64s/it]                                                        {'loss': 1.3157, 'grad_norm': 0.9140625, 'learning_rate': 9.987865783907504e-05, 'epoch': 0.02}
  2%|▏         | 230/10365 [1:20:49<63:43:48, 22.64s/it]  2%|▏         | 231/10365 [1:21:11<63:33:41, 22.58s/it]  2%|▏         | 232/10365 [1:21:28<58:47:02, 20.88s/it]  2%|▏         | 233/10365 [1:21:52<60:44:20, 21.58s/it]  2%|▏         | 234/10365 [1:22:11<58:34:42, 20.82s/it]  2%|▏         | 235/10365 [1:22:29<56:57:27, 20.24s/it]  2%|▏         | 236/10365 [1:22:52<58:33:45, 20.81s/it]  2%|▏         | 237/10365 [1:23:11<57:11:27, 20.33s/it]  2%|▏         | 238/10365 [1:23:34<59:54:25, 21.30s/it]  2%|▏         | 239/10365 [1:23:53<57:22:18, 20.40s/it]  2%|▏         | 240/10365 [1:24:12<56:27:03, 20.07s/it]                                                        {'loss': 1.2969, 'grad_norm': 0.8828125, 'learning_rate': 9.986787692988775e-05, 'epoch': 0.02}
  2%|▏         | 240/10365 [1:24:12<56:27:03, 20.07s/it]  2%|▏         | 241/10365 [1:24:30<54:18:49, 19.31s/it]  2%|▏         | 242/10365 [1:24:52<56:34:52, 20.12s/it]  2%|▏         | 243/10365 [1:25:15<59:44:37, 21.25s/it]  2%|▏         | 244/10365 [1:25:34<57:44:45, 20.54s/it]  2%|▏         | 245/10365 [1:25:57<59:55:59, 21.32s/it]  2%|▏         | 246/10365 [1:26:19<60:24:39, 21.49s/it]  2%|▏         | 247/10365 [1:26:36<56:27:08, 20.09s/it]  2%|▏         | 248/10365 [1:27:01<60:07:30, 21.39s/it]  2%|▏         | 249/10365 [1:27:20<58:51:56, 20.95s/it]  2%|▏         | 250/10365 [1:27:41<58:36:07, 20.86s/it]                                                        {'loss': 1.29, 'grad_norm': 0.9765625, 'learning_rate': 9.985663788930038e-05, 'epoch': 0.02}
  2%|▏         | 250/10365 [1:27:41<58:36:07, 20.86s/it]  2%|▏         | 251/10365 [1:28:03<59:02:58, 21.02s/it]  2%|▏         | 252/10365 [1:28:26<61:04:36, 21.74s/it]  2%|▏         | 253/10365 [1:28:46<59:26:33, 21.16s/it]  2%|▏         | 254/10365 [1:29:07<59:16:13, 21.10s/it]  2%|▏         | 255/10365 [1:29:28<59:37:25, 21.23s/it]  2%|▏         | 256/10365 [1:29:52<61:20:24, 21.84s/it]  2%|▏         | 257/10365 [1:30:15<62:31:38, 22.27s/it]  2%|▏         | 258/10365 [1:30:38<63:44:11, 22.70s/it]  2%|▏         | 259/10365 [1:31:01<63:51:06, 22.75s/it]  3%|▎         | 260/10365 [1:31:20<60:48:59, 21.67s/it]                                                        {'loss': 1.3153, 'grad_norm': 0.99609375, 'learning_rate': 9.984494082056493e-05, 'epoch': 0.03}
  3%|▎         | 260/10365 [1:31:20<60:48:59, 21.67s/it]  3%|▎         | 261/10365 [1:31:41<59:39:27, 21.26s/it]  3%|▎         | 262/10365 [1:32:07<64:00:34, 22.81s/it]  3%|▎         | 263/10365 [1:32:30<64:18:39, 22.92s/it]  3%|▎         | 264/10365 [1:32:55<65:42:10, 23.42s/it]  3%|▎         | 265/10365 [1:33:15<63:14:11, 22.54s/it]  3%|▎         | 266/10365 [1:33:34<60:00:10, 21.39s/it]  3%|▎         | 267/10365 [1:33:53<57:29:10, 20.49s/it]  3%|▎         | 268/10365 [1:34:13<57:35:24, 20.53s/it]  3%|▎         | 269/10365 [1:34:36<59:47:34, 21.32s/it]  3%|▎         | 270/10365 [1:34:55<57:22:16, 20.46s/it]                                                        {'loss': 1.2845, 'grad_norm': 0.95703125, 'learning_rate': 9.983278583114124e-05, 'epoch': 0.03}
  3%|▎         | 270/10365 [1:34:55<57:22:16, 20.46s/it]  3%|▎         | 271/10365 [1:35:15<57:04:29, 20.36s/it]  3%|▎         | 272/10365 [1:35:34<56:21:27, 20.10s/it]  3%|▎         | 273/10365 [1:35:56<57:20:37, 20.46s/it]  3%|▎         | 274/10365 [1:36:17<58:17:56, 20.80s/it]  3%|▎         | 275/10365 [1:36:38<58:15:19, 20.78s/it]  3%|▎         | 276/10365 [1:36:56<55:29:54, 19.80s/it]  3%|▎         | 277/10365 [1:37:18<57:42:06, 20.59s/it]  3%|▎         | 278/10365 [1:37:35<54:31:59, 19.46s/it]  3%|▎         | 279/10365 [1:37:56<55:37:19, 19.85s/it]  3%|▎         | 280/10365 [1:38:17<57:14:53, 20.44s/it]                                                        {'loss': 1.288, 'grad_norm': 1.0, 'learning_rate': 9.982017303269602e-05, 'epoch': 0.03}
  3%|▎         | 280/10365 [1:38:17<57:14:53, 20.44s/it]  3%|▎         | 281/10365 [1:38:37<56:46:01, 20.27s/it]  3%|▎         | 282/10365 [1:38:57<56:09:40, 20.05s/it]  3%|▎         | 283/10365 [1:39:21<59:41:05, 21.31s/it]  3%|▎         | 284/10365 [1:39:40<57:35:56, 20.57s/it]  3%|▎         | 285/10365 [1:40:04<60:37:20, 21.65s/it]  3%|▎         | 286/10365 [1:40:24<58:44:45, 20.98s/it]  3%|▎         | 287/10365 [1:40:44<58:01:22, 20.73s/it]  3%|▎         | 288/10365 [1:41:02<56:09:24, 20.06s/it]  3%|▎         | 289/10365 [1:41:22<56:12:33, 20.08s/it]  3%|▎         | 290/10365 [1:41:39<53:21:51, 19.07s/it]                                                        {'loss': 1.3113, 'grad_norm': 0.8984375, 'learning_rate': 9.980710254110186e-05, 'epoch': 0.03}
  3%|▎         | 290/10365 [1:41:39<53:21:51, 19.07s/it]  3%|▎         | 291/10365 [1:41:59<53:53:27, 19.26s/it]  3%|▎         | 292/10365 [1:42:26<60:50:04, 21.74s/it]  3%|▎         | 293/10365 [1:42:47<59:50:57, 21.39s/it]  3%|▎         | 294/10365 [1:43:13<63:38:14, 22.75s/it]  3%|▎         | 295/10365 [1:43:32<60:48:39, 21.74s/it]  3%|▎         | 296/10365 [1:43:55<62:08:07, 22.22s/it]  3%|▎         | 297/10365 [1:44:14<58:46:35, 21.02s/it]  3%|▎         | 298/10365 [1:44:36<59:40:33, 21.34s/it]  3%|▎         | 299/10365 [1:45:01<62:39:20, 22.41s/it]  3%|▎         | 300/10365 [1:45:27<65:47:21, 23.53s/it]                                                        {'loss': 1.2823, 'grad_norm': 0.89453125, 'learning_rate': 9.979357447643609e-05, 'epoch': 0.03}
  3%|▎         | 300/10365 [1:45:27<65:47:21, 23.53s/it]  3%|▎         | 301/10365 [1:45:44<60:23:51, 21.60s/it]  3%|▎         | 302/10365 [1:46:04<59:28:25, 21.28s/it]  3%|▎         | 303/10365 [1:46:27<60:33:35, 21.67s/it]  3%|▎         | 304/10365 [1:46:48<60:04:18, 21.49s/it]  3%|▎         | 305/10365 [1:47:11<61:37:46, 22.05s/it]  3%|▎         | 306/10365 [1:47:29<57:46:33, 20.68s/it]  3%|▎         | 307/10365 [1:47:58<64:59:40, 23.26s/it]  3%|▎         | 308/10365 [1:48:18<62:15:14, 22.28s/it]  3%|▎         | 309/10365 [1:48:39<61:08:37, 21.89s/it]  3%|▎         | 310/10365 [1:49:01<61:02:59, 21.86s/it]                                                        {'loss': 1.2941, 'grad_norm': 1.0390625, 'learning_rate': 9.977958896297975e-05, 'epoch': 0.03}
  3%|▎         | 310/10365 [1:49:01<61:02:59, 21.86s/it]  3%|▎         | 311/10365 [1:49:26<63:33:46, 22.76s/it]  3%|▎         | 312/10365 [1:49:48<63:23:27, 22.70s/it]  3%|▎         | 313/10365 [1:50:09<61:20:17, 21.97s/it]  3%|▎         | 314/10365 [1:50:29<60:22:18, 21.62s/it]  3%|▎         | 315/10365 [1:50:51<59:56:56, 21.47s/it]  3%|▎         | 316/10365 [1:51:09<57:38:27, 20.65s/it]  3%|▎         | 317/10365 [1:51:32<59:18:28, 21.25s/it]  3%|▎         | 318/10365 [1:51:51<57:20:05, 20.54s/it]  3%|▎         | 319/10365 [1:52:13<58:21:45, 20.91s/it]  3%|▎         | 320/10365 [1:52:38<62:25:20, 22.37s/it]                                                        {'loss': 1.3167, 'grad_norm': 1.0234375, 'learning_rate': 9.976514612921642e-05, 'epoch': 0.03}
  3%|▎         | 320/10365 [1:52:38<62:25:20, 22.37s/it]  3%|▎         | 321/10365 [1:52:57<59:10:57, 21.21s/it]  3%|▎         | 322/10365 [1:53:19<60:07:27, 21.55s/it]  3%|▎         | 323/10365 [1:53:40<59:33:53, 21.35s/it]  3%|▎         | 324/10365 [1:54:02<60:02:58, 21.53s/it]  3%|▎         | 325/10365 [1:54:25<61:24:45, 22.02s/it]  3%|▎         | 326/10365 [1:54:47<61:32:03, 22.07s/it]  3%|▎         | 327/10365 [1:55:06<58:26:41, 20.96s/it]  3%|▎         | 328/10365 [1:55:24<56:27:13, 20.25s/it]  3%|▎         | 329/10365 [1:55:48<59:14:15, 21.25s/it]  3%|▎         | 330/10365 [1:56:08<58:29:21, 20.98s/it]                                                        {'loss': 1.257, 'grad_norm': 0.97265625, 'learning_rate': 9.975024610783103e-05, 'epoch': 0.03}
  3%|▎         | 330/10365 [1:56:08<58:29:21, 20.98s/it]  3%|▎         | 331/10365 [1:56:26<55:54:08, 20.06s/it]  3%|▎         | 332/10365 [1:56:48<57:14:27, 20.54s/it]  3%|▎         | 333/10365 [1:57:09<57:36:49, 20.67s/it]  3%|▎         | 334/10365 [1:57:29<57:29:45, 20.63s/it]  3%|▎         | 335/10365 [1:57:54<60:48:49, 21.83s/it]  3%|▎         | 336/10365 [1:58:17<61:20:37, 22.02s/it]  3%|▎         | 337/10365 [1:58:39<61:26:03, 22.05s/it]  3%|▎         | 338/10365 [1:58:58<59:25:25, 21.33s/it]  3%|▎         | 339/10365 [1:59:19<58:40:03, 21.07s/it]  3%|▎         | 340/10365 [1:59:35<54:21:11, 19.52s/it]                                                        {'loss': 1.2528, 'grad_norm': 0.9609375, 'learning_rate': 9.973488903570862e-05, 'epoch': 0.03}
  3%|▎         | 340/10365 [1:59:35<54:21:11, 19.52s/it]  3%|▎         | 341/10365 [1:59:56<55:57:38, 20.10s/it]  3%|▎         | 342/10365 [2:00:27<64:39:28, 23.22s/it]  3%|▎         | 343/10365 [2:00:50<64:37:57, 23.22s/it]  3%|▎         | 344/10365 [2:01:13<64:30:41, 23.18s/it]  3%|▎         | 345/10365 [2:01:31<60:35:53, 21.77s/it]  3%|▎         | 346/10365 [2:01:49<57:06:08, 20.52s/it]  3%|▎         | 347/10365 [2:02:10<57:49:59, 20.78s/it]  3%|▎         | 348/10365 [2:02:36<61:58:25, 22.27s/it]  3%|▎         | 349/10365 [2:02:59<62:10:29, 22.35s/it]  3%|▎         | 350/10365 [2:03:18<59:17:09, 21.31s/it]                                                        {'loss': 1.2729, 'grad_norm': 1.140625, 'learning_rate': 9.971907505393316e-05, 'epoch': 0.03}
  3%|▎         | 350/10365 [2:03:18<59:17:09, 21.31s/it]  3%|▎         | 351/10365 [2:03:42<61:34:02, 22.13s/it]  3%|▎         | 352/10365 [2:04:02<60:13:39, 21.65s/it]  3%|▎         | 353/10365 [2:04:27<62:45:52, 22.57s/it]  3%|▎         | 354/10365 [2:04:48<61:38:11, 22.16s/it]  3%|▎         | 355/10365 [2:05:09<60:30:20, 21.76s/it]  3%|▎         | 356/10365 [2:05:28<58:25:37, 21.01s/it]  3%|▎         | 357/10365 [2:05:53<61:30:41, 22.13s/it]  3%|▎         | 358/10365 [2:06:14<60:44:43, 21.85s/it]  3%|▎         | 359/10365 [2:06:31<56:32:31, 20.34s/it]  3%|▎         | 360/10365 [2:06:53<57:56:49, 20.85s/it]                                                        {'loss': 1.2627, 'grad_norm': 1.0, 'learning_rate': 9.97028043077862e-05, 'epoch': 0.03}
  3%|▎         | 360/10365 [2:06:53<57:56:49, 20.85s/it]  3%|▎         | 361/10365 [2:07:17<61:00:18, 21.95s/it]  3%|▎         | 362/10365 [2:07:36<58:07:17, 20.92s/it]  4%|▎         | 363/10365 [2:07:54<55:54:50, 20.13s/it]  4%|▎         | 364/10365 [2:08:12<53:33:30, 19.28s/it]  4%|▎         | 365/10365 [2:08:27<50:42:56, 18.26s/it]  4%|▎         | 366/10365 [2:08:52<56:19:34, 20.28s/it]  4%|▎         | 367/10365 [2:09:18<60:50:48, 21.91s/it]  4%|▎         | 368/10365 [2:09:40<61:06:06, 22.00s/it]  4%|▎         | 369/10365 [2:10:01<59:45:34, 21.52s/it]  4%|▎         | 370/10365 [2:10:20<58:03:33, 20.91s/it]                                                        {'loss': 1.289, 'grad_norm': 0.8828125, 'learning_rate': 9.968607694674548e-05, 'epoch': 0.04}
  4%|▎         | 370/10365 [2:10:20<58:03:33, 20.91s/it]  4%|▎         | 371/10365 [2:10:39<56:05:38, 20.21s/it]  4%|▎         | 372/10365 [2:11:01<57:32:10, 20.73s/it]  4%|▎         | 373/10365 [2:11:25<60:26:36, 21.78s/it]  4%|▎         | 374/10365 [2:11:45<59:07:37, 21.30s/it]  4%|▎         | 375/10365 [2:12:09<60:51:54, 21.93s/it]  4%|▎         | 376/10365 [2:12:32<62:06:37, 22.38s/it]  4%|▎         | 377/10365 [2:12:54<61:50:49, 22.29s/it]  4%|▎         | 378/10365 [2:13:15<61:01:42, 22.00s/it]  4%|▎         | 379/10365 [2:13:37<60:32:00, 21.82s/it]  4%|▎         | 380/10365 [2:13:57<59:09:25, 21.33s/it]                                                        {'loss': 1.3123, 'grad_norm': 0.9453125, 'learning_rate': 9.966889312448368e-05, 'epoch': 0.04}
  4%|▎         | 380/10365 [2:13:57<59:09:25, 21.33s/it]  4%|▎         | 381/10365 [2:14:24<63:41:15, 22.96s/it]  4%|▎         | 382/10365 [2:14:44<61:06:00, 22.03s/it]  4%|▎         | 383/10365 [2:15:15<68:56:33, 24.86s/it]  4%|▎         | 384/10365 [2:15:38<67:25:17, 24.32s/it]  4%|▎         | 385/10365 [2:16:02<66:53:22, 24.13s/it]  4%|▎         | 386/10365 [2:16:20<61:58:43, 22.36s/it]  4%|▎         | 387/10365 [2:16:40<60:22:57, 21.79s/it]  4%|▎         | 388/10365 [2:16:59<58:02:32, 20.94s/it]  4%|▍         | 389/10365 [2:17:18<56:15:20, 20.30s/it]  4%|▍         | 390/10365 [2:17:40<57:35:26, 20.78s/it]                                                        {'loss': 1.2585, 'grad_norm': 1.0078125, 'learning_rate': 9.965125299886694e-05, 'epoch': 0.04}
  4%|▍         | 390/10365 [2:17:40<57:35:26, 20.78s/it]  4%|▍         | 391/10365 [2:17:59<55:58:32, 20.20s/it]  4%|▍         | 392/10365 [2:18:18<54:37:30, 19.72s/it]  4%|▍         | 393/10365 [2:18:38<54:47:32, 19.78s/it]  4%|▍         | 394/10365 [2:18:54<52:07:06, 18.82s/it]  4%|▍         | 395/10365 [2:19:13<51:59:54, 18.78s/it]  4%|▍         | 396/10365 [2:19:30<51:05:47, 18.45s/it]  4%|▍         | 397/10365 [2:19:51<52:28:58, 18.95s/it]  4%|▍         | 398/10365 [2:20:12<54:09:47, 19.56s/it]  4%|▍         | 399/10365 [2:20:37<58:56:44, 21.29s/it]  4%|▍         | 400/10365 [2:20:57<57:51:48, 20.90s/it]                                                        {'loss': 1.2508, 'grad_norm': 0.93359375, 'learning_rate': 9.96331567319534e-05, 'epoch': 0.04}
  4%|▍         | 400/10365 [2:20:57<57:51:48, 20.90s/it]  4%|▍         | 401/10365 [2:21:22<61:17:51, 22.15s/it]  4%|▍         | 402/10365 [2:21:43<60:15:15, 21.77s/it]  4%|▍         | 403/10365 [2:22:12<66:28:06, 24.02s/it]  4%|▍         | 404/10365 [2:22:33<63:29:20, 22.95s/it]  4%|▍         | 405/10365 [2:22:47<56:22:12, 20.37s/it]  4%|▍         | 406/10365 [2:23:09<57:57:07, 20.95s/it]  4%|▍         | 407/10365 [2:23:37<63:19:14, 22.89s/it]  4%|▍         | 408/10365 [2:24:04<67:09:06, 24.28s/it]  4%|▍         | 409/10365 [2:24:24<63:19:07, 22.90s/it]  4%|▍         | 410/10365 [2:24:44<60:39:26, 21.94s/it]                                                        {'loss': 1.2453, 'grad_norm': 0.98046875, 'learning_rate': 9.96146044899917e-05, 'epoch': 0.04}
  4%|▍         | 410/10365 [2:24:44<60:39:26, 21.94s/it]  4%|▍         | 411/10365 [2:25:02<57:53:45, 20.94s/it]  4%|▍         | 412/10365 [2:25:25<59:42:22, 21.60s/it]  4%|▍         | 413/10365 [2:25:44<57:33:32, 20.82s/it]  4%|▍         | 414/10365 [2:26:04<56:12:46, 20.34s/it]  4%|▍         | 415/10365 [2:26:24<56:33:09, 20.46s/it]  4%|▍         | 416/10365 [2:26:47<58:21:07, 21.11s/it]  4%|▍         | 417/10365 [2:27:10<59:58:22, 21.70s/it]  4%|▍         | 418/10365 [2:27:30<58:47:41, 21.28s/it]  4%|▍         | 419/10365 [2:27:50<57:39:44, 20.87s/it]  4%|▍         | 420/10365 [2:28:15<60:57:16, 22.07s/it]                                                        {'loss': 1.2329, 'grad_norm': 0.99609375, 'learning_rate': 9.959559644341954e-05, 'epoch': 0.04}
  4%|▍         | 420/10365 [2:28:15<60:57:16, 22.07s/it]  4%|▍         | 421/10365 [2:28:35<59:08:38, 21.41s/it]  4%|▍         | 422/10365 [2:28:53<56:36:10, 20.49s/it]  4%|▍         | 423/10365 [2:29:14<56:38:15, 20.51s/it]  4%|▍         | 424/10365 [2:29:34<56:11:21, 20.35s/it]  4%|▍         | 425/10365 [2:29:55<57:12:41, 20.72s/it]  4%|▍         | 426/10365 [2:30:14<55:23:39, 20.06s/it]  4%|▍         | 427/10365 [2:30:29<50:53:35, 18.44s/it]  4%|▍         | 428/10365 [2:30:50<53:10:27, 19.26s/it]  4%|▍         | 429/10365 [2:31:09<53:01:59, 19.21s/it]  4%|▍         | 430/10365 [2:31:32<56:26:36, 20.45s/it]                                                        {'loss': 1.2282, 'grad_norm': 1.0703125, 'learning_rate': 9.957613276686198e-05, 'epoch': 0.04}
  4%|▍         | 430/10365 [2:31:32<56:26:36, 20.45s/it]  4%|▍         | 431/10365 [2:31:52<55:58:23, 20.28s/it]  4%|▍         | 432/10365 [2:32:14<57:16:42, 20.76s/it]  4%|▍         | 433/10365 [2:32:36<58:25:53, 21.18s/it]  4%|▍         | 434/10365 [2:32:54<55:48:50, 20.23s/it]  4%|▍         | 435/10365 [2:33:19<59:40:53, 21.64s/it]  4%|▍         | 436/10365 [2:33:34<54:28:52, 19.75s/it]  4%|▍         | 437/10365 [2:33:52<52:29:13, 19.03s/it]  4%|▍         | 438/10365 [2:34:12<53:23:51, 19.36s/it]  4%|▍         | 439/10365 [2:34:32<54:08:47, 19.64s/it]  4%|▍         | 440/10365 [2:34:51<53:47:14, 19.51s/it]                                                        {'loss': 1.2234, 'grad_norm': 1.0546875, 'learning_rate': 9.955621363913e-05, 'epoch': 0.04}
  4%|▍         | 440/10365 [2:34:51<53:47:14, 19.51s/it]  4%|▍         | 441/10365 [2:35:11<53:44:15, 19.49s/it]  4%|▍         | 442/10365 [2:35:40<61:26:58, 22.29s/it]  4%|▍         | 443/10365 [2:36:08<66:36:47, 24.17s/it]  4%|▍         | 444/10365 [2:36:28<63:07:36, 22.91s/it]  4%|▍         | 445/10365 [2:36:50<61:57:51, 22.49s/it]  4%|▍         | 446/10365 [2:37:11<60:45:28, 22.05s/it]  4%|▍         | 447/10365 [2:37:28<57:00:55, 20.70s/it]  4%|▍         | 448/10365 [2:37:48<55:50:02, 20.27s/it]  4%|▍         | 449/10365 [2:38:09<57:10:39, 20.76s/it]  4%|▍         | 450/10365 [2:38:29<55:51:37, 20.28s/it]                                                        {'loss': 1.2363, 'grad_norm': 0.91796875, 'learning_rate': 9.953583924321868e-05, 'epoch': 0.04}
  4%|▍         | 450/10365 [2:38:29<55:51:37, 20.28s/it]  4%|▍         | 451/10365 [2:38:49<55:46:39, 20.25s/it]  4%|▍         | 452/10365 [2:39:14<59:38:01, 21.66s/it]  4%|▍         | 453/10365 [2:39:33<57:49:53, 21.00s/it]  4%|▍         | 454/10365 [2:39:55<58:09:16, 21.12s/it]  4%|▍         | 455/10365 [2:40:14<57:04:25, 20.73s/it]  4%|▍         | 456/10365 [2:40:34<56:01:39, 20.36s/it]  4%|▍         | 457/10365 [2:40:49<51:40:47, 18.78s/it]  4%|▍         | 458/10365 [2:41:08<52:15:42, 18.99s/it]  4%|▍         | 459/10365 [2:41:30<54:14:08, 19.71s/it]  4%|▍         | 460/10365 [2:41:49<53:51:27, 19.57s/it]                                                        {'loss': 1.2412, 'grad_norm': 0.98046875, 'learning_rate': 9.951500976630563e-05, 'epoch': 0.04}
  4%|▍         | 460/10365 [2:41:49<53:51:27, 19.57s/it]  4%|▍         | 461/10365 [2:42:05<50:45:01, 18.45s/it]  4%|▍         | 462/10365 [2:42:30<55:48:43, 20.29s/it]  4%|▍         | 463/10365 [2:42:50<56:09:07, 20.41s/it]  4%|▍         | 464/10365 [2:43:19<63:17:46, 23.01s/it]  4%|▍         | 465/10365 [2:43:39<60:14:06, 21.90s/it]  4%|▍         | 466/10365 [2:44:01<60:51:36, 22.13s/it]  5%|▍         | 467/10365 [2:44:20<58:18:28, 21.21s/it]  5%|▍         | 468/10365 [2:44:42<58:45:56, 21.38s/it]  5%|▍         | 469/10365 [2:45:03<58:26:10, 21.26s/it]  5%|▍         | 470/10365 [2:45:28<61:03:05, 22.21s/it]                                                        {'loss': 1.2497, 'grad_norm': 0.8515625, 'learning_rate': 9.94937253997493e-05, 'epoch': 0.05}
  5%|▍         | 470/10365 [2:45:28<61:03:05, 22.21s/it]  5%|▍         | 471/10365 [2:45:47<58:26:59, 21.27s/it]  5%|▍         | 472/10365 [2:46:06<56:50:28, 20.68s/it]  5%|▍         | 473/10365 [2:46:32<61:39:00, 22.44s/it]  5%|▍         | 474/10365 [2:46:53<60:18:34, 21.95s/it]  5%|▍         | 475/10365 [2:47:13<58:24:16, 21.26s/it]  5%|▍         | 476/10365 [2:47:32<56:16:08, 20.48s/it]  5%|▍         | 477/10365 [2:47:52<56:11:12, 20.46s/it]  5%|▍         | 478/10365 [2:48:17<59:56:59, 21.83s/it]  5%|▍         | 479/10365 [2:48:37<58:20:48, 21.25s/it]  5%|▍         | 480/10365 [2:48:58<58:07:48, 21.17s/it]                                                        {'loss': 1.2395, 'grad_norm': 0.97265625, 'learning_rate': 9.947198633908709e-05, 'epoch': 0.05}
  5%|▍         | 480/10365 [2:48:58<58:07:48, 21.17s/it]  5%|▍         | 481/10365 [2:49:26<63:32:45, 23.15s/it]  5%|▍         | 482/10365 [2:49:48<62:34:58, 22.80s/it]  5%|▍         | 483/10365 [2:50:07<59:25:42, 21.65s/it]  5%|▍         | 484/10365 [2:50:26<57:40:06, 21.01s/it]  5%|▍         | 485/10365 [2:50:47<57:57:01, 21.12s/it]  5%|▍         | 486/10365 [2:51:05<54:59:37, 20.04s/it]  5%|▍         | 487/10365 [2:51:26<55:44:51, 20.32s/it]  5%|▍         | 488/10365 [2:51:47<56:12:26, 20.49s/it]  5%|▍         | 489/10365 [2:52:09<57:21:00, 20.91s/it]  5%|▍         | 490/10365 [2:52:31<58:42:40, 21.40s/it]                                                        {'loss': 1.2539, 'grad_norm': 1.0078125, 'learning_rate': 9.944979278403365e-05, 'epoch': 0.05}
  5%|▍         | 490/10365 [2:52:31<58:42:40, 21.40s/it]  5%|▍         | 491/10365 [2:52:56<61:33:45, 22.45s/it]  5%|▍         | 492/10365 [2:53:21<63:09:56, 23.03s/it]  5%|▍         | 493/10365 [2:53:48<66:59:26, 24.43s/it]  5%|▍         | 494/10365 [2:54:10<64:55:43, 23.68s/it]  5%|▍         | 495/10365 [2:54:31<62:33:58, 22.82s/it]  5%|▍         | 496/10365 [2:54:49<58:39:18, 21.40s/it]  5%|▍         | 497/10365 [2:55:11<58:49:59, 21.46s/it]  5%|▍         | 498/10365 [2:55:30<57:06:41, 20.84s/it]  5%|▍         | 499/10365 [2:55:48<55:00:57, 20.07s/it]  5%|▍         | 500/10365 [2:56:09<55:44:33, 20.34s/it]                                                        {'loss': 1.2127, 'grad_norm': 0.96484375, 'learning_rate': 9.942714493847909e-05, 'epoch': 0.05}
  5%|▍         | 500/10365 [2:56:09<55:44:33, 20.34s/it][INFO|trainer.py:3719] 2024-05-30 13:50:35,221 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-30 13:50:35,221 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-30 13:50:35,222 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:48,  1.77s/it][A
  5%|▍         | 3/63 [00:08<03:16,  3.27s/it][A
  6%|▋         | 4/63 [00:13<03:48,  3.87s/it][A
  8%|▊         | 5/63 [00:18<04:07,  4.26s/it][A
 10%|▉         | 6/63 [00:23<04:11,  4.41s/it][A
 11%|█         | 7/63 [00:28<04:17,  4.59s/it][A
 13%|█▎        | 8/63 [00:33<04:14,  4.64s/it][A
 14%|█▍        | 9/63 [00:38<04:17,  4.77s/it][A
 16%|█▌        | 10/63 [00:43<04:25,  5.02s/it][A
 17%|█▋        | 11/63 [00:49<04:34,  5.29s/it][A
 19%|█▉        | 12/63 [00:54<04:21,  5.12s/it][A
 21%|██        | 13/63 [00:59<04:15,  5.11s/it][A
 22%|██▏       | 14/63 [01:04<04:02,  4.95s/it][A
 24%|██▍       | 15/63 [01:09<04:00,  5.01s/it][A
 25%|██▌       | 16/63 [01:14<03:54,  5.00s/it][A
 27%|██▋       | 17/63 [01:19<03:50,  5.02s/it][A
 29%|██▊       | 18/63 [01:24<03:51,  5.15s/it][A
 30%|███       | 19/63 [01:30<03:52,  5.29s/it][A
 32%|███▏      | 20/63 [01:36<03:51,  5.38s/it][A
 33%|███▎      | 21/63 [01:40<03:34,  5.11s/it][A
 35%|███▍      | 22/63 [01:46<03:44,  5.48s/it][A
 37%|███▋      | 23/63 [01:50<03:17,  4.94s/it][A
 38%|███▊      | 24/63 [01:56<03:20,  5.15s/it][A
 40%|███▉      | 25/63 [02:01<03:21,  5.31s/it][A
 41%|████▏     | 26/63 [02:06<03:11,  5.19s/it][A
 43%|████▎     | 27/63 [02:12<03:12,  5.35s/it][A
 44%|████▍     | 28/63 [02:18<03:14,  5.55s/it][A
 46%|████▌     | 29/63 [02:25<03:23,  5.97s/it][A
 48%|████▊     | 30/63 [02:29<03:01,  5.50s/it][A
 49%|████▉     | 31/63 [02:34<02:52,  5.38s/it][A
 51%|█████     | 32/63 [02:39<02:34,  4.99s/it][A
 52%|█████▏    | 33/63 [02:44<02:37,  5.26s/it][A
 54%|█████▍    | 34/63 [02:48<02:18,  4.76s/it][A
 56%|█████▌    | 35/63 [02:53<02:13,  4.76s/it][A
 57%|█████▋    | 36/63 [02:57<02:04,  4.60s/it][A
 59%|█████▊    | 37/63 [03:04<02:14,  5.19s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.29s/it][A
 62%|██████▏   | 39/63 [03:14<02:01,  5.07s/it][A
 63%|██████▎   | 40/63 [03:19<01:57,  5.10s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.15s/it][A
 67%|██████▋   | 42/63 [03:31<01:59,  5.68s/it][A
 68%|██████▊   | 43/63 [03:37<01:53,  5.68s/it][A
 70%|██████▉   | 44/63 [03:41<01:42,  5.40s/it][A
 71%|███████▏  | 45/63 [03:48<01:45,  5.86s/it][A
 73%|███████▎  | 46/63 [03:54<01:38,  5.81s/it][A
 75%|███████▍  | 47/63 [04:00<01:32,  5.78s/it][A
 76%|███████▌  | 48/63 [04:07<01:31,  6.12s/it][A
 78%|███████▊  | 49/63 [04:11<01:19,  5.64s/it][A
 79%|███████▉  | 50/63 [04:18<01:16,  5.91s/it][A
 81%|████████  | 51/63 [04:23<01:09,  5.80s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.13s/it][A
 84%|████████▍ | 53/63 [04:36<00:59,  5.93s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.82s/it][A
 87%|████████▋ | 55/63 [04:46<00:43,  5.38s/it][A
 89%|████████▉ | 56/63 [04:50<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.30s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.20s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.15s/it][A
 95%|█████████▌| 60/63 [05:10<00:14,  4.89s/it][A
 97%|█████████▋| 61/63 [05:17<00:10,  5.41s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.67s/it][A
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A                                                        
                                               [A{'eval_loss': 1.22943913936615, 'eval_runtime': 336.2929, 'eval_samples_per_second': 14.868, 'eval_steps_per_second': 0.187, 'epoch': 0.05}
  5%|▍         | 500/10365 [3:01:46<55:44:33, 20.34s/it]
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-30 13:56:14,389 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-500
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-30 13:56:14,456 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-30 13:56:14,456 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-500/special_tokens_map.json
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
  5%|▍         | 501/10365 [3:02:11<336:17:58, 122.74s/it]  5%|▍         | 502/10365 [3:02:29<249:57:48, 91.24s/it]   5%|▍         | 503/10365 [3:02:50<192:26:02, 70.25s/it]  5%|▍         | 504/10365 [3:03:15<155:38:22, 56.82s/it]  5%|▍         | 505/10365 [3:03:35<125:11:20, 45.71s/it]  5%|▍         | 506/10365 [3:03:51<100:08:26, 36.57s/it]  5%|▍         | 507/10365 [3:04:10<86:06:38, 31.45s/it]   5%|▍         | 508/10365 [3:04:32<78:17:25, 28.59s/it]  5%|▍         | 509/10365 [3:04:51<70:17:43, 25.68s/it]  5%|▍         | 510/10365 [3:05:09<63:53:15, 23.34s/it]                                                        {'loss': 1.2461, 'grad_norm': 0.86328125, 'learning_rate': 9.940404301048696e-05, 'epoch': 0.05}
  5%|▍         | 510/10365 [3:05:09<63:53:15, 23.34s/it]  5%|▍         | 511/10365 [3:05:26<59:02:06, 21.57s/it]  5%|▍         | 512/10365 [3:05:47<58:10:32, 21.26s/it]  5%|▍         | 513/10365 [3:06:10<59:45:10, 21.83s/it]  5%|▍         | 514/10365 [3:06:28<56:43:27, 20.73s/it]  5%|▍         | 515/10365 [3:06:48<56:27:05, 20.63s/it]  5%|▍         | 516/10365 [3:07:15<61:16:38, 22.40s/it]  5%|▍         | 517/10365 [3:07:40<63:31:07, 23.22s/it]  5%|▍         | 518/10365 [3:08:01<61:15:02, 22.39s/it]  5%|▌         | 519/10365 [3:08:18<57:23:35, 20.98s/it]  5%|▌         | 520/10365 [3:08:36<55:06:26, 20.15s/it]                                                        {'loss': 1.2308, 'grad_norm': 0.921875, 'learning_rate': 9.938048721229246e-05, 'epoch': 0.05}
  5%|▌         | 520/10365 [3:08:36<55:06:26, 20.15s/it]  5%|▌         | 521/10365 [3:08:59<56:45:24, 20.76s/it]  5%|▌         | 522/10365 [3:09:23<59:38:26, 21.81s/it]  5%|▌         | 523/10365 [3:09:43<58:10:12, 21.28s/it]  5%|▌         | 524/10365 [3:10:05<58:29:04, 21.39s/it]  5%|▌         | 525/10365 [3:10:23<56:26:15, 20.65s/it]  5%|▌         | 526/10365 [3:10:46<58:05:27, 21.25s/it]  5%|▌         | 527/10365 [3:11:06<56:47:43, 20.78s/it]  5%|▌         | 528/10365 [3:11:25<55:30:44, 20.32s/it]  5%|▌         | 529/10365 [3:11:49<58:39:37, 21.47s/it]  5%|▌         | 530/10365 [3:12:10<57:49:16, 21.16s/it]                                                        {'loss': 1.2509, 'grad_norm': 0.91015625, 'learning_rate': 9.935647776030045e-05, 'epoch': 0.05}
  5%|▌         | 530/10365 [3:12:10<57:49:16, 21.16s/it]  5%|▌         | 531/10365 [3:12:28<55:40:34, 20.38s/it]  5%|▌         | 532/10365 [3:12:51<57:20:08, 20.99s/it]  5%|▌         | 533/10365 [3:13:11<56:54:27, 20.84s/it]  5%|▌         | 534/10365 [3:13:34<58:25:08, 21.39s/it]  5%|▌         | 535/10365 [3:13:53<56:30:20, 20.69s/it]  5%|▌         | 536/10365 [3:14:14<57:08:13, 20.93s/it]  5%|▌         | 537/10365 [3:14:36<57:50:18, 21.19s/it]  5%|▌         | 538/10365 [3:14:57<57:38:01, 21.11s/it]  5%|▌         | 539/10365 [3:15:16<56:02:10, 20.53s/it]  5%|▌         | 540/10365 [3:15:34<53:53:48, 19.75s/it]                                                        {'loss': 1.217, 'grad_norm': 0.99609375, 'learning_rate': 9.933201487508345e-05, 'epoch': 0.05}
  5%|▌         | 540/10365 [3:15:34<53:53:48, 19.75s/it]  5%|▌         | 541/10365 [3:15:59<58:07:30, 21.30s/it]  5%|▌         | 542/10365 [3:16:22<59:30:13, 21.81s/it]  5%|▌         | 543/10365 [3:16:42<57:50:45, 21.20s/it]  5%|▌         | 544/10365 [3:17:05<59:44:21, 21.90s/it]  5%|▌         | 545/10365 [3:17:28<60:40:24, 22.24s/it]  5%|▌         | 546/10365 [3:17:52<61:21:10, 22.49s/it]  5%|▌         | 547/10365 [3:18:12<59:25:50, 21.79s/it]  5%|▌         | 548/10365 [3:18:30<56:18:59, 20.65s/it]  5%|▌         | 549/10365 [3:18:47<53:24:27, 19.59s/it]  5%|▌         | 550/10365 [3:19:08<55:05:37, 20.21s/it]                                                        {'loss': 1.2117, 'grad_norm': 0.9296875, 'learning_rate': 9.930709878137967e-05, 'epoch': 0.05}
  5%|▌         | 550/10365 [3:19:08<55:05:37, 20.21s/it]  5%|▌         | 551/10365 [3:19:27<54:08:56, 19.86s/it]  5%|▌         | 552/10365 [3:19:46<53:12:11, 19.52s/it]  5%|▌         | 553/10365 [3:20:11<57:09:44, 20.97s/it]  5%|▌         | 554/10365 [3:20:30<56:03:24, 20.57s/it]  5%|▌         | 555/10365 [3:20:52<57:23:42, 21.06s/it]  5%|▌         | 556/10365 [3:21:17<60:34:11, 22.23s/it]  5%|▌         | 557/10365 [3:21:40<61:06:25, 22.43s/it]  5%|▌         | 558/10365 [3:22:02<60:47:59, 22.32s/it]  5%|▌         | 559/10365 [3:22:21<57:32:56, 21.13s/it]  5%|▌         | 560/10365 [3:22:41<57:18:02, 21.04s/it]                                                        {'loss': 1.2044, 'grad_norm': 0.8515625, 'learning_rate': 9.928172970809084e-05, 'epoch': 0.05}
  5%|▌         | 560/10365 [3:22:41<57:18:02, 21.04s/it]  5%|▌         | 561/10365 [3:23:03<57:42:39, 21.19s/it]  5%|▌         | 562/10365 [3:23:25<58:25:38, 21.46s/it]  5%|▌         | 563/10365 [3:23:52<62:52:10, 23.09s/it]  5%|▌         | 564/10365 [3:24:09<57:34:01, 21.14s/it]  5%|▌         | 565/10365 [3:24:27<55:11:19, 20.27s/it]  5%|▌         | 566/10365 [3:24:45<53:42:55, 19.73s/it]  5%|▌         | 567/10365 [3:25:03<51:44:39, 19.01s/it]  5%|▌         | 568/10365 [3:25:22<51:50:16, 19.05s/it]  5%|▌         | 569/10365 [3:25:40<51:14:18, 18.83s/it]  5%|▌         | 570/10365 [3:26:03<54:42:33, 20.11s/it]                                                        {'loss': 1.1854, 'grad_norm': 0.8671875, 'learning_rate': 9.92559078882802e-05, 'epoch': 0.05}
  5%|▌         | 570/10365 [3:26:03<54:42:33, 20.11s/it]  6%|▌         | 571/10365 [3:26:25<56:05:12, 20.62s/it]  6%|▌         | 572/10365 [3:26:49<58:39:03, 21.56s/it]  6%|▌         | 573/10365 [3:27:10<58:17:46, 21.43s/it]  6%|▌         | 574/10365 [3:27:33<59:26:07, 21.85s/it]  6%|▌         | 575/10365 [3:28:00<63:30:01, 23.35s/it]  6%|▌         | 576/10365 [3:28:20<60:51:53, 22.38s/it]  6%|▌         | 577/10365 [3:28:38<57:31:02, 21.15s/it]  6%|▌         | 578/10365 [3:28:58<56:19:09, 20.72s/it]  6%|▌         | 579/10365 [3:29:18<56:01:18, 20.61s/it]  6%|▌         | 580/10365 [3:29:40<56:44:36, 20.88s/it]                                                        {'loss': 1.2038, 'grad_norm': 0.8125, 'learning_rate': 9.922963355917037e-05, 'epoch': 0.06}
  6%|▌         | 580/10365 [3:29:40<56:44:36, 20.88s/it]  6%|▌         | 581/10365 [3:30:05<60:20:50, 22.20s/it]  6%|▌         | 582/10365 [3:30:20<54:47:26, 20.16s/it]  6%|▌         | 583/10365 [3:30:41<55:08:31, 20.29s/it]  6%|▌         | 584/10365 [3:31:06<59:06:19, 21.75s/it]  6%|▌         | 585/10365 [3:31:26<57:51:43, 21.30s/it]  6%|▌         | 586/10365 [3:31:48<58:30:32, 21.54s/it]  6%|▌         | 587/10365 [3:32:10<58:31:11, 21.55s/it]  6%|▌         | 588/10365 [3:32:32<59:04:23, 21.75s/it]  6%|▌         | 589/10365 [3:32:48<54:25:31, 20.04s/it]  6%|▌         | 590/10365 [3:33:16<60:34:42, 22.31s/it]                                                        {'loss': 1.2141, 'grad_norm': 0.99609375, 'learning_rate': 9.920290696214105e-05, 'epoch': 0.06}
  6%|▌         | 590/10365 [3:33:16<60:34:42, 22.31s/it]  6%|▌         | 591/10365 [3:33:36<58:36:20, 21.59s/it]  6%|▌         | 592/10365 [3:33:58<59:28:51, 21.91s/it]  6%|▌         | 593/10365 [3:34:15<55:33:27, 20.47s/it]  6%|▌         | 594/10365 [3:34:39<57:46:00, 21.28s/it]  6%|▌         | 595/10365 [3:35:01<58:24:09, 21.52s/it]  6%|▌         | 596/10365 [3:35:23<59:11:43, 21.81s/it]  6%|▌         | 597/10365 [3:35:44<58:22:27, 21.51s/it]  6%|▌         | 598/10365 [3:36:06<58:57:08, 21.73s/it]  6%|▌         | 599/10365 [3:36:26<56:55:35, 20.98s/it]  6%|▌         | 600/10365 [3:36:45<55:30:19, 20.46s/it]                                                        {'loss': 1.1922, 'grad_norm': 0.9609375, 'learning_rate': 9.917572834272695e-05, 'epoch': 0.06}
  6%|▌         | 600/10365 [3:36:45<55:30:19, 20.46s/it]  6%|▌         | 601/10365 [3:37:08<58:04:31, 21.41s/it]  6%|▌         | 602/10365 [3:37:29<57:28:18, 21.19s/it]  6%|▌         | 603/10365 [3:37:54<60:22:01, 22.26s/it]  6%|▌         | 604/10365 [3:38:15<59:13:27, 21.84s/it]  6%|▌         | 605/10365 [3:38:38<60:36:52, 22.36s/it]  6%|▌         | 606/10365 [3:38:59<59:36:30, 21.99s/it]  6%|▌         | 607/10365 [3:39:21<59:17:21, 21.87s/it]  6%|▌         | 608/10365 [3:39:37<54:24:00, 20.07s/it]  6%|▌         | 609/10365 [3:39:58<55:37:01, 20.52s/it]  6%|▌         | 610/10365 [3:40:18<54:59:05, 20.29s/it]                                                        {'loss': 1.1942, 'grad_norm': 0.98046875, 'learning_rate': 9.914809795061541e-05, 'epoch': 0.06}
  6%|▌         | 610/10365 [3:40:18<54:59:05, 20.29s/it]  6%|▌         | 611/10365 [3:40:40<56:14:22, 20.76s/it]  6%|▌         | 612/10365 [3:41:02<57:26:01, 21.20s/it]  6%|▌         | 613/10365 [3:41:29<61:50:44, 22.83s/it]  6%|▌         | 614/10365 [3:41:54<63:33:58, 23.47s/it]  6%|▌         | 615/10365 [3:42:16<62:42:15, 23.15s/it]  6%|▌         | 616/10365 [3:42:36<59:53:55, 22.12s/it]  6%|▌         | 617/10365 [3:42:59<60:24:34, 22.31s/it]  6%|▌         | 618/10365 [3:43:17<56:57:46, 21.04s/it]  6%|▌         | 619/10365 [3:43:38<56:58:54, 21.05s/it]  6%|▌         | 620/10365 [3:43:58<56:01:38, 20.70s/it]                                                        {'loss': 1.21, 'grad_norm': 0.95703125, 'learning_rate': 9.912001603964421e-05, 'epoch': 0.06}
  6%|▌         | 620/10365 [3:43:58<56:01:38, 20.70s/it]  6%|▌         | 621/10365 [3:44:20<57:01:33, 21.07s/it]  6%|▌         | 622/10365 [3:44:37<54:13:39, 20.04s/it]  6%|▌         | 623/10365 [3:45:03<59:10:34, 21.87s/it]  6%|▌         | 624/10365 [3:45:24<58:10:13, 21.50s/it]  6%|▌         | 625/10365 [3:45:45<58:00:45, 21.44s/it]  6%|▌         | 626/10365 [3:46:12<62:34:57, 23.13s/it]  6%|▌         | 627/10365 [3:46:29<57:18:51, 21.19s/it]  6%|▌         | 628/10365 [3:46:49<55:51:59, 20.66s/it]  6%|▌         | 629/10365 [3:47:08<54:58:40, 20.33s/it]  6%|▌         | 630/10365 [3:47:29<55:37:58, 20.57s/it]                                                        {'loss': 1.1972, 'grad_norm': 0.87109375, 'learning_rate': 9.909148286779916e-05, 'epoch': 0.06}
  6%|▌         | 630/10365 [3:47:29<55:37:58, 20.57s/it]  6%|▌         | 631/10365 [3:47:51<56:44:34, 20.99s/it]  6%|▌         | 632/10365 [3:48:16<59:58:10, 22.18s/it]  6%|▌         | 633/10365 [3:48:34<56:10:42, 20.78s/it]  6%|▌         | 634/10365 [3:48:59<59:35:34, 22.05s/it]  6%|▌         | 635/10365 [3:49:19<58:14:42, 21.55s/it]  6%|▌         | 636/10365 [3:49:39<57:19:37, 21.21s/it]  6%|▌         | 637/10365 [3:50:02<58:20:18, 21.59s/it]  6%|▌         | 638/10365 [3:50:24<58:34:51, 21.68s/it]  6%|▌         | 639/10365 [3:50:45<58:22:36, 21.61s/it]  6%|▌         | 640/10365 [3:51:09<60:07:28, 22.26s/it]                                                        {'loss': 1.1897, 'grad_norm': 1.0, 'learning_rate': 9.90624986972118e-05, 'epoch': 0.06}
  6%|▌         | 640/10365 [3:51:09<60:07:28, 22.26s/it]  6%|▌         | 641/10365 [3:51:31<60:11:46, 22.29s/it]  6%|▌         | 642/10365 [3:51:56<61:46:22, 22.87s/it]  6%|▌         | 643/10365 [3:52:15<58:49:23, 21.78s/it]  6%|▌         | 644/10365 [3:52:34<56:22:32, 20.88s/it]  6%|▌         | 645/10365 [3:52:57<58:06:45, 21.52s/it]  6%|▌         | 646/10365 [3:53:14<54:39:58, 20.25s/it]  6%|▌         | 647/10365 [3:53:35<55:02:45, 20.39s/it]  6%|▋         | 648/10365 [3:53:55<54:43:40, 20.28s/it]  6%|▋         | 649/10365 [3:54:18<56:48:03, 21.05s/it]  6%|▋         | 650/10365 [3:54:37<55:49:09, 20.68s/it]                                                        {'loss': 1.1988, 'grad_norm': 0.98046875, 'learning_rate': 9.903306379415689e-05, 'epoch': 0.06}
  6%|▋         | 650/10365 [3:54:37<55:49:09, 20.68s/it]  6%|▋         | 651/10365 [3:54:55<53:27:19, 19.81s/it]  6%|▋         | 652/10365 [3:55:19<56:35:28, 20.97s/it]  6%|▋         | 653/10365 [3:55:42<58:32:15, 21.70s/it]  6%|▋         | 654/10365 [3:55:59<54:39:30, 20.26s/it]  6%|▋         | 655/10365 [3:56:21<55:47:49, 20.69s/it]  6%|▋         | 656/10365 [3:56:43<57:23:54, 21.28s/it]  6%|▋         | 657/10365 [3:57:02<55:28:49, 20.57s/it]  6%|▋         | 658/10365 [3:57:21<53:54:05, 19.99s/it]  6%|▋         | 659/10365 [3:57:43<55:25:09, 20.56s/it]  6%|▋         | 660/10365 [3:58:08<58:42:29, 21.78s/it]                                                        {'loss': 1.2017, 'grad_norm': 0.84375, 'learning_rate': 9.900317842905007e-05, 'epoch': 0.06}
  6%|▋         | 660/10365 [3:58:08<58:42:29, 21.78s/it]  6%|▋         | 661/10365 [3:58:27<56:31:26, 20.97s/it]  6%|▋         | 662/10365 [3:58:44<53:48:23, 19.96s/it]  6%|▋         | 663/10365 [3:59:04<53:23:37, 19.81s/it]  6%|▋         | 664/10365 [3:59:22<52:21:53, 19.43s/it]  6%|▋         | 665/10365 [3:59:44<54:03:34, 20.06s/it]  6%|▋         | 666/10365 [4:00:07<56:26:42, 20.95s/it]  6%|▋         | 667/10365 [4:00:34<61:23:12, 22.79s/it]  6%|▋         | 668/10365 [4:00:55<60:06:41, 22.32s/it]  6%|▋         | 669/10365 [4:01:15<57:44:53, 21.44s/it]  6%|▋         | 670/10365 [4:01:36<57:39:52, 21.41s/it]                                                        {'loss': 1.1917, 'grad_norm': 1.046875, 'learning_rate': 9.897284287644534e-05, 'epoch': 0.06}
  6%|▋         | 670/10365 [4:01:36<57:39:52, 21.41s/it]  6%|▋         | 671/10365 [4:01:58<57:58:39, 21.53s/it]  6%|▋         | 672/10365 [4:02:19<57:32:28, 21.37s/it]  6%|▋         | 673/10365 [4:02:41<58:30:22, 21.73s/it]  7%|▋         | 674/10365 [4:03:01<57:00:28, 21.18s/it]  7%|▋         | 675/10365 [4:03:21<55:34:46, 20.65s/it]  7%|▋         | 676/10365 [4:03:42<56:31:43, 21.00s/it]  7%|▋         | 677/10365 [4:04:03<56:26:36, 20.97s/it]  7%|▋         | 678/10365 [4:04:25<56:45:25, 21.09s/it]  7%|▋         | 679/10365 [4:04:45<55:55:18, 20.78s/it]  7%|▋         | 680/10365 [4:05:05<55:47:14, 20.74s/it]                                                        {'loss': 1.1798, 'grad_norm': 0.93359375, 'learning_rate': 9.894205741503249e-05, 'epoch': 0.07}
  7%|▋         | 680/10365 [4:05:05<55:47:14, 20.74s/it]  7%|▋         | 681/10365 [4:05:28<57:21:24, 21.32s/it]  7%|▋         | 682/10365 [4:05:46<54:50:28, 20.39s/it]  7%|▋         | 683/10365 [4:06:09<56:52:01, 21.14s/it]  7%|▋         | 684/10365 [4:06:34<59:52:21, 22.26s/it]  7%|▋         | 685/10365 [4:06:53<57:30:17, 21.39s/it]  7%|▋         | 686/10365 [4:07:16<58:19:42, 21.69s/it]  7%|▋         | 687/10365 [4:07:40<60:21:24, 22.45s/it]  7%|▋         | 688/10365 [4:08:01<59:28:54, 22.13s/it]  7%|▋         | 689/10365 [4:08:22<58:18:40, 21.69s/it]  7%|▋         | 690/10365 [4:08:43<57:56:23, 21.56s/it]                                                        {'loss': 1.1776, 'grad_norm': 0.8984375, 'learning_rate': 9.89108223276346e-05, 'epoch': 0.07}
  7%|▋         | 690/10365 [4:08:43<57:56:23, 21.56s/it]  7%|▋         | 691/10365 [4:09:04<57:28:34, 21.39s/it]  7%|▋         | 692/10365 [4:09:27<58:12:16, 21.66s/it]  7%|▋         | 693/10365 [4:09:52<61:19:49, 22.83s/it]  7%|▋         | 694/10365 [4:10:10<57:11:33, 21.29s/it]  7%|▋         | 695/10365 [4:10:31<56:43:03, 21.12s/it]  7%|▋         | 696/10365 [4:10:52<56:50:41, 21.16s/it]  7%|▋         | 697/10365 [4:11:12<56:14:20, 20.94s/it]  7%|▋         | 698/10365 [4:11:38<60:29:29, 22.53s/it]  7%|▋         | 699/10365 [4:11:59<59:14:33, 22.06s/it]  7%|▋         | 700/10365 [4:12:17<55:48:29, 20.79s/it]                                                        {'loss': 1.1849, 'grad_norm': 0.98828125, 'learning_rate': 9.887913790120541e-05, 'epoch': 0.07}
  7%|▋         | 700/10365 [4:12:17<55:48:29, 20.79s/it]  7%|▋         | 701/10365 [4:12:35<53:10:38, 19.81s/it]  7%|▋         | 702/10365 [4:12:55<53:25:48, 19.91s/it]  7%|▋         | 703/10365 [4:13:15<53:41:21, 20.00s/it]  7%|▋         | 704/10365 [4:13:39<57:11:02, 21.31s/it]  7%|▋         | 705/10365 [4:13:59<55:53:54, 20.83s/it]  7%|▋         | 706/10365 [4:14:16<52:39:51, 19.63s/it]  7%|▋         | 707/10365 [4:14:34<51:32:29, 19.21s/it]  7%|▋         | 708/10365 [4:14:55<52:23:43, 19.53s/it]  7%|▋         | 709/10365 [4:15:10<49:09:30, 18.33s/it]  7%|▋         | 710/10365 [4:15:35<54:11:01, 20.20s/it]                                                        {'loss': 1.1883, 'grad_norm': 0.97265625, 'learning_rate': 9.884700442682675e-05, 'epoch': 0.07}
  7%|▋         | 710/10365 [4:15:35<54:11:01, 20.20s/it]  7%|▋         | 711/10365 [4:15:56<54:53:21, 20.47s/it]  7%|▋         | 712/10365 [4:16:17<55:30:34, 20.70s/it]  7%|▋         | 713/10365 [4:16:43<59:43:13, 22.27s/it]  7%|▋         | 714/10365 [4:17:03<58:00:40, 21.64s/it]  7%|▋         | 715/10365 [4:17:27<59:38:46, 22.25s/it]  7%|▋         | 716/10365 [4:17:49<59:56:10, 22.36s/it]  7%|▋         | 717/10365 [4:18:12<60:18:19, 22.50s/it]  7%|▋         | 718/10365 [4:18:36<61:01:01, 22.77s/it]  7%|▋         | 719/10365 [4:18:59<61:44:25, 23.04s/it]  7%|▋         | 720/10365 [4:19:18<58:13:15, 21.73s/it]                                                        {'loss': 1.165, 'grad_norm': 1.0078125, 'learning_rate': 9.881442219970573e-05, 'epoch': 0.07}
  7%|▋         | 720/10365 [4:19:18<58:13:15, 21.73s/it]  7%|▋         | 721/10365 [4:19:47<64:04:37, 23.92s/it]  7%|▋         | 722/10365 [4:20:05<59:21:30, 22.16s/it]  7%|▋         | 723/10365 [4:20:24<56:30:23, 21.10s/it]  7%|▋         | 724/10365 [4:20:46<57:15:41, 21.38s/it]  7%|▋         | 725/10365 [4:21:02<53:26:48, 19.96s/it]  7%|▋         | 726/10365 [4:21:24<55:08:14, 20.59s/it]  7%|▋         | 727/10365 [4:21:46<56:01:51, 20.93s/it]  7%|▋         | 728/10365 [4:22:07<55:59:33, 20.92s/it]  7%|▋         | 729/10365 [4:22:25<53:15:13, 19.90s/it]  7%|▋         | 730/10365 [4:22:47<55:05:28, 20.58s/it]                                                        {'loss': 1.1971, 'grad_norm': 1.0234375, 'learning_rate': 9.878139151917215e-05, 'epoch': 0.07}
  7%|▋         | 730/10365 [4:22:47<55:05:28, 20.58s/it]  7%|▋         | 731/10365 [4:23:09<56:07:57, 20.98s/it]  7%|▋         | 732/10365 [4:23:32<57:56:04, 21.65s/it]  7%|▋         | 733/10365 [4:23:49<54:34:39, 20.40s/it]  7%|▋         | 734/10365 [4:24:07<52:29:42, 19.62s/it]  7%|▋         | 735/10365 [4:24:31<56:18:43, 21.05s/it]  7%|▋         | 736/10365 [4:24:53<56:46:30, 21.23s/it]  7%|▋         | 737/10365 [4:25:11<54:04:03, 20.22s/it]  7%|▋         | 738/10365 [4:25:30<53:21:07, 19.95s/it]  7%|▋         | 739/10365 [4:25:48<51:31:47, 19.27s/it]  7%|▋         | 740/10365 [4:26:11<54:12:54, 20.28s/it]                                                        {'loss': 1.2103, 'grad_norm': 1.0, 'learning_rate': 9.874791268867569e-05, 'epoch': 0.07}
  7%|▋         | 740/10365 [4:26:11<54:12:54, 20.28s/it]  7%|▋         | 741/10365 [4:26:32<55:06:44, 20.62s/it]  7%|▋         | 742/10365 [4:26:59<60:31:07, 22.64s/it]  7%|▋         | 743/10365 [4:27:18<56:52:29, 21.28s/it]  7%|▋         | 744/10365 [4:27:39<57:21:52, 21.46s/it]  7%|▋         | 745/10365 [4:27:56<53:26:56, 20.00s/it]  7%|▋         | 746/10365 [4:28:11<49:44:17, 18.61s/it]  7%|▋         | 747/10365 [4:28:31<50:27:28, 18.89s/it]  7%|▋         | 748/10365 [4:28:50<50:14:46, 18.81s/it]  7%|▋         | 749/10365 [4:29:11<52:46:07, 19.76s/it]  7%|▋         | 750/10365 [4:29:33<54:09:05, 20.28s/it]                                                        {'loss': 1.1829, 'grad_norm': 1.0234375, 'learning_rate': 9.871398601578318e-05, 'epoch': 0.07}
  7%|▋         | 750/10365 [4:29:33<54:09:05, 20.28s/it]  7%|▋         | 751/10365 [4:29:54<54:41:28, 20.48s/it]  7%|▋         | 752/10365 [4:30:14<54:20:57, 20.35s/it]  7%|▋         | 753/10365 [4:30:33<53:21:22, 19.98s/it]  7%|▋         | 754/10365 [4:30:55<54:59:23, 20.60s/it]  7%|▋         | 755/10365 [4:31:15<54:00:12, 20.23s/it]  7%|▋         | 756/10365 [4:31:33<52:30:10, 19.67s/it]  7%|▋         | 757/10365 [4:31:58<56:46:20, 21.27s/it]  7%|▋         | 758/10365 [4:32:19<56:51:24, 21.31s/it]  7%|▋         | 759/10365 [4:32:40<56:19:46, 21.11s/it]  7%|▋         | 760/10365 [4:33:01<56:15:30, 21.09s/it]                                                        {'loss': 1.2062, 'grad_norm': 0.9453125, 'learning_rate': 9.867961181217569e-05, 'epoch': 0.07}
  7%|▋         | 760/10365 [4:33:01<56:15:30, 21.09s/it]  7%|▋         | 761/10365 [4:33:19<54:04:14, 20.27s/it]  7%|▋         | 762/10365 [4:33:39<53:36:13, 20.10s/it]  7%|▋         | 763/10365 [4:34:02<55:47:51, 20.92s/it]  7%|▋         | 764/10365 [4:34:17<51:29:30, 19.31s/it]  7%|▋         | 765/10365 [4:34:36<50:55:56, 19.10s/it]  7%|▋         | 766/10365 [4:34:57<52:23:55, 19.65s/it]  7%|▋         | 767/10365 [4:35:26<59:51:14, 22.45s/it]  7%|▋         | 768/10365 [4:35:46<57:32:59, 21.59s/it]  7%|▋         | 769/10365 [4:36:09<59:16:50, 22.24s/it]  7%|▋         | 770/10365 [4:36:32<59:41:18, 22.39s/it]                                                        {'loss': 1.2116, 'grad_norm': 0.91796875, 'learning_rate': 9.864479039364574e-05, 'epoch': 0.07}
  7%|▋         | 770/10365 [4:36:32<59:41:18, 22.39s/it]  7%|▋         | 771/10365 [4:36:52<57:38:33, 21.63s/it]  7%|▋         | 772/10365 [4:37:12<56:22:55, 21.16s/it]  7%|▋         | 773/10365 [4:37:31<54:27:34, 20.44s/it]  7%|▋         | 774/10365 [4:37:49<52:45:08, 19.80s/it]  7%|▋         | 775/10365 [4:38:08<52:29:50, 19.71s/it]  7%|▋         | 776/10365 [4:38:24<49:13:59, 18.48s/it]  7%|▋         | 777/10365 [4:38:47<52:22:47, 19.67s/it]  8%|▊         | 778/10365 [4:39:04<50:58:51, 19.14s/it]  8%|▊         | 779/10365 [4:39:27<54:04:07, 20.31s/it]  8%|▊         | 780/10365 [4:39:53<58:14:49, 21.88s/it]                                                        {'loss': 1.1637, 'grad_norm': 1.1015625, 'learning_rate': 9.860952208009434e-05, 'epoch': 0.08}
  8%|▊         | 780/10365 [4:39:53<58:14:49, 21.88s/it]  8%|▊         | 781/10365 [4:40:14<57:09:25, 21.47s/it]  8%|▊         | 782/10365 [4:40:33<55:11:34, 20.73s/it]  8%|▊         | 783/10365 [4:40:54<56:01:59, 21.05s/it]  8%|▊         | 784/10365 [4:41:14<54:59:50, 20.66s/it]  8%|▊         | 785/10365 [4:41:38<57:09:45, 21.48s/it]  8%|▊         | 786/10365 [4:42:02<59:40:39, 22.43s/it]  8%|▊         | 787/10365 [4:42:19<55:30:21, 20.86s/it]  8%|▊         | 788/10365 [4:42:39<54:31:26, 20.50s/it]  8%|▊         | 789/10365 [4:43:01<55:36:48, 20.91s/it]  8%|▊         | 790/10365 [4:43:25<58:26:17, 21.97s/it]                                                        {'loss': 1.2126, 'grad_norm': 1.203125, 'learning_rate': 9.857380719552813e-05, 'epoch': 0.08}
  8%|▊         | 790/10365 [4:43:25<58:26:17, 21.97s/it]  8%|▊         | 791/10365 [4:43:41<53:05:25, 19.96s/it]  8%|▊         | 792/10365 [4:43:58<51:09:22, 19.24s/it]  8%|▊         | 793/10365 [4:44:18<51:36:51, 19.41s/it]  8%|▊         | 794/10365 [4:44:40<53:47:55, 20.24s/it]  8%|▊         | 795/10365 [4:45:07<58:45:00, 22.10s/it]  8%|▊         | 796/10365 [4:45:27<57:25:26, 21.60s/it]  8%|▊         | 797/10365 [4:45:47<55:52:02, 21.02s/it]  8%|▊         | 798/10365 [4:46:08<56:16:33, 21.18s/it]  8%|▊         | 799/10365 [4:46:35<60:58:29, 22.95s/it]  8%|▊         | 800/10365 [4:46:56<58:56:46, 22.19s/it]                                                        {'loss': 1.1893, 'grad_norm': 0.96875, 'learning_rate': 9.853764606805631e-05, 'epoch': 0.08}
  8%|▊         | 800/10365 [4:46:56<58:56:46, 22.19s/it]  8%|▊         | 801/10365 [4:47:17<58:09:04, 21.89s/it]  8%|▊         | 802/10365 [4:47:33<53:26:14, 20.12s/it]  8%|▊         | 803/10365 [4:47:53<53:03:36, 19.98s/it]  8%|▊         | 804/10365 [4:48:14<54:25:30, 20.49s/it]  8%|▊         | 805/10365 [4:48:37<56:26:43, 21.26s/it]  8%|▊         | 806/10365 [4:49:00<57:48:02, 21.77s/it]  8%|▊         | 807/10365 [4:49:27<61:56:58, 23.33s/it]  8%|▊         | 808/10365 [4:49:48<60:17:58, 22.71s/it]  8%|▊         | 809/10365 [4:50:09<58:49:50, 22.16s/it]  8%|▊         | 810/10365 [4:50:36<62:40:31, 23.61s/it]                                                        {'loss': 1.1868, 'grad_norm': 0.83203125, 'learning_rate': 9.85010390298877e-05, 'epoch': 0.08}
  8%|▊         | 810/10365 [4:50:36<62:40:31, 23.61s/it]  8%|▊         | 811/10365 [4:50:57<60:05:41, 22.64s/it]  8%|▊         | 812/10365 [4:51:23<63:11:02, 23.81s/it]  8%|▊         | 813/10365 [4:51:49<64:30:06, 24.31s/it]  8%|▊         | 814/10365 [4:52:07<59:33:37, 22.45s/it]  8%|▊         | 815/10365 [4:52:26<57:15:42, 21.59s/it]  8%|▊         | 816/10365 [4:52:51<59:37:58, 22.48s/it]  8%|▊         | 817/10365 [4:53:11<57:57:15, 21.85s/it]  8%|▊         | 818/10365 [4:53:34<58:33:13, 22.08s/it]  8%|▊         | 819/10365 [4:53:54<56:53:25, 21.45s/it]  8%|▊         | 820/10365 [4:54:13<55:17:07, 20.85s/it]                                                        {'loss': 1.2026, 'grad_norm': 0.9921875, 'learning_rate': 9.846398641732763e-05, 'epoch': 0.08}
  8%|▊         | 820/10365 [4:54:13<55:17:07, 20.85s/it]  8%|▊         | 821/10365 [4:54:38<58:00:34, 21.88s/it]  8%|▊         | 822/10365 [4:54:55<54:40:53, 20.63s/it]  8%|▊         | 823/10365 [4:55:18<56:15:51, 21.23s/it]  8%|▊         | 824/10365 [4:55:39<56:26:20, 21.30s/it]  8%|▊         | 825/10365 [4:56:06<60:13:37, 22.73s/it]  8%|▊         | 826/10365 [4:56:27<59:28:48, 22.45s/it]  8%|▊         | 827/10365 [4:56:50<59:25:36, 22.43s/it]  8%|▊         | 828/10365 [4:57:16<62:06:05, 23.44s/it]  8%|▊         | 829/10365 [4:57:36<60:04:31, 22.68s/it]  8%|▊         | 830/10365 [4:57:52<54:25:30, 20.55s/it]                                                        {'loss': 1.1905, 'grad_norm': 0.95703125, 'learning_rate': 9.842648857077492e-05, 'epoch': 0.08}
  8%|▊         | 830/10365 [4:57:52<54:25:30, 20.55s/it]  8%|▊         | 831/10365 [4:58:15<56:28:48, 21.33s/it]  8%|▊         | 832/10365 [4:58:39<58:37:32, 22.14s/it]  8%|▊         | 833/10365 [4:59:06<62:00:31, 23.42s/it]  8%|▊         | 834/10365 [4:59:24<57:45:37, 21.82s/it]  8%|▊         | 835/10365 [4:59:46<57:58:06, 21.90s/it]  8%|▊         | 836/10365 [5:00:07<57:40:05, 21.79s/it]  8%|▊         | 837/10365 [5:00:26<55:03:29, 20.80s/it]  8%|▊         | 838/10365 [5:00:45<53:59:28, 20.40s/it]  8%|▊         | 839/10365 [5:01:03<51:52:42, 19.61s/it]  8%|▊         | 840/10365 [5:01:29<57:06:02, 21.58s/it]                                                        {'loss': 1.1837, 'grad_norm': 1.0, 'learning_rate': 9.838854583471866e-05, 'epoch': 0.08}
  8%|▊         | 840/10365 [5:01:29<57:06:02, 21.58s/it]  8%|▊         | 841/10365 [5:01:53<58:46:34, 22.22s/it]  8%|▊         | 842/10365 [5:02:16<59:32:35, 22.51s/it]  8%|▊         | 843/10365 [5:02:36<57:34:15, 21.77s/it]  8%|▊         | 844/10365 [5:02:56<56:22:29, 21.32s/it]  8%|▊         | 845/10365 [5:03:17<56:04:34, 21.21s/it]  8%|▊         | 846/10365 [5:03:41<58:21:22, 22.07s/it]  8%|▊         | 847/10365 [5:03:57<53:31:34, 20.25s/it]  8%|▊         | 848/10365 [5:04:19<54:12:20, 20.50s/it]  8%|▊         | 849/10365 [5:04:42<56:32:53, 21.39s/it]  8%|▊         | 850/10365 [5:05:03<56:21:20, 21.32s/it]                                                        {'loss': 1.1897, 'grad_norm': 0.95703125, 'learning_rate': 9.835015855773516e-05, 'epoch': 0.08}
  8%|▊         | 850/10365 [5:05:03<56:21:20, 21.32s/it]  8%|▊         | 851/10365 [5:05:21<53:26:32, 20.22s/it]  8%|▊         | 852/10365 [5:05:41<53:39:50, 20.31s/it]  8%|▊         | 853/10365 [5:05:59<51:41:35, 19.56s/it]  8%|▊         | 854/10365 [5:06:18<51:31:10, 19.50s/it]  8%|▊         | 855/10365 [5:06:42<54:39:45, 20.69s/it]  8%|▊         | 856/10365 [5:07:05<56:13:00, 21.28s/it]  8%|▊         | 857/10365 [5:07:23<53:43:31, 20.34s/it]  8%|▊         | 858/10365 [5:07:41<51:52:44, 19.64s/it]  8%|▊         | 859/10365 [5:07:58<50:12:44, 19.02s/it]  8%|▊         | 860/10365 [5:08:19<51:28:06, 19.49s/it]                                                        {'loss': 1.175, 'grad_norm': 0.95703125, 'learning_rate': 9.831132709248461e-05, 'epoch': 0.08}
  8%|▊         | 860/10365 [5:08:19<51:28:06, 19.49s/it]  8%|▊         | 861/10365 [5:08:34<48:05:06, 18.21s/it]  8%|▊         | 862/10365 [5:09:03<56:44:11, 21.49s/it]  8%|▊         | 863/10365 [5:09:25<56:55:07, 21.56s/it]  8%|▊         | 864/10365 [5:09:51<60:22:14, 22.87s/it]  8%|▊         | 865/10365 [5:10:14<60:21:52, 22.87s/it]  8%|▊         | 866/10365 [5:10:34<57:57:50, 21.97s/it]  8%|▊         | 867/10365 [5:10:53<55:44:02, 21.12s/it]  8%|▊         | 868/10365 [5:11:15<56:13:03, 21.31s/it]  8%|▊         | 869/10365 [5:11:34<54:55:22, 20.82s/it]  8%|▊         | 870/10365 [5:11:57<56:41:02, 21.49s/it]                                                        {'loss': 1.1736, 'grad_norm': 1.125, 'learning_rate': 9.827205179570798e-05, 'epoch': 0.08}
  8%|▊         | 870/10365 [5:11:57<56:41:02, 21.49s/it]  8%|▊         | 871/10365 [5:12:17<54:50:44, 20.80s/it]  8%|▊         | 872/10365 [5:12:39<56:21:21, 21.37s/it]  8%|▊         | 873/10365 [5:12:59<54:45:32, 20.77s/it]  8%|▊         | 874/10365 [5:13:30<63:26:46, 24.07s/it]  8%|▊         | 875/10365 [5:14:00<67:30:38, 25.61s/it]  8%|▊         | 876/10365 [5:14:23<65:51:43, 24.99s/it]  8%|▊         | 877/10365 [5:14:45<63:40:02, 24.16s/it]  8%|▊         | 878/10365 [5:15:02<57:58:03, 22.00s/it]  8%|▊         | 879/10365 [5:15:32<64:06:13, 24.33s/it]  8%|▊         | 880/10365 [5:15:52<60:25:29, 22.93s/it]                                                        {'loss': 1.1582, 'grad_norm': 0.9140625, 'learning_rate': 9.823233302822363e-05, 'epoch': 0.08}
  8%|▊         | 880/10365 [5:15:52<60:25:29, 22.93s/it]  8%|▊         | 881/10365 [5:16:12<58:33:48, 22.23s/it]  9%|▊         | 882/10365 [5:16:32<56:31:50, 21.46s/it]  9%|▊         | 883/10365 [5:16:52<55:18:27, 21.00s/it]  9%|▊         | 884/10365 [5:17:10<53:23:12, 20.27s/it]  9%|▊         | 885/10365 [5:17:30<53:08:30, 20.18s/it]  9%|▊         | 886/10365 [5:17:52<54:25:06, 20.67s/it]  9%|▊         | 887/10365 [5:18:16<56:53:48, 21.61s/it]  9%|▊         | 888/10365 [5:18:35<54:26:37, 20.68s/it]  9%|▊         | 889/10365 [5:18:53<52:49:33, 20.07s/it]  9%|▊         | 890/10365 [5:19:13<52:59:07, 20.13s/it]                                                        {'loss': 1.1972, 'grad_norm': 1.046875, 'learning_rate': 9.819217115492411e-05, 'epoch': 0.09}
  9%|▊         | 890/10365 [5:19:14<52:59:07, 20.13s/it]  9%|▊         | 891/10365 [5:19:33<52:44:57, 20.04s/it]  9%|▊         | 892/10365 [5:19:56<55:10:11, 20.97s/it]  9%|▊         | 893/10365 [5:20:17<54:55:25, 20.87s/it]  9%|▊         | 894/10365 [5:20:38<55:18:25, 21.02s/it]  9%|▊         | 895/10365 [5:20:58<54:04:37, 20.56s/it]  9%|▊         | 896/10365 [5:21:26<59:38:13, 22.67s/it]  9%|▊         | 897/10365 [5:21:47<58:21:07, 22.19s/it]  9%|▊         | 898/10365 [5:22:09<58:39:24, 22.31s/it]  9%|▊         | 899/10365 [5:22:33<59:27:57, 22.62s/it]  9%|▊         | 900/10365 [5:22:52<57:08:39, 21.73s/it]                                                        {'loss': 1.1679, 'grad_norm': 1.03125, 'learning_rate': 9.815156654477265e-05, 'epoch': 0.09}
  9%|▊         | 900/10365 [5:22:52<57:08:39, 21.73s/it]  9%|▊         | 901/10365 [5:23:17<59:31:50, 22.64s/it]  9%|▊         | 902/10365 [5:23:46<64:15:55, 24.45s/it]  9%|▊         | 903/10365 [5:24:03<58:57:41, 22.43s/it]  9%|▊         | 904/10365 [5:24:23<56:52:38, 21.64s/it]  9%|▊         | 905/10365 [5:24:49<60:29:15, 23.02s/it]  9%|▊         | 906/10365 [5:25:09<57:43:17, 21.97s/it]  9%|▉         | 907/10365 [5:25:30<57:24:08, 21.85s/it]  9%|▉         | 908/10365 [5:25:51<56:16:46, 21.42s/it]  9%|▉         | 909/10365 [5:26:14<57:13:35, 21.79s/it]  9%|▉         | 910/10365 [5:26:33<55:27:36, 21.12s/it]                                                        {'loss': 1.2063, 'grad_norm': 0.98828125, 'learning_rate': 9.811051957079993e-05, 'epoch': 0.09}
  9%|▉         | 910/10365 [5:26:33<55:27:36, 21.12s/it]  9%|▉         | 911/10365 [5:26:54<55:18:55, 21.06s/it]  9%|▉         | 912/10365 [5:27:17<56:54:54, 21.68s/it]  9%|▉         | 913/10365 [5:27:34<53:26:08, 20.35s/it]  9%|▉         | 914/10365 [5:28:00<57:21:17, 21.85s/it]  9%|▉         | 915/10365 [5:28:20<55:45:12, 21.24s/it]  9%|▉         | 916/10365 [5:28:47<60:13:45, 22.95s/it]  9%|▉         | 917/10365 [5:29:10<60:41:22, 23.12s/it]  9%|▉         | 918/10365 [5:29:32<59:29:20, 22.67s/it]  9%|▉         | 919/10365 [5:29:51<57:05:22, 21.76s/it]  9%|▉         | 920/10365 [5:30:13<56:49:22, 21.66s/it]                                                        {'loss': 1.196, 'grad_norm': 0.9375, 'learning_rate': 9.806903061010055e-05, 'epoch': 0.09}
  9%|▉         | 920/10365 [5:30:13<56:49:22, 21.66s/it]  9%|▉         | 921/10365 [5:30:38<60:00:04, 22.87s/it]  9%|▉         | 922/10365 [5:30:56<55:58:43, 21.34s/it]  9%|▉         | 923/10365 [5:31:14<52:54:30, 20.17s/it]  9%|▉         | 924/10365 [5:31:36<54:14:51, 20.69s/it]  9%|▉         | 925/10365 [5:31:58<55:21:59, 21.11s/it]  9%|▉         | 926/10365 [5:32:16<53:10:56, 20.28s/it]  9%|▉         | 927/10365 [5:32:42<57:54:19, 22.09s/it]  9%|▉         | 928/10365 [5:32:58<52:54:25, 20.18s/it]  9%|▉         | 929/10365 [5:33:14<49:56:41, 19.05s/it]  9%|▉         | 930/10365 [5:33:30<47:35:30, 18.16s/it]                                                        {'loss': 1.1748, 'grad_norm': 1.0546875, 'learning_rate': 9.802710004382964e-05, 'epoch': 0.09}
  9%|▉         | 930/10365 [5:33:30<47:35:30, 18.16s/it]  9%|▉         | 931/10365 [5:33:53<50:45:16, 19.37s/it]  9%|▉         | 932/10365 [5:34:16<54:12:30, 20.69s/it]  9%|▉         | 933/10365 [5:34:38<54:33:24, 20.82s/it]  9%|▉         | 934/10365 [5:35:00<55:35:00, 21.22s/it]  9%|▉         | 935/10365 [5:35:26<59:15:37, 22.62s/it]  9%|▉         | 936/10365 [5:35:45<56:22:22, 21.52s/it]  9%|▉         | 937/10365 [5:36:09<58:44:01, 22.43s/it]  9%|▉         | 938/10365 [5:36:29<56:41:16, 21.65s/it]  9%|▉         | 939/10365 [5:36:51<57:10:20, 21.84s/it]  9%|▉         | 940/10365 [5:37:10<54:47:56, 20.93s/it]                                                        {'loss': 1.1996, 'grad_norm': 0.8359375, 'learning_rate': 9.798472825719924e-05, 'epoch': 0.09}
  9%|▉         | 940/10365 [5:37:10<54:47:56, 20.93s/it]  9%|▉         | 941/10365 [5:37:31<54:55:32, 20.98s/it]  9%|▉         | 942/10365 [5:37:52<54:30:00, 20.82s/it]  9%|▉         | 943/10365 [5:38:12<54:21:28, 20.77s/it]  9%|▉         | 944/10365 [5:38:33<54:37:31, 20.87s/it]  9%|▉         | 945/10365 [5:38:49<50:31:56, 19.31s/it]  9%|▉         | 946/10365 [5:39:08<50:00:43, 19.11s/it]  9%|▉         | 947/10365 [5:39:31<53:01:08, 20.27s/it]  9%|▉         | 948/10365 [5:39:51<53:17:33, 20.37s/it]  9%|▉         | 949/10365 [5:40:11<52:45:41, 20.17s/it]  9%|▉         | 950/10365 [5:40:29<50:55:06, 19.47s/it]                                                        {'loss': 1.1757, 'grad_norm': 1.1171875, 'learning_rate': 9.794191563947493e-05, 'epoch': 0.09}
  9%|▉         | 950/10365 [5:40:29<50:55:06, 19.47s/it]  9%|▉         | 951/10365 [5:40:48<50:42:01, 19.39s/it]  9%|▉         | 952/10365 [5:41:09<51:44:46, 19.79s/it]  9%|▉         | 953/10365 [5:41:35<56:26:39, 21.59s/it]  9%|▉         | 954/10365 [5:41:55<55:18:57, 21.16s/it]  9%|▉         | 955/10365 [5:42:14<53:52:18, 20.61s/it]  9%|▉         | 956/10365 [5:42:38<56:12:36, 21.51s/it]  9%|▉         | 957/10365 [5:42:58<55:37:03, 21.28s/it]  9%|▉         | 958/10365 [5:43:18<54:11:36, 20.74s/it]  9%|▉         | 959/10365 [5:43:34<50:54:02, 19.48s/it]  9%|▉         | 960/10365 [5:43:52<49:38:21, 19.00s/it]                                                        {'loss': 1.1737, 'grad_norm': 0.91796875, 'learning_rate': 9.789866258397211e-05, 'epoch': 0.09}
  9%|▉         | 960/10365 [5:43:52<49:38:21, 19.00s/it]  9%|▉         | 961/10365 [5:44:19<55:50:41, 21.38s/it]  9%|▉         | 962/10365 [5:44:40<55:36:21, 21.29s/it]  9%|▉         | 963/10365 [5:45:03<56:23:31, 21.59s/it]  9%|▉         | 964/10365 [5:45:28<59:36:21, 22.83s/it]  9%|▉         | 965/10365 [5:45:51<59:29:46, 22.79s/it]  9%|▉         | 966/10365 [5:46:11<57:17:16, 21.94s/it]  9%|▉         | 967/10365 [5:46:35<58:51:06, 22.54s/it]  9%|▉         | 968/10365 [5:46:58<59:38:16, 22.85s/it]  9%|▉         | 969/10365 [5:47:23<61:20:20, 23.50s/it]  9%|▉         | 970/10365 [5:47:46<60:23:51, 23.14s/it]                                                        {'loss': 1.1432, 'grad_norm': 1.2109375, 'learning_rate': 9.785496948805243e-05, 'epoch': 0.09}
  9%|▉         | 970/10365 [5:47:46<60:23:51, 23.14s/it]  9%|▉         | 971/10365 [5:48:02<54:48:47, 21.01s/it]  9%|▉         | 972/10365 [5:48:31<61:06:31, 23.42s/it]  9%|▉         | 973/10365 [5:48:51<58:33:52, 22.45s/it]  9%|▉         | 974/10365 [5:49:16<60:10:03, 23.07s/it]  9%|▉         | 975/10365 [5:49:36<57:48:57, 22.17s/it]  9%|▉         | 976/10365 [5:49:54<54:55:34, 21.06s/it]  9%|▉         | 977/10365 [5:50:15<54:45:48, 21.00s/it]  9%|▉         | 978/10365 [5:50:35<53:58:18, 20.70s/it]  9%|▉         | 979/10365 [5:50:56<53:58:35, 20.70s/it]  9%|▉         | 980/10365 [5:51:17<54:11:27, 20.79s/it]                                                        {'loss': 1.1586, 'grad_norm': 0.921875, 'learning_rate': 9.781083675312019e-05, 'epoch': 0.09}
  9%|▉         | 980/10365 [5:51:17<54:11:27, 20.79s/it]  9%|▉         | 981/10365 [5:51:32<50:01:22, 19.19s/it]  9%|▉         | 982/10365 [5:51:49<47:53:54, 18.38s/it]  9%|▉         | 983/10365 [5:52:08<48:43:03, 18.69s/it]  9%|▉         | 984/10365 [5:52:30<51:31:40, 19.77s/it] 10%|▉         | 985/10365 [5:52:57<56:34:58, 21.72s/it] 10%|▉         | 986/10365 [5:53:17<55:52:11, 21.44s/it] 10%|▉         | 987/10365 [5:53:44<59:44:35, 22.93s/it] 10%|▉         | 988/10365 [5:54:09<61:16:00, 23.52s/it] 10%|▉         | 989/10365 [5:54:29<58:43:03, 22.55s/it] 10%|▉         | 990/10365 [5:54:50<57:23:31, 22.04s/it]                                                        {'loss': 1.1628, 'grad_norm': 1.046875, 'learning_rate': 9.776626478461859e-05, 'epoch': 0.1}
 10%|▉         | 990/10365 [5:54:50<57:23:31, 22.04s/it] 10%|▉         | 991/10365 [5:55:11<56:44:05, 21.79s/it] 10%|▉         | 992/10365 [5:55:29<53:57:15, 20.72s/it] 10%|▉         | 993/10365 [5:55:51<54:31:43, 20.95s/it] 10%|▉         | 994/10365 [5:56:11<54:14:53, 20.84s/it] 10%|▉         | 995/10365 [5:56:35<56:38:11, 21.76s/it] 10%|▉         | 996/10365 [5:56:54<54:19:16, 20.87s/it] 10%|▉         | 997/10365 [5:57:14<53:47:08, 20.67s/it] 10%|▉         | 998/10365 [5:57:42<59:08:41, 22.73s/it] 10%|▉         | 999/10365 [5:58:07<60:59:53, 23.45s/it] 10%|▉         | 1000/10365 [5:58:29<59:56:27, 23.04s/it]                                                         {'loss': 1.1357, 'grad_norm': 0.9921875, 'learning_rate': 9.7721253992026e-05, 'epoch': 0.1}
 10%|▉         | 1000/10365 [5:58:29<59:56:27, 23.04s/it][INFO|trainer.py:3719] 2024-05-30 16:52:54,814 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-30 16:52:54,814 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-30 16:52:54,814 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:47,  1.76s/it][A
  5%|▍         | 3/63 [00:08<03:16,  3.27s/it][A
  6%|▋         | 4/63 [00:13<03:47,  3.86s/it][A
  8%|▊         | 5/63 [00:18<04:06,  4.25s/it][A
 10%|▉         | 6/63 [00:23<04:11,  4.41s/it][A
 11%|█         | 7/63 [00:28<04:16,  4.58s/it][A
 13%|█▎        | 8/63 [00:33<04:14,  4.62s/it][A
 14%|█▍        | 9/63 [00:38<04:16,  4.75s/it][A
 16%|█▌        | 10/63 [00:43<04:25,  5.01s/it][A
 17%|█▋        | 11/63 [00:49<04:34,  5.28s/it][A
 19%|█▉        | 12/63 [00:54<04:20,  5.12s/it][A
 21%|██        | 13/63 [00:59<04:15,  5.11s/it][A
 22%|██▏       | 14/63 [01:04<04:02,  4.95s/it][A
 24%|██▍       | 15/63 [01:09<04:00,  5.01s/it][A
 25%|██▌       | 16/63 [01:14<03:54,  5.00s/it][A
 27%|██▋       | 17/63 [01:19<03:51,  5.02s/it][A
 29%|██▊       | 18/63 [01:24<03:51,  5.15s/it][A
 30%|███       | 19/63 [01:30<03:52,  5.29s/it][A
 32%|███▏      | 20/63 [01:35<03:51,  5.38s/it][A
 33%|███▎      | 21/63 [01:40<03:34,  5.11s/it][A
 35%|███▍      | 22/63 [01:46<03:44,  5.47s/it][A
 37%|███▋      | 23/63 [01:50<03:17,  4.93s/it][A
 38%|███▊      | 24/63 [01:56<03:20,  5.14s/it][A
 40%|███▉      | 25/63 [02:01<03:21,  5.31s/it][A
 41%|████▏     | 26/63 [02:06<03:11,  5.18s/it][A
 43%|████▎     | 27/63 [02:12<03:12,  5.34s/it][A
 44%|████▍     | 28/63 [02:18<03:14,  5.55s/it][A
 46%|████▌     | 29/63 [02:25<03:27,  6.10s/it][A
 48%|████▊     | 30/63 [02:30<03:04,  5.59s/it][A
 49%|████▉     | 31/63 [02:35<02:54,  5.44s/it][A
 51%|█████     | 32/63 [02:39<02:35,  5.03s/it][A
 52%|█████▏    | 33/63 [02:45<02:38,  5.29s/it][A
 54%|█████▍    | 34/63 [02:48<02:18,  4.78s/it][A
 56%|█████▌    | 35/63 [02:53<02:13,  4.78s/it][A
 57%|█████▋    | 36/63 [02:57<02:04,  4.61s/it][A
 59%|█████▊    | 37/63 [03:04<02:15,  5.20s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.31s/it][A
 62%|██████▏   | 39/63 [03:14<02:01,  5.07s/it][A
 63%|██████▎   | 40/63 [03:19<01:57,  5.10s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.15s/it][A
 67%|██████▋   | 42/63 [03:31<01:59,  5.69s/it][A
 68%|██████▊   | 43/63 [03:37<01:53,  5.68s/it][A
 70%|██████▉   | 44/63 [03:42<01:42,  5.40s/it][A
 71%|███████▏  | 45/63 [03:49<01:45,  5.86s/it][A
 73%|███████▎  | 46/63 [03:54<01:38,  5.81s/it][A
 75%|███████▍  | 47/63 [04:00<01:32,  5.78s/it][A
 76%|███████▌  | 48/63 [04:07<01:31,  6.11s/it][A
 78%|███████▊  | 49/63 [04:11<01:18,  5.63s/it][A
 79%|███████▉  | 50/63 [04:18<01:16,  5.90s/it][A
 81%|████████  | 51/63 [04:24<01:09,  5.79s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.13s/it][A
 84%|████████▍ | 53/63 [04:36<00:59,  5.92s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.80s/it][A
 87%|████████▋ | 55/63 [04:46<00:42,  5.37s/it][A
 89%|████████▉ | 56/63 [04:51<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.31s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.21s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.15s/it][A
 95%|█████████▌| 60/63 [05:10<00:14,  4.89s/it][A
 97%|█████████▋| 61/63 [05:17<00:10,  5.41s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.67s/it][A
100%|██████████| 63/63 [05:30<00:00,  5.83s/it][A                                                         
                                               [A{'eval_loss': 1.170988917350769, 'eval_runtime': 336.5277, 'eval_samples_per_second': 14.858, 'eval_steps_per_second': 0.187, 'epoch': 0.1}
 10%|▉         | 1000/10365 [6:04:05<59:56:27, 23.04s/it]
100%|██████████| 63/63 [05:30<00:00,  5.83s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-30 16:58:33,643 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-1000
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-30 16:58:33,701 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-30 16:58:33,701 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-1000/special_tokens_map.json
 10%|▉         | 1001/10365 [6:04:27<321:41:55, 123.68s/it] 10%|▉         | 1002/10365 [6:04:52<243:59:37, 93.81s/it]  10%|▉         | 1003/10365 [6:05:17<190:14:30, 73.15s/it] 10%|▉         | 1004/10365 [6:05:39<151:01:08, 58.08s/it] 10%|▉         | 1005/10365 [6:06:03<124:07:19, 47.74s/it] 10%|▉         | 1006/10365 [6:06:20<99:52:10, 38.42s/it]  10%|▉         | 1007/10365 [6:06:40<85:28:12, 32.88s/it] 10%|▉         | 1008/10365 [6:07:08<82:14:44, 31.64s/it] 10%|▉         | 1009/10365 [6:07:34<77:28:53, 29.81s/it] 10%|▉         | 1010/10365 [6:07:54<70:05:25, 26.97s/it]                                                         {'loss': 1.1848, 'grad_norm': 0.921875, 'learning_rate': 9.767580478885232e-05, 'epoch': 0.1}
 10%|▉         | 1010/10365 [6:07:54<70:05:25, 26.97s/it] 10%|▉         | 1011/10365 [6:08:15<64:50:39, 24.96s/it] 10%|▉         | 1012/10365 [6:08:35<61:27:34, 23.66s/it] 10%|▉         | 1013/10365 [6:08:51<55:43:40, 21.45s/it] 10%|▉         | 1014/10365 [6:09:12<54:56:30, 21.15s/it] 10%|▉         | 1015/10365 [6:09:38<59:01:24, 22.73s/it] 10%|▉         | 1016/10365 [6:09:59<57:35:59, 22.18s/it] 10%|▉         | 1017/10365 [6:10:24<59:43:15, 23.00s/it] 10%|▉         | 1018/10365 [6:10:52<63:29:38, 24.45s/it] 10%|▉         | 1019/10365 [6:11:14<61:17:17, 23.61s/it] 10%|▉         | 1020/10365 [6:11:30<55:24:17, 21.34s/it]                                                         {'loss': 1.1754, 'grad_norm': 0.98828125, 'learning_rate': 9.762991759263493e-05, 'epoch': 0.1}
 10%|▉         | 1020/10365 [6:11:30<55:24:17, 21.34s/it] 10%|▉         | 1021/10365 [6:11:55<58:41:50, 22.61s/it] 10%|▉         | 1022/10365 [6:12:16<56:57:28, 21.95s/it] 10%|▉         | 1023/10365 [6:12:38<57:08:26, 22.02s/it] 10%|▉         | 1024/10365 [6:12:56<54:27:25, 20.99s/it] 10%|▉         | 1025/10365 [6:13:15<52:29:42, 20.23s/it] 10%|▉         | 1026/10365 [6:13:36<52:48:36, 20.36s/it] 10%|▉         | 1027/10365 [6:13:56<52:40:34, 20.31s/it] 10%|▉         | 1028/10365 [6:14:14<51:08:26, 19.72s/it] 10%|▉         | 1029/10365 [6:14:34<50:54:28, 19.63s/it] 10%|▉         | 1030/10365 [6:14:56<53:18:18, 20.56s/it]                                                         {'loss': 1.1758, 'grad_norm': 0.98828125, 'learning_rate': 9.758359282493517e-05, 'epoch': 0.1}
 10%|▉         | 1030/10365 [6:14:56<53:18:18, 20.56s/it] 10%|▉         | 1031/10365 [6:15:25<60:01:42, 23.15s/it] 10%|▉         | 1032/10365 [6:15:46<58:09:10, 22.43s/it] 10%|▉         | 1033/10365 [6:16:10<59:19:41, 22.89s/it] 10%|▉         | 1034/10365 [6:16:33<59:17:45, 22.88s/it] 10%|▉         | 1035/10365 [6:16:52<56:06:45, 21.65s/it] 10%|▉         | 1036/10365 [6:17:10<53:09:47, 20.52s/it] 10%|█         | 1037/10365 [6:17:31<53:32:04, 20.66s/it] 10%|█         | 1038/10365 [6:17:53<54:31:04, 21.04s/it] 10%|█         | 1039/10365 [6:18:10<51:35:06, 19.91s/it] 10%|█         | 1040/10365 [6:18:32<53:27:35, 20.64s/it]                                                         {'loss': 1.1596, 'grad_norm': 0.921875, 'learning_rate': 9.753683091133419e-05, 'epoch': 0.1}
 10%|█         | 1040/10365 [6:18:32<53:27:35, 20.64s/it] 10%|█         | 1041/10365 [6:18:52<52:32:20, 20.29s/it] 10%|█         | 1042/10365 [6:19:16<55:58:53, 21.62s/it] 10%|█         | 1043/10365 [6:19:35<53:28:28, 20.65s/it] 10%|█         | 1044/10365 [6:19:59<56:34:26, 21.85s/it] 10%|█         | 1045/10365 [6:20:20<55:56:30, 21.61s/it] 10%|█         | 1046/10365 [6:20:39<53:56:19, 20.84s/it] 10%|█         | 1047/10365 [6:20:59<53:02:07, 20.49s/it] 10%|█         | 1048/10365 [6:21:18<51:51:39, 20.04s/it] 10%|█         | 1049/10365 [6:21:45<56:51:43, 21.97s/it] 10%|█         | 1050/10365 [6:22:11<60:07:02, 23.23s/it]                                                         {'loss': 1.1577, 'grad_norm': 0.8984375, 'learning_rate': 9.748963228142923e-05, 'epoch': 0.1}
 10%|█         | 1050/10365 [6:22:11<60:07:02, 23.23s/it] 10%|█         | 1051/10365 [6:22:33<59:33:41, 23.02s/it] 10%|█         | 1052/10365 [6:22:58<61:07:27, 23.63s/it] 10%|█         | 1053/10365 [6:23:18<58:14:38, 22.52s/it] 10%|█         | 1054/10365 [6:23:39<56:53:20, 22.00s/it] 10%|█         | 1055/10365 [6:24:00<55:52:22, 21.60s/it] 10%|█         | 1056/10365 [6:24:22<56:11:03, 21.73s/it] 10%|█         | 1057/10365 [6:24:43<55:24:07, 21.43s/it] 10%|█         | 1058/10365 [6:25:02<53:33:16, 20.72s/it] 10%|█         | 1059/10365 [6:25:20<51:53:59, 20.08s/it] 10%|█         | 1060/10365 [6:25:41<52:38:59, 20.37s/it]                                                         {'loss': 1.1798, 'grad_norm': 1.015625, 'learning_rate': 9.744199736882955e-05, 'epoch': 0.1}
 10%|█         | 1060/10365 [6:25:41<52:38:59, 20.37s/it] 10%|█         | 1061/10365 [6:25:58<50:06:57, 19.39s/it] 10%|█         | 1062/10365 [6:26:22<53:15:03, 20.61s/it] 10%|█         | 1063/10365 [6:26:44<54:17:28, 21.01s/it] 10%|█         | 1064/10365 [6:27:06<55:19:29, 21.41s/it] 10%|█         | 1065/10365 [6:27:24<52:38:32, 20.38s/it] 10%|█         | 1066/10365 [6:27:45<53:07:33, 20.57s/it] 10%|█         | 1067/10365 [6:28:06<53:07:14, 20.57s/it] 10%|█         | 1068/10365 [6:28:25<52:07:18, 20.18s/it] 10%|█         | 1069/10365 [6:28:44<51:07:47, 19.80s/it] 10%|█         | 1070/10365 [6:29:04<51:41:25, 20.02s/it]                                                         {'loss': 1.1773, 'grad_norm': 0.98828125, 'learning_rate': 9.739392661115255e-05, 'epoch': 0.1}
 10%|█         | 1070/10365 [6:29:04<51:41:25, 20.02s/it] 10%|█         | 1071/10365 [6:29:26<52:42:59, 20.42s/it] 10%|█         | 1072/10365 [6:29:46<52:57:56, 20.52s/it] 10%|█         | 1073/10365 [6:30:08<54:02:43, 20.94s/it] 10%|█         | 1074/10365 [6:30:31<54:58:19, 21.30s/it] 10%|█         | 1075/10365 [6:30:59<60:33:57, 23.47s/it] 10%|█         | 1076/10365 [6:31:21<59:30:15, 23.06s/it] 10%|█         | 1077/10365 [6:31:41<56:59:16, 22.09s/it] 10%|█         | 1078/10365 [6:32:00<54:47:53, 21.24s/it] 10%|█         | 1079/10365 [6:32:25<57:31:18, 22.30s/it] 10%|█         | 1080/10365 [6:32:43<54:16:15, 21.04s/it]                                                         {'loss': 1.14, 'grad_norm': 1.078125, 'learning_rate': 9.734542045001966e-05, 'epoch': 0.1}
 10%|█         | 1080/10365 [6:32:43<54:16:15, 21.04s/it] 10%|█         | 1081/10365 [6:33:06<55:46:02, 21.62s/it] 10%|█         | 1082/10365 [6:33:20<49:33:56, 19.22s/it] 10%|█         | 1083/10365 [6:33:43<52:52:33, 20.51s/it] 10%|█         | 1084/10365 [6:34:05<54:04:26, 20.97s/it] 10%|█         | 1085/10365 [6:34:28<55:22:31, 21.48s/it] 10%|█         | 1086/10365 [6:34:47<53:46:51, 20.87s/it] 10%|█         | 1087/10365 [6:35:17<60:21:14, 23.42s/it] 10%|█         | 1088/10365 [6:35:41<61:12:15, 23.75s/it] 11%|█         | 1089/10365 [6:36:00<57:16:49, 22.23s/it] 11%|█         | 1090/10365 [6:36:18<54:16:10, 21.06s/it]                                                         {'loss': 1.1483, 'grad_norm': 0.93359375, 'learning_rate': 9.72964793310523e-05, 'epoch': 0.11}
 11%|█         | 1090/10365 [6:36:18<54:16:10, 21.06s/it] 11%|█         | 1091/10365 [6:36:42<56:38:38, 21.99s/it] 11%|█         | 1092/10365 [6:37:00<52:52:01, 20.52s/it] 11%|█         | 1093/10365 [6:37:20<52:57:47, 20.56s/it] 11%|█         | 1094/10365 [6:37:42<54:04:55, 21.00s/it] 11%|█         | 1095/10365 [6:38:04<54:54:28, 21.32s/it] 11%|█         | 1096/10365 [6:38:26<55:25:38, 21.53s/it] 11%|█         | 1097/10365 [6:38:46<53:44:24, 20.87s/it] 11%|█         | 1098/10365 [6:39:09<55:49:38, 21.69s/it] 11%|█         | 1099/10365 [6:39:28<53:16:48, 20.70s/it] 11%|█         | 1100/10365 [6:39:48<53:04:45, 20.62s/it]                                                         {'loss': 1.146, 'grad_norm': 0.921875, 'learning_rate': 9.724710370386787e-05, 'epoch': 0.11}
 11%|█         | 1100/10365 [6:39:48<53:04:45, 20.62s/it] 11%|█         | 1101/10365 [6:40:08<52:50:42, 20.54s/it] 11%|█         | 1102/10365 [6:40:32<55:13:20, 21.46s/it] 11%|█         | 1103/10365 [6:40:52<53:45:17, 20.89s/it] 11%|█         | 1104/10365 [6:41:08<49:57:17, 19.42s/it] 11%|█         | 1105/10365 [6:41:27<49:58:41, 19.43s/it] 11%|█         | 1106/10365 [6:41:49<51:32:20, 20.04s/it] 11%|█         | 1107/10365 [6:42:07<50:24:05, 19.60s/it] 11%|█         | 1108/10365 [6:42:26<49:48:40, 19.37s/it] 11%|█         | 1109/10365 [6:42:44<48:34:32, 18.89s/it] 11%|█         | 1110/10365 [6:43:05<50:34:26, 19.67s/it]                                                         {'loss': 1.1699, 'grad_norm': 1.0234375, 'learning_rate': 9.71972940220755e-05, 'epoch': 0.11}
 11%|█         | 1110/10365 [6:43:05<50:34:26, 19.67s/it] 11%|█         | 1111/10365 [6:43:26<51:15:32, 19.94s/it] 11%|█         | 1112/10365 [6:43:49<53:37:08, 20.86s/it] 11%|█         | 1113/10365 [6:44:10<53:44:27, 20.91s/it] 11%|█         | 1114/10365 [6:44:29<52:23:35, 20.39s/it] 11%|█         | 1115/10365 [6:44:47<50:40:22, 19.72s/it] 11%|█         | 1116/10365 [6:45:05<49:31:06, 19.27s/it] 11%|█         | 1117/10365 [6:45:28<52:18:24, 20.36s/it] 11%|█         | 1118/10365 [6:45:46<50:18:10, 19.58s/it] 11%|█         | 1119/10365 [6:46:05<49:48:15, 19.39s/it] 11%|█         | 1120/10365 [6:46:31<55:08:22, 21.47s/it]                                                         {'loss': 1.1199, 'grad_norm': 1.0390625, 'learning_rate': 9.714705074327197e-05, 'epoch': 0.11}
 11%|█         | 1120/10365 [6:46:31<55:08:22, 21.47s/it] 11%|█         | 1121/10365 [6:46:59<60:00:13, 23.37s/it] 11%|█         | 1122/10365 [6:47:20<58:04:13, 22.62s/it] 11%|█         | 1123/10365 [6:47:44<59:19:07, 23.11s/it] 11%|█         | 1124/10365 [6:48:07<59:13:24, 23.07s/it] 11%|█         | 1125/10365 [6:48:28<57:15:08, 22.31s/it] 11%|█         | 1126/10365 [6:48:47<54:59:10, 21.43s/it] 11%|█         | 1127/10365 [6:49:06<53:12:01, 20.73s/it] 11%|█         | 1128/10365 [6:49:31<56:08:02, 21.88s/it] 11%|█         | 1129/10365 [6:49:53<56:07:51, 21.88s/it] 11%|█         | 1130/10365 [6:50:12<54:07:37, 21.10s/it]                                                         {'loss': 1.1493, 'grad_norm': 0.91796875, 'learning_rate': 9.709637432903743e-05, 'epoch': 0.11}
 11%|█         | 1130/10365 [6:50:12<54:07:37, 21.10s/it] 11%|█         | 1131/10365 [6:50:38<58:07:25, 22.66s/it] 11%|█         | 1132/10365 [6:51:02<59:20:06, 23.14s/it] 11%|█         | 1133/10365 [6:51:24<58:23:19, 22.77s/it] 11%|█         | 1134/10365 [6:51:41<53:18:27, 20.79s/it] 11%|█         | 1135/10365 [6:52:01<53:03:17, 20.69s/it] 11%|█         | 1136/10365 [6:52:22<53:36:39, 20.91s/it] 11%|█         | 1137/10365 [6:52:42<52:14:40, 20.38s/it] 11%|█         | 1138/10365 [6:53:02<52:30:45, 20.49s/it] 11%|█         | 1139/10365 [6:53:21<51:11:36, 19.98s/it] 11%|█         | 1140/10365 [6:53:44<53:14:30, 20.78s/it]                                                         {'loss': 1.1379, 'grad_norm': 0.93359375, 'learning_rate': 9.704526524493127e-05, 'epoch': 0.11}
 11%|█         | 1140/10365 [6:53:44<53:14:30, 20.78s/it] 11%|█         | 1141/10365 [6:54:04<52:40:16, 20.56s/it] 11%|█         | 1142/10365 [6:54:25<52:54:17, 20.65s/it] 11%|█         | 1143/10365 [6:54:47<54:23:28, 21.23s/it] 11%|█         | 1144/10365 [6:55:09<54:53:47, 21.43s/it] 11%|█         | 1145/10365 [6:55:32<55:50:17, 21.80s/it] 11%|█         | 1146/10365 [6:55:55<56:40:53, 22.13s/it] 11%|█         | 1147/10365 [6:56:16<55:53:52, 21.83s/it] 11%|█         | 1148/10365 [6:56:34<53:17:56, 20.82s/it] 11%|█         | 1149/10365 [6:56:49<48:54:08, 19.10s/it] 11%|█         | 1150/10365 [6:57:13<52:43:11, 20.60s/it]                                                         {'loss': 1.1632, 'grad_norm': 0.9375, 'learning_rate': 9.699372396048772e-05, 'epoch': 0.11}
 11%|█         | 1150/10365 [6:57:13<52:43:11, 20.60s/it] 11%|█         | 1151/10365 [6:57:35<53:42:01, 20.98s/it] 11%|█         | 1152/10365 [6:57:56<53:47:05, 21.02s/it] 11%|█         | 1153/10365 [6:58:18<54:09:43, 21.17s/it] 11%|█         | 1154/10365 [6:58:34<50:28:57, 19.73s/it] 11%|█         | 1155/10365 [6:58:59<54:29:25, 21.30s/it] 11%|█         | 1156/10365 [6:59:18<52:36:37, 20.57s/it] 11%|█         | 1157/10365 [6:59:37<51:06:39, 19.98s/it] 11%|█         | 1158/10365 [6:59:58<51:55:18, 20.30s/it] 11%|█         | 1159/10365 [7:00:18<51:46:11, 20.24s/it] 11%|█         | 1160/10365 [7:00:36<50:07:41, 19.60s/it]                                                         {'loss': 1.1152, 'grad_norm': 0.9453125, 'learning_rate': 9.694175094921163e-05, 'epoch': 0.11}
 11%|█         | 1160/10365 [7:00:36<50:07:41, 19.60s/it] 11%|█         | 1161/10365 [7:00:53<47:49:19, 18.70s/it] 11%|█         | 1162/10365 [7:01:14<49:47:53, 19.48s/it] 11%|█         | 1163/10365 [7:01:37<52:41:51, 20.62s/it] 11%|█         | 1164/10365 [7:01:56<51:17:24, 20.07s/it] 11%|█         | 1165/10365 [7:02:15<50:50:21, 19.89s/it] 11%|█         | 1166/10365 [7:02:38<52:37:33, 20.59s/it] 11%|█▏        | 1167/10365 [7:03:01<54:56:24, 21.50s/it] 11%|█▏        | 1168/10365 [7:03:22<54:11:36, 21.21s/it] 11%|█▏        | 1169/10365 [7:03:40<52:03:13, 20.38s/it] 11%|█▏        | 1170/10365 [7:04:01<52:33:08, 20.58s/it]                                                         {'loss': 1.153, 'grad_norm': 1.03125, 'learning_rate': 9.688934668857406e-05, 'epoch': 0.11}
 11%|█▏        | 1170/10365 [7:04:01<52:33:08, 20.58s/it] 11%|█▏        | 1171/10365 [7:04:21<52:12:48, 20.44s/it] 11%|█▏        | 1172/10365 [7:04:45<54:18:40, 21.27s/it] 11%|█▏        | 1173/10365 [7:05:00<49:28:03, 19.37s/it] 11%|█▏        | 1174/10365 [7:05:25<53:59:06, 21.15s/it] 11%|█▏        | 1175/10365 [7:05:51<57:42:13, 22.60s/it] 11%|█▏        | 1176/10365 [7:06:12<56:43:46, 22.23s/it] 11%|█▏        | 1177/10365 [7:06:34<56:04:53, 21.97s/it] 11%|█▏        | 1178/10365 [7:06:53<54:08:53, 21.22s/it] 11%|█▏        | 1179/10365 [7:07:17<55:53:13, 21.90s/it] 11%|█▏        | 1180/10365 [7:07:34<52:09:10, 20.44s/it]                                                         {'loss': 1.1479, 'grad_norm': 0.8828125, 'learning_rate': 9.683651166000791e-05, 'epoch': 0.11}
 11%|█▏        | 1180/10365 [7:07:34<52:09:10, 20.44s/it] 11%|█▏        | 1181/10365 [7:07:53<51:25:46, 20.16s/it] 11%|█▏        | 1182/10365 [7:08:13<50:51:06, 19.94s/it] 11%|█▏        | 1183/10365 [7:08:30<48:44:14, 19.11s/it] 11%|█▏        | 1184/10365 [7:08:52<50:51:31, 19.94s/it] 11%|█▏        | 1185/10365 [7:09:16<54:26:16, 21.35s/it] 11%|█▏        | 1186/10365 [7:09:39<55:50:20, 21.90s/it] 11%|█▏        | 1187/10365 [7:10:01<55:22:18, 21.72s/it] 11%|█▏        | 1188/10365 [7:10:24<56:17:14, 22.08s/it] 11%|█▏        | 1189/10365 [7:10:45<55:33:18, 21.80s/it] 11%|█▏        | 1190/10365 [7:10:59<49:32:44, 19.44s/it]                                                         {'loss': 1.1573, 'grad_norm': 1.1328125, 'learning_rate': 9.678324634890354e-05, 'epoch': 0.11}
 11%|█▏        | 1190/10365 [7:10:59<49:32:44, 19.44s/it] 11%|█▏        | 1191/10365 [7:11:20<51:17:10, 20.13s/it] 12%|█▏        | 1192/10365 [7:11:38<49:19:43, 19.36s/it] 12%|█▏        | 1193/10365 [7:11:55<47:50:54, 18.78s/it] 12%|█▏        | 1194/10365 [7:12:19<51:11:46, 20.10s/it] 12%|█▏        | 1195/10365 [7:12:45<56:01:30, 21.99s/it] 12%|█▏        | 1196/10365 [7:13:04<53:54:23, 21.17s/it] 12%|█▏        | 1197/10365 [7:13:25<53:44:03, 21.10s/it] 12%|█▏        | 1198/10365 [7:13:45<52:32:34, 20.63s/it] 12%|█▏        | 1199/10365 [7:14:05<52:08:45, 20.48s/it] 12%|█▏        | 1200/10365 [7:14:23<50:04:07, 19.67s/it]                                                         {'loss': 1.1131, 'grad_norm': 0.984375, 'learning_rate': 9.672955124460425e-05, 'epoch': 0.12}
 12%|█▏        | 1200/10365 [7:14:23<50:04:07, 19.67s/it] 12%|█▏        | 1201/10365 [7:14:41<48:54:54, 19.22s/it] 12%|█▏        | 1202/10365 [7:15:02<50:46:50, 19.95s/it] 12%|█▏        | 1203/10365 [7:15:24<51:39:34, 20.30s/it] 12%|█▏        | 1204/10365 [7:15:46<53:02:25, 20.84s/it] 12%|█▏        | 1205/10365 [7:16:07<53:14:52, 20.93s/it] 12%|█▏        | 1206/10365 [7:16:26<52:15:49, 20.54s/it] 12%|█▏        | 1207/10365 [7:16:51<55:05:19, 21.66s/it] 12%|█▏        | 1208/10365 [7:17:10<53:00:16, 20.84s/it] 12%|█▏        | 1209/10365 [7:17:28<51:24:23, 20.21s/it] 12%|█▏        | 1210/10365 [7:17:46<49:44:02, 19.56s/it]                                                         {'loss': 1.1439, 'grad_norm': 0.95703125, 'learning_rate': 9.667542684040179e-05, 'epoch': 0.12}
 12%|█▏        | 1210/10365 [7:17:46<49:44:02, 19.56s/it] 12%|█▏        | 1211/10365 [7:18:08<51:19:03, 20.18s/it] 12%|█▏        | 1212/10365 [7:18:26<49:31:48, 19.48s/it] 12%|█▏        | 1213/10365 [7:18:47<50:27:23, 19.85s/it] 12%|█▏        | 1214/10365 [7:19:05<49:27:06, 19.45s/it] 12%|█▏        | 1215/10365 [7:19:23<48:00:18, 18.89s/it] 12%|█▏        | 1216/10365 [7:19:50<54:45:56, 21.55s/it] 12%|█▏        | 1217/10365 [7:20:08<52:00:53, 20.47s/it] 12%|█▏        | 1218/10365 [7:20:23<47:46:41, 18.80s/it] 12%|█▏        | 1219/10365 [7:20:45<50:17:29, 19.80s/it] 12%|█▏        | 1220/10365 [7:21:10<54:07:29, 21.31s/it]                                                         {'loss': 1.1557, 'grad_norm': 0.9921875, 'learning_rate': 9.662087363353188e-05, 'epoch': 0.12}
 12%|█▏        | 1220/10365 [7:21:10<54:07:29, 21.31s/it] 12%|█▏        | 1221/10365 [7:21:33<54:59:43, 21.65s/it] 12%|█▏        | 1222/10365 [7:21:53<53:59:46, 21.26s/it] 12%|█▏        | 1223/10365 [7:22:12<51:52:36, 20.43s/it] 12%|█▏        | 1224/10365 [7:22:33<52:52:49, 20.83s/it] 12%|█▏        | 1225/10365 [7:22:54<53:06:04, 20.92s/it] 12%|█▏        | 1226/10365 [7:23:20<56:58:33, 22.44s/it] 12%|█▏        | 1227/10365 [7:23:48<61:05:20, 24.07s/it] 12%|█▏        | 1228/10365 [7:24:10<58:58:46, 23.24s/it] 12%|█▏        | 1229/10365 [7:24:29<55:50:11, 22.00s/it] 12%|█▏        | 1230/10365 [7:24:50<55:13:53, 21.77s/it]                                                         {'loss': 1.1666, 'grad_norm': 0.91796875, 'learning_rate': 9.65658921251696e-05, 'epoch': 0.12}
 12%|█▏        | 1230/10365 [7:24:50<55:13:53, 21.77s/it] 12%|█▏        | 1231/10365 [7:25:11<54:34:16, 21.51s/it] 12%|█▏        | 1232/10365 [7:25:29<52:06:39, 20.54s/it] 12%|█▏        | 1233/10365 [7:25:51<53:18:11, 21.01s/it] 12%|█▏        | 1234/10365 [7:26:08<49:48:23, 19.64s/it] 12%|█▏        | 1235/10365 [7:26:30<52:07:20, 20.55s/it] 12%|█▏        | 1236/10365 [7:26:53<53:26:03, 21.07s/it] 12%|█▏        | 1237/10365 [7:27:15<54:02:44, 21.32s/it] 12%|█▏        | 1238/10365 [7:27:34<52:50:41, 20.84s/it] 12%|█▏        | 1239/10365 [7:27:52<50:16:40, 19.83s/it] 12%|█▏        | 1240/10365 [7:28:17<54:19:12, 21.43s/it]                                                         {'loss': 1.1252, 'grad_norm': 0.921875, 'learning_rate': 9.651048282042479e-05, 'epoch': 0.12}
 12%|█▏        | 1240/10365 [7:28:17<54:19:12, 21.43s/it] 12%|█▏        | 1241/10365 [7:28:34<51:18:34, 20.24s/it] 12%|█▏        | 1242/10365 [7:28:49<47:17:30, 18.66s/it] 12%|█▏        | 1243/10365 [7:29:07<46:45:26, 18.45s/it] 12%|█▏        | 1244/10365 [7:29:27<47:18:30, 18.67s/it] 12%|█▏        | 1245/10365 [7:29:44<46:19:43, 18.29s/it] 12%|█▏        | 1246/10365 [7:30:14<54:58:54, 21.71s/it] 12%|█▏        | 1247/10365 [7:30:29<50:32:57, 19.96s/it] 12%|█▏        | 1248/10365 [7:30:50<50:37:13, 19.99s/it] 12%|█▏        | 1249/10365 [7:31:12<52:14:15, 20.63s/it] 12%|█▏        | 1250/10365 [7:31:30<50:26:29, 19.92s/it]                                                         {'loss': 1.1451, 'grad_norm': 0.94140625, 'learning_rate': 9.645464622833743e-05, 'epoch': 0.12}
 12%|█▏        | 1250/10365 [7:31:30<50:26:29, 19.92s/it] 12%|█▏        | 1251/10365 [7:31:50<50:16:24, 19.86s/it] 12%|█▏        | 1252/10365 [7:32:19<57:27:00, 22.70s/it] 12%|█▏        | 1253/10365 [7:32:39<55:16:35, 21.84s/it] 12%|█▏        | 1254/10365 [7:32:59<53:45:51, 21.24s/it] 12%|█▏        | 1255/10365 [7:33:19<52:56:09, 20.92s/it] 12%|█▏        | 1256/10365 [7:33:35<49:25:58, 19.54s/it] 12%|█▏        | 1257/10365 [7:33:52<47:25:29, 18.74s/it] 12%|█▏        | 1258/10365 [7:34:13<49:23:26, 19.52s/it] 12%|█▏        | 1259/10365 [7:34:27<45:10:53, 17.86s/it] 12%|█▏        | 1260/10365 [7:34:45<45:17:16, 17.91s/it]                                                         {'loss': 1.1564, 'grad_norm': 0.96484375, 'learning_rate': 9.63983828618729e-05, 'epoch': 0.12}
 12%|█▏        | 1260/10365 [7:34:45<45:17:16, 17.91s/it] 12%|█▏        | 1261/10365 [7:35:08<48:36:46, 19.22s/it] 12%|█▏        | 1262/10365 [7:35:29<49:52:10, 19.72s/it] 12%|█▏        | 1263/10365 [7:35:50<50:57:17, 20.15s/it] 12%|█▏        | 1264/10365 [7:36:07<49:02:36, 19.40s/it] 12%|█▏        | 1265/10365 [7:36:29<50:24:30, 19.94s/it] 12%|█▏        | 1266/10365 [7:36:44<47:09:05, 18.66s/it] 12%|█▏        | 1267/10365 [7:37:06<49:10:21, 19.46s/it] 12%|█▏        | 1268/10365 [7:37:30<52:54:14, 20.94s/it] 12%|█▏        | 1269/10365 [7:37:56<57:02:58, 22.58s/it] 12%|█▏        | 1270/10365 [7:38:17<55:24:59, 21.94s/it]                                                         {'loss': 1.0897, 'grad_norm': 0.98046875, 'learning_rate': 9.634169323791737e-05, 'epoch': 0.12}
 12%|█▏        | 1270/10365 [7:38:17<55:24:59, 21.94s/it] 12%|█▏        | 1271/10365 [7:38:38<54:48:49, 21.70s/it] 12%|█▏        | 1272/10365 [7:38:58<53:49:39, 21.31s/it] 12%|█▏        | 1273/10365 [7:39:17<51:36:22, 20.43s/it] 12%|█▏        | 1274/10365 [7:39:42<55:19:04, 21.91s/it] 12%|█▏        | 1275/10365 [7:40:10<59:59:15, 23.76s/it] 12%|█▏        | 1276/10365 [7:40:34<59:59:20, 23.76s/it] 12%|█▏        | 1277/10365 [7:40:55<58:05:39, 23.01s/it] 12%|█▏        | 1278/10365 [7:41:17<56:53:26, 22.54s/it] 12%|█▏        | 1279/10365 [7:41:36<54:38:42, 21.65s/it] 12%|█▏        | 1280/10365 [7:42:00<56:17:36, 22.31s/it]                                                         {'loss': 1.1353, 'grad_norm': 0.98828125, 'learning_rate': 9.628457787727296e-05, 'epoch': 0.12}
 12%|█▏        | 1280/10365 [7:42:00<56:17:36, 22.31s/it] 12%|█▏        | 1281/10365 [7:42:21<55:02:32, 21.81s/it] 12%|█▏        | 1282/10365 [7:42:42<54:29:03, 21.59s/it] 12%|█▏        | 1283/10365 [7:43:00<52:18:47, 20.74s/it] 12%|█▏        | 1284/10365 [7:43:20<51:45:11, 20.52s/it] 12%|█▏        | 1285/10365 [7:43:41<51:32:59, 20.44s/it] 12%|█▏        | 1286/10365 [7:43:58<49:21:56, 19.57s/it] 12%|█▏        | 1287/10365 [7:44:19<50:21:26, 19.97s/it] 12%|█▏        | 1288/10365 [7:44:37<48:25:58, 19.21s/it] 12%|█▏        | 1289/10365 [7:44:55<47:49:59, 18.97s/it] 12%|█▏        | 1290/10365 [7:45:12<46:20:10, 18.38s/it]                                                         {'loss': 1.1404, 'grad_norm': 1.0078125, 'learning_rate': 9.622703730465303e-05, 'epoch': 0.12}
 12%|█▏        | 1290/10365 [7:45:12<46:20:10, 18.38s/it] 12%|█▏        | 1291/10365 [7:45:28<44:32:34, 17.67s/it] 12%|█▏        | 1292/10365 [7:45:52<49:22:48, 19.59s/it] 12%|█▏        | 1293/10365 [7:46:14<51:00:30, 20.24s/it] 12%|█▏        | 1294/10365 [7:46:39<54:50:12, 21.76s/it] 12%|█▏        | 1295/10365 [7:47:01<54:52:51, 21.78s/it] 13%|█▎        | 1296/10365 [7:47:20<52:43:07, 20.93s/it] 13%|█▎        | 1297/10365 [7:47:40<51:56:55, 20.62s/it] 13%|█▎        | 1298/10365 [7:48:02<53:03:00, 21.06s/it] 13%|█▎        | 1299/10365 [7:48:24<53:46:10, 21.35s/it] 13%|█▎        | 1300/10365 [7:48:46<54:09:56, 21.51s/it]                                                         {'loss': 1.1482, 'grad_norm': 1.0390625, 'learning_rate': 9.61690720486773e-05, 'epoch': 0.13}
 13%|█▎        | 1300/10365 [7:48:46<54:09:56, 21.51s/it] 13%|█▎        | 1301/10365 [7:49:10<55:50:50, 22.18s/it] 13%|█▎        | 1302/10365 [7:49:29<53:56:17, 21.43s/it] 13%|█▎        | 1303/10365 [7:49:59<60:22:45, 23.99s/it] 13%|█▎        | 1304/10365 [7:50:19<57:23:08, 22.80s/it] 13%|█▎        | 1305/10365 [7:50:38<54:36:27, 21.70s/it] 13%|█▎        | 1306/10365 [7:51:00<54:11:31, 21.54s/it] 13%|█▎        | 1307/10365 [7:51:21<53:50:21, 21.40s/it] 13%|█▎        | 1308/10365 [7:51:39<51:51:17, 20.61s/it] 13%|█▎        | 1309/10365 [7:51:58<50:20:33, 20.01s/it] 13%|█▎        | 1310/10365 [7:52:23<54:09:50, 21.53s/it]                                                         {'loss': 1.1305, 'grad_norm': 0.90234375, 'learning_rate': 9.611068264186698e-05, 'epoch': 0.13}
 13%|█▎        | 1310/10365 [7:52:23<54:09:50, 21.53s/it] 13%|█▎        | 1311/10365 [7:52:41<51:35:41, 20.51s/it] 13%|█▎        | 1312/10365 [7:53:01<50:48:44, 20.21s/it] 13%|█▎        | 1313/10365 [7:53:26<54:19:55, 21.61s/it] 13%|█▎        | 1314/10365 [7:53:42<50:36:07, 20.13s/it] 13%|█▎        | 1315/10365 [7:54:04<51:36:34, 20.53s/it] 13%|█▎        | 1316/10365 [7:54:21<49:28:09, 19.68s/it] 13%|█▎        | 1317/10365 [7:54:47<53:44:42, 21.38s/it] 13%|█▎        | 1318/10365 [7:55:06<52:16:27, 20.80s/it] 13%|█▎        | 1319/10365 [7:55:22<48:41:42, 19.38s/it] 13%|█▎        | 1320/10365 [7:55:45<51:17:40, 20.42s/it]                                                         {'loss': 1.1486, 'grad_norm': 0.89453125, 'learning_rate': 9.605186962063999e-05, 'epoch': 0.13}
 13%|█▎        | 1320/10365 [7:55:45<51:17:40, 20.42s/it] 13%|█▎        | 1321/10365 [7:56:07<52:29:34, 20.90s/it] 13%|█▎        | 1322/10365 [7:56:33<56:08:24, 22.35s/it] 13%|█▎        | 1323/10365 [7:56:59<58:44:48, 23.39s/it] 13%|█▎        | 1324/10365 [7:57:21<57:54:50, 23.06s/it] 13%|█▎        | 1325/10365 [7:57:40<54:39:18, 21.77s/it] 13%|█▎        | 1326/10365 [7:58:04<56:41:56, 22.58s/it] 13%|█▎        | 1327/10365 [7:58:26<55:43:29, 22.20s/it] 13%|█▎        | 1328/10365 [7:58:47<55:10:04, 21.98s/it] 13%|█▎        | 1329/10365 [7:59:09<55:08:14, 21.97s/it] 13%|█▎        | 1330/10365 [7:59:31<55:12:24, 22.00s/it]                                                         {'loss': 1.0898, 'grad_norm': 1.1328125, 'learning_rate': 9.599263352530588e-05, 'epoch': 0.13}
 13%|█▎        | 1330/10365 [7:59:31<55:12:24, 22.00s/it] 13%|█▎        | 1331/10365 [7:59:47<50:53:12, 20.28s/it] 13%|█▎        | 1332/10365 [8:00:05<49:06:02, 19.57s/it] 13%|█▎        | 1333/10365 [8:00:37<58:10:03, 23.18s/it] 13%|█▎        | 1334/10365 [8:01:00<58:06:07, 23.16s/it] 13%|█▎        | 1335/10365 [8:01:22<57:30:27, 22.93s/it] 13%|█▎        | 1336/10365 [8:01:44<56:32:32, 22.54s/it] 13%|█▎        | 1337/10365 [8:02:03<53:59:12, 21.53s/it] 13%|█▎        | 1338/10365 [8:02:23<52:32:12, 20.95s/it] 13%|█▎        | 1339/10365 [8:02:49<56:32:49, 22.55s/it] 13%|█▎        | 1340/10365 [8:03:07<53:26:19, 21.32s/it]                                                         {'loss': 1.1337, 'grad_norm': 0.98046875, 'learning_rate': 9.593297490006099e-05, 'epoch': 0.13}
 13%|█▎        | 1340/10365 [8:03:07<53:26:19, 21.32s/it] 13%|█▎        | 1341/10365 [8:03:30<54:31:20, 21.75s/it] 13%|█▎        | 1342/10365 [8:03:51<53:30:41, 21.35s/it] 13%|█▎        | 1343/10365 [8:04:07<49:55:07, 19.92s/it] 13%|█▎        | 1344/10365 [8:04:26<48:56:26, 19.53s/it] 13%|█▎        | 1345/10365 [8:04:47<50:12:29, 20.04s/it] 13%|█▎        | 1346/10365 [8:05:07<50:19:11, 20.09s/it] 13%|█▎        | 1347/10365 [8:05:27<50:14:15, 20.05s/it] 13%|█▎        | 1348/10365 [8:05:49<51:29:55, 20.56s/it] 13%|█▎        | 1349/10365 [8:06:06<48:58:25, 19.55s/it] 13%|█▎        | 1350/10365 [8:06:31<53:13:59, 21.26s/it]                                                         {'loss': 1.1236, 'grad_norm': 1.0, 'learning_rate': 9.587289429298338e-05, 'epoch': 0.13}
 13%|█▎        | 1350/10365 [8:06:31<53:13:59, 21.26s/it] 13%|█▎        | 1351/10365 [8:06:52<52:45:38, 21.07s/it] 13%|█▎        | 1352/10365 [8:07:13<52:55:59, 21.14s/it] 13%|█▎        | 1353/10365 [8:07:35<53:09:25, 21.23s/it] 13%|█▎        | 1354/10365 [8:07:58<54:46:38, 21.88s/it] 13%|█▎        | 1355/10365 [8:08:19<53:48:07, 21.50s/it] 13%|█▎        | 1356/10365 [8:08:42<54:54:46, 21.94s/it] 13%|█▎        | 1357/10365 [8:09:04<55:10:29, 22.05s/it] 13%|█▎        | 1358/10365 [8:09:30<58:03:29, 23.21s/it] 13%|█▎        | 1359/10365 [8:09:48<54:28:32, 21.78s/it] 13%|█▎        | 1360/10365 [8:10:10<53:58:37, 21.58s/it]                                                         {'loss': 1.131, 'grad_norm': 0.9140625, 'learning_rate': 9.581239225602783e-05, 'epoch': 0.13}
 13%|█▎        | 1360/10365 [8:10:10<53:58:37, 21.58s/it] 13%|█▎        | 1361/10365 [8:10:28<51:52:04, 20.74s/it] 13%|█▎        | 1362/10365 [8:10:53<54:39:57, 21.86s/it] 13%|█▎        | 1363/10365 [8:11:12<52:48:04, 21.12s/it] 13%|█▎        | 1364/10365 [8:11:36<54:32:53, 21.82s/it] 13%|█▎        | 1365/10365 [8:11:53<51:27:28, 20.58s/it] 13%|█▎        | 1366/10365 [8:12:12<49:59:35, 20.00s/it] 13%|█▎        | 1367/10365 [8:12:31<49:35:22, 19.84s/it] 13%|█▎        | 1368/10365 [8:12:58<54:19:08, 21.73s/it] 13%|█▎        | 1369/10365 [8:13:26<59:29:32, 23.81s/it] 13%|█▎        | 1370/10365 [8:13:47<57:31:31, 23.02s/it]                                                         {'loss': 1.1397, 'grad_norm': 0.96875, 'learning_rate': 9.575146934502073e-05, 'epoch': 0.13}
 13%|█▎        | 1370/10365 [8:13:47<57:31:31, 23.02s/it] 13%|█▎        | 1371/10365 [8:14:09<56:47:09, 22.73s/it] 13%|█▎        | 1372/10365 [8:14:31<55:56:44, 22.40s/it] 13%|█▎        | 1373/10365 [8:14:55<57:00:21, 22.82s/it] 13%|█▎        | 1374/10365 [8:15:10<51:09:45, 20.49s/it] 13%|█▎        | 1375/10365 [8:15:35<54:12:56, 21.71s/it] 13%|█▎        | 1376/10365 [8:16:02<58:25:36, 23.40s/it] 13%|█▎        | 1377/10365 [8:16:24<57:26:48, 23.01s/it] 13%|█▎        | 1378/10365 [8:16:47<57:22:10, 22.98s/it] 13%|█▎        | 1379/10365 [8:17:08<55:51:59, 22.38s/it] 13%|█▎        | 1380/10365 [8:17:25<51:40:05, 20.70s/it]                                                         {'loss': 1.1496, 'grad_norm': 0.9140625, 'learning_rate': 9.569012611965504e-05, 'epoch': 0.13}
 13%|█▎        | 1380/10365 [8:17:25<51:40:05, 20.70s/it] 13%|█▎        | 1381/10365 [8:17:45<51:44:18, 20.73s/it] 13%|█▎        | 1382/10365 [8:18:10<54:44:32, 21.94s/it] 13%|█▎        | 1383/10365 [8:18:37<58:13:10, 23.33s/it] 13%|█▎        | 1384/10365 [8:18:54<53:39:08, 21.51s/it] 13%|█▎        | 1385/10365 [8:19:12<50:43:46, 20.34s/it] 13%|█▎        | 1386/10365 [8:19:32<50:44:08, 20.34s/it] 13%|█▎        | 1387/10365 [8:19:53<51:16:22, 20.56s/it] 13%|█▎        | 1388/10365 [8:20:14<51:42:17, 20.73s/it] 13%|█▎        | 1389/10365 [8:20:36<52:41:44, 21.13s/it] 13%|█▎        | 1390/10365 [8:20:58<53:30:57, 21.47s/it]                                                         {'loss': 1.1019, 'grad_norm': 0.984375, 'learning_rate': 9.562836314348506e-05, 'epoch': 0.13}
 13%|█▎        | 1390/10365 [8:20:59<53:30:57, 21.47s/it] 13%|█▎        | 1391/10365 [8:21:20<53:40:59, 21.54s/it] 13%|█▎        | 1392/10365 [8:21:40<52:04:25, 20.89s/it] 13%|█▎        | 1393/10365 [8:22:05<55:14:31, 22.17s/it] 13%|█▎        | 1394/10365 [8:22:24<53:01:14, 21.28s/it] 13%|█▎        | 1395/10365 [8:22:44<51:58:57, 20.86s/it] 13%|█▎        | 1396/10365 [8:23:09<55:17:04, 22.19s/it] 13%|█▎        | 1397/10365 [8:23:32<55:49:44, 22.41s/it] 13%|█▎        | 1398/10365 [8:23:51<52:57:16, 21.26s/it] 13%|█▎        | 1399/10365 [8:24:17<57:06:49, 22.93s/it] 14%|█▎        | 1400/10365 [8:24:36<53:50:15, 21.62s/it]                                                         {'loss': 1.1427, 'grad_norm': 0.91796875, 'learning_rate': 9.556618098392134e-05, 'epoch': 0.14}
 14%|█▎        | 1400/10365 [8:24:36<53:50:15, 21.62s/it] 14%|█▎        | 1401/10365 [8:24:53<50:30:37, 20.29s/it] 14%|█▎        | 1402/10365 [8:25:17<53:15:31, 21.39s/it] 14%|█▎        | 1403/10365 [8:25:38<52:35:34, 21.13s/it] 14%|█▎        | 1404/10365 [8:26:01<54:35:09, 21.93s/it] 14%|█▎        | 1405/10365 [8:26:26<56:40:43, 22.77s/it] 14%|█▎        | 1406/10365 [8:26:47<55:26:18, 22.28s/it] 14%|█▎        | 1407/10365 [8:27:08<54:06:22, 21.74s/it] 14%|█▎        | 1408/10365 [8:27:26<51:06:21, 20.54s/it] 14%|█▎        | 1409/10365 [8:27:48<52:11:52, 20.98s/it] 14%|█▎        | 1410/10365 [8:28:10<53:05:09, 21.34s/it]                                                         {'loss': 1.138, 'grad_norm': 0.98046875, 'learning_rate': 9.550358021222543e-05, 'epoch': 0.14}
 14%|█▎        | 1410/10365 [8:28:10<53:05:09, 21.34s/it] 14%|█▎        | 1411/10365 [8:28:32<53:47:13, 21.63s/it] 14%|█▎        | 1412/10365 [8:28:53<52:55:13, 21.28s/it] 14%|█▎        | 1413/10365 [8:29:16<54:13:40, 21.81s/it] 14%|█▎        | 1414/10365 [8:29:35<52:31:19, 21.12s/it] 14%|█▎        | 1415/10365 [8:29:56<52:13:23, 21.01s/it] 14%|█▎        | 1416/10365 [8:30:19<53:48:14, 21.64s/it] 14%|█▎        | 1417/10365 [8:30:36<50:43:55, 20.41s/it] 14%|█▎        | 1418/10365 [8:30:56<50:09:12, 20.18s/it] 14%|█▎        | 1419/10365 [8:31:15<49:08:43, 19.78s/it] 14%|█▎        | 1420/10365 [8:31:39<52:40:01, 21.20s/it]                                                         {'loss': 1.1315, 'grad_norm': 0.98828125, 'learning_rate': 9.544056140350458e-05, 'epoch': 0.14}
 14%|█▎        | 1420/10365 [8:31:39<52:40:01, 21.20s/it] 14%|█▎        | 1421/10365 [8:31:57<50:07:38, 20.18s/it] 14%|█▎        | 1422/10365 [8:32:15<48:38:51, 19.58s/it] 14%|█▎        | 1423/10365 [8:32:37<50:08:43, 20.19s/it] 14%|█▎        | 1424/10365 [8:32:56<49:18:20, 19.85s/it] 14%|█▎        | 1425/10365 [8:33:12<46:12:18, 18.61s/it] 14%|█▍        | 1426/10365 [8:33:37<51:02:08, 20.55s/it] 14%|█▍        | 1427/10365 [8:33:55<49:09:39, 19.80s/it] 14%|█▍        | 1428/10365 [8:34:11<46:40:52, 18.80s/it] 14%|█▍        | 1429/10365 [8:34:34<49:26:57, 19.92s/it] 14%|█▍        | 1430/10365 [8:34:56<50:52:15, 20.50s/it]                                                         {'loss': 1.107, 'grad_norm': 0.8984375, 'learning_rate': 9.537712513670656e-05, 'epoch': 0.14}
 14%|█▍        | 1430/10365 [8:34:56<50:52:15, 20.50s/it] 14%|█▍        | 1431/10365 [8:35:23<55:40:03, 22.43s/it] 14%|█▍        | 1432/10365 [8:35:45<55:28:29, 22.36s/it] 14%|█▍        | 1433/10365 [8:36:01<50:35:13, 20.39s/it] 14%|█▍        | 1434/10365 [8:36:18<48:18:22, 19.47s/it] 14%|█▍        | 1435/10365 [8:36:40<49:47:23, 20.07s/it] 14%|█▍        | 1436/10365 [8:37:00<50:08:00, 20.21s/it] 14%|█▍        | 1437/10365 [8:37:18<48:47:49, 19.68s/it] 14%|█▍        | 1438/10365 [8:37:39<49:34:43, 19.99s/it] 14%|█▍        | 1439/10365 [8:38:00<49:55:01, 20.13s/it] 14%|█▍        | 1440/10365 [8:38:26<54:14:46, 21.88s/it]                                                         {'loss': 1.1159, 'grad_norm': 0.875, 'learning_rate': 9.531327199461425e-05, 'epoch': 0.14}
 14%|█▍        | 1440/10365 [8:38:26<54:14:46, 21.88s/it] 14%|█▍        | 1441/10365 [8:38:48<54:50:02, 22.12s/it] 14%|█▍        | 1442/10365 [8:39:13<56:28:50, 22.79s/it] 14%|█▍        | 1443/10365 [8:39:35<55:46:15, 22.50s/it] 14%|█▍        | 1444/10365 [8:39:59<57:34:50, 23.24s/it] 14%|█▍        | 1445/10365 [8:40:20<55:33:21, 22.42s/it] 14%|█▍        | 1446/10365 [8:40:38<52:25:04, 21.16s/it] 14%|█▍        | 1447/10365 [8:40:59<52:22:41, 21.14s/it] 14%|█▍        | 1448/10365 [8:41:19<51:19:13, 20.72s/it] 14%|█▍        | 1449/10365 [8:41:47<56:52:19, 22.96s/it] 14%|█▍        | 1450/10365 [8:42:04<52:14:25, 21.10s/it]                                                         {'loss': 1.1223, 'grad_norm': 0.87109375, 'learning_rate': 9.524900256384034e-05, 'epoch': 0.14}
 14%|█▍        | 1450/10365 [8:42:04<52:14:25, 21.10s/it] 14%|█▍        | 1451/10365 [8:42:28<54:14:12, 21.90s/it] 14%|█▍        | 1452/10365 [8:42:50<54:15:44, 21.92s/it] 14%|█▍        | 1453/10365 [8:43:14<55:46:20, 22.53s/it] 14%|█▍        | 1454/10365 [8:43:37<56:02:35, 22.64s/it] 14%|█▍        | 1455/10365 [8:44:01<57:09:05, 23.09s/it] 14%|█▍        | 1456/10365 [8:44:18<52:46:47, 21.33s/it] 14%|█▍        | 1457/10365 [8:44:37<51:08:50, 20.67s/it] 14%|█▍        | 1458/10365 [8:44:55<49:22:16, 19.95s/it] 14%|█▍        | 1459/10365 [8:45:19<51:55:20, 20.99s/it] 14%|█▍        | 1460/10365 [8:45:40<52:08:05, 21.08s/it]                                                         {'loss': 1.1179, 'grad_norm': 0.95703125, 'learning_rate': 9.518431743482196e-05, 'epoch': 0.14}
 14%|█▍        | 1460/10365 [8:45:40<52:08:05, 21.08s/it] 14%|█▍        | 1461/10365 [8:45:57<48:46:51, 19.72s/it] 14%|█▍        | 1462/10365 [8:46:20<51:27:30, 20.81s/it] 14%|█▍        | 1463/10365 [8:46:40<50:40:47, 20.50s/it] 14%|█▍        | 1464/10365 [8:47:01<50:58:26, 20.62s/it] 14%|█▍        | 1465/10365 [8:47:24<53:09:27, 21.50s/it] 14%|█▍        | 1466/10365 [8:47:49<55:33:03, 22.47s/it] 14%|█▍        | 1467/10365 [8:48:15<58:15:59, 23.57s/it] 14%|█▍        | 1468/10365 [8:48:36<56:35:21, 22.90s/it] 14%|█▍        | 1469/10365 [8:48:58<55:48:16, 22.58s/it] 14%|█▍        | 1470/10365 [8:49:17<52:46:22, 21.36s/it]                                                         {'loss': 1.1605, 'grad_norm': 0.921875, 'learning_rate': 9.511921720181514e-05, 'epoch': 0.14}
 14%|█▍        | 1470/10365 [8:49:17<52:46:22, 21.36s/it] 14%|█▍        | 1471/10365 [8:49:44<57:14:46, 23.17s/it] 14%|█▍        | 1472/10365 [8:50:03<53:46:40, 21.77s/it] 14%|█▍        | 1473/10365 [8:50:28<56:09:51, 22.74s/it] 14%|█▍        | 1474/10365 [8:50:47<53:45:11, 21.76s/it] 14%|█▍        | 1475/10365 [8:51:07<52:21:03, 21.20s/it] 14%|█▍        | 1476/10365 [8:51:35<57:20:21, 23.22s/it] 14%|█▍        | 1477/10365 [8:51:53<53:17:23, 21.58s/it] 14%|█▍        | 1478/10365 [8:52:11<50:56:37, 20.64s/it] 14%|█▍        | 1479/10365 [8:52:29<48:48:38, 19.77s/it] 14%|█▍        | 1480/10365 [8:52:52<51:15:14, 20.77s/it]                                                         {'loss': 1.1614, 'grad_norm': 1.015625, 'learning_rate': 9.505370246288947e-05, 'epoch': 0.14}
 14%|█▍        | 1480/10365 [8:52:52<51:15:14, 20.77s/it] 14%|█▍        | 1481/10365 [8:53:12<50:20:30, 20.40s/it] 14%|█▍        | 1482/10365 [8:53:31<49:42:49, 20.15s/it] 14%|█▍        | 1483/10365 [8:53:49<47:44:34, 19.35s/it] 14%|█▍        | 1484/10365 [8:54:10<49:18:11, 19.99s/it] 14%|█▍        | 1485/10365 [8:54:30<49:06:43, 19.91s/it] 14%|█▍        | 1486/10365 [8:54:48<48:07:53, 19.52s/it] 14%|█▍        | 1487/10365 [8:55:05<46:00:29, 18.66s/it] 14%|█▍        | 1488/10365 [8:55:26<47:30:35, 19.27s/it] 14%|█▍        | 1489/10365 [8:55:47<49:04:19, 19.90s/it] 14%|█▍        | 1490/10365 [8:56:06<47:58:23, 19.46s/it]                                                         {'loss': 1.1605, 'grad_norm': 1.03125, 'learning_rate': 9.498777381992261e-05, 'epoch': 0.14}
 14%|█▍        | 1490/10365 [8:56:06<47:58:23, 19.46s/it] 14%|█▍        | 1491/10365 [8:56:26<48:50:43, 19.82s/it] 14%|█▍        | 1492/10365 [8:56:52<52:58:02, 21.49s/it] 14%|█▍        | 1493/10365 [8:57:14<53:51:19, 21.85s/it] 14%|█▍        | 1494/10365 [8:57:36<54:03:09, 21.94s/it] 14%|█▍        | 1495/10365 [8:57:58<54:08:06, 21.97s/it] 14%|█▍        | 1496/10365 [8:58:22<55:33:27, 22.55s/it] 14%|█▍        | 1497/10365 [8:58:46<56:02:43, 22.75s/it] 14%|█▍        | 1498/10365 [8:59:06<54:33:30, 22.15s/it] 14%|█▍        | 1499/10365 [8:59:28<54:11:35, 22.00s/it] 14%|█▍        | 1500/10365 [8:59:50<54:29:47, 22.13s/it]                                                         {'loss': 1.1241, 'grad_norm': 1.015625, 'learning_rate': 9.492143187859465e-05, 'epoch': 0.14}
 14%|█▍        | 1500/10365 [8:59:50<54:29:47, 22.13s/it][INFO|trainer.py:3719] 2024-05-30 19:54:16,271 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-30 19:54:16,271 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-30 19:54:16,271 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:47,  1.76s/it][A
  5%|▍         | 3/63 [00:08<03:15,  3.26s/it][A
  6%|▋         | 4/63 [00:13<03:47,  3.85s/it][A
  8%|▊         | 5/63 [00:18<04:06,  4.26s/it][A
 10%|▉         | 6/63 [00:23<04:11,  4.41s/it][A
 11%|█         | 7/63 [00:28<04:16,  4.59s/it][A
 13%|█▎        | 8/63 [00:33<04:14,  4.62s/it][A
 14%|█▍        | 9/63 [00:38<04:17,  4.76s/it][A
 16%|█▌        | 10/63 [00:43<04:25,  5.01s/it][A
 17%|█▋        | 11/63 [00:49<04:34,  5.28s/it][A
 19%|█▉        | 12/63 [00:54<04:20,  5.11s/it][A
 21%|██        | 13/63 [00:59<04:15,  5.10s/it][A
 22%|██▏       | 14/63 [01:04<04:02,  4.95s/it][A
 24%|██▍       | 15/63 [01:09<03:59,  5.00s/it][A
 25%|██▌       | 16/63 [01:14<03:54,  4.99s/it][A
 27%|██▋       | 17/63 [01:19<03:50,  5.02s/it][A
 29%|██▊       | 18/63 [01:24<03:51,  5.15s/it][A
 30%|███       | 19/63 [01:30<03:52,  5.29s/it][A
 32%|███▏      | 20/63 [01:35<03:51,  5.39s/it][A
 33%|███▎      | 21/63 [01:40<03:34,  5.11s/it][A
 35%|███▍      | 22/63 [01:46<03:44,  5.48s/it][A
 37%|███▋      | 23/63 [01:50<03:17,  4.93s/it][A
 38%|███▊      | 24/63 [01:55<03:20,  5.13s/it][A
 40%|███▉      | 25/63 [02:01<03:21,  5.30s/it][A
 41%|████▏     | 26/63 [02:06<03:11,  5.17s/it][A
 43%|████▎     | 27/63 [02:12<03:11,  5.33s/it][A
 44%|████▍     | 28/63 [02:18<03:14,  5.54s/it][A
 46%|████▌     | 29/63 [02:25<03:22,  5.96s/it][A
 48%|████▊     | 30/63 [02:29<03:00,  5.48s/it][A
 49%|████▉     | 31/63 [02:34<02:51,  5.36s/it][A
 51%|█████     | 32/63 [02:38<02:33,  4.97s/it][A
 52%|█████▏    | 33/63 [02:44<02:37,  5.25s/it][A
 54%|█████▍    | 34/63 [02:48<02:17,  4.75s/it][A
 56%|█████▌    | 35/63 [02:52<02:13,  4.75s/it][A
 57%|█████▋    | 36/63 [02:57<02:03,  4.59s/it][A
 59%|█████▊    | 37/63 [03:03<02:14,  5.18s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.29s/it][A
 62%|██████▏   | 39/63 [03:13<02:01,  5.06s/it][A
 63%|██████▎   | 40/63 [03:18<01:57,  5.09s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.14s/it][A
 67%|██████▋   | 42/63 [03:31<01:59,  5.68s/it][A
 68%|██████▊   | 43/63 [03:36<01:53,  5.67s/it][A
 70%|██████▉   | 44/63 [03:41<01:42,  5.40s/it][A
 71%|███████▏  | 45/63 [03:48<01:45,  5.86s/it][A
 73%|███████▎  | 46/63 [03:54<01:38,  5.81s/it][A
 75%|███████▍  | 47/63 [03:59<01:32,  5.77s/it][A
 76%|███████▌  | 48/63 [04:06<01:31,  6.11s/it][A
 78%|███████▊  | 49/63 [04:11<01:18,  5.63s/it][A
 79%|███████▉  | 50/63 [04:17<01:16,  5.90s/it][A
 81%|████████  | 51/63 [04:23<01:09,  5.80s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.13s/it][A
 84%|████████▍ | 53/63 [04:35<00:59,  5.92s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.81s/it][A
 87%|████████▋ | 55/63 [04:45<00:42,  5.37s/it][A
 89%|████████▉ | 56/63 [04:50<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.31s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.21s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.15s/it][A
 95%|█████████▌| 60/63 [05:10<00:14,  4.89s/it][A
 97%|█████████▋| 61/63 [05:16<00:10,  5.41s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.67s/it][A
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A                                                         
                                               [A{'eval_loss': 1.1359196901321411, 'eval_runtime': 335.8535, 'eval_samples_per_second': 14.887, 'eval_steps_per_second': 0.188, 'epoch': 0.14}
 14%|█▍        | 1500/10365 [9:05:26<54:29:47, 22.13s/it]
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-30 19:59:54,424 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-1500
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-30 19:59:54,479 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-30 19:59:54,479 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-1500/special_tokens_map.json
 14%|█▍        | 1501/10365 [9:05:55<307:22:22, 124.84s/it] 14%|█▍        | 1502/10365 [9:06:18<231:58:26, 94.22s/it]  15%|█▍        | 1503/10365 [9:06:43<181:16:53, 73.64s/it] 15%|█▍        | 1504/10365 [9:07:08<145:24:49, 59.08s/it] 15%|█▍        | 1505/10365 [9:07:31<118:37:14, 48.20s/it] 15%|█▍        | 1506/10365 [9:07:53<99:27:43, 40.42s/it]  15%|█▍        | 1507/10365 [9:08:12<83:34:42, 33.97s/it] 15%|█▍        | 1508/10365 [9:08:33<73:36:36, 29.92s/it] 15%|█▍        | 1509/10365 [9:08:52<65:46:29, 26.74s/it] 15%|█▍        | 1510/10365 [9:09:11<60:10:42, 24.47s/it]                                                         {'loss': 1.1288, 'grad_norm': 0.99609375, 'learning_rate': 9.485467724838264e-05, 'epoch': 0.15}
 15%|█▍        | 1510/10365 [9:09:11<60:10:42, 24.47s/it] 15%|█▍        | 1511/10365 [9:09:38<62:05:59, 25.25s/it] 15%|█▍        | 1512/10365 [9:10:04<62:09:48, 25.28s/it] 15%|█▍        | 1513/10365 [9:10:23<58:03:09, 23.61s/it] 15%|█▍        | 1514/10365 [9:10:47<58:07:51, 23.64s/it] 15%|█▍        | 1515/10365 [9:11:10<57:10:05, 23.25s/it] 15%|█▍        | 1516/10365 [9:11:32<56:30:59, 22.99s/it] 15%|█▍        | 1517/10365 [9:11:59<59:43:25, 24.30s/it] 15%|█▍        | 1518/10365 [9:12:20<56:54:02, 23.15s/it] 15%|█▍        | 1519/10365 [9:12:41<55:49:33, 22.72s/it] 15%|█▍        | 1520/10365 [9:13:00<52:34:17, 21.40s/it]                                                         {'loss': 1.1491, 'grad_norm': 1.0546875, 'learning_rate': 9.478751054255495e-05, 'epoch': 0.15}
 15%|█▍        | 1520/10365 [9:13:00<52:34:17, 21.40s/it] 15%|█▍        | 1521/10365 [9:13:16<48:54:56, 19.91s/it] 15%|█▍        | 1522/10365 [9:13:34<47:01:20, 19.14s/it] 15%|█▍        | 1523/10365 [9:13:50<45:08:41, 18.38s/it] 15%|█▍        | 1524/10365 [9:14:13<48:27:39, 19.73s/it] 15%|█▍        | 1525/10365 [9:14:35<50:24:17, 20.53s/it] 15%|█▍        | 1526/10365 [9:14:52<47:47:23, 19.46s/it] 15%|█▍        | 1527/10365 [9:15:12<47:52:35, 19.50s/it] 15%|█▍        | 1528/10365 [9:15:36<51:26:23, 20.96s/it] 15%|█▍        | 1529/10365 [9:15:58<52:07:00, 21.23s/it] 15%|█▍        | 1530/10365 [9:16:19<51:56:30, 21.16s/it]                                                         {'loss': 1.1494, 'grad_norm': 0.91796875, 'learning_rate': 9.47199323781657e-05, 'epoch': 0.15}
 15%|█▍        | 1530/10365 [9:16:19<51:56:30, 21.16s/it] 15%|█▍        | 1531/10365 [9:16:44<54:44:31, 22.31s/it] 15%|█▍        | 1532/10365 [9:17:02<51:34:13, 21.02s/it] 15%|█▍        | 1533/10365 [9:17:24<51:45:57, 21.10s/it] 15%|█▍        | 1534/10365 [9:17:45<51:56:24, 21.17s/it] 15%|█▍        | 1535/10365 [9:18:08<53:03:40, 21.63s/it] 15%|█▍        | 1536/10365 [9:18:37<58:28:47, 23.84s/it] 15%|█▍        | 1537/10365 [9:18:55<54:48:42, 22.35s/it] 15%|█▍        | 1538/10365 [9:19:18<54:46:46, 22.34s/it] 15%|█▍        | 1539/10365 [9:19:40<54:44:12, 22.33s/it] 15%|█▍        | 1540/10365 [9:20:04<55:40:32, 22.71s/it]                                                         {'loss': 1.1512, 'grad_norm': 0.90234375, 'learning_rate': 9.465194337604896e-05, 'epoch': 0.15}
 15%|█▍        | 1540/10365 [9:20:04<55:40:32, 22.71s/it] 15%|█▍        | 1541/10365 [9:20:25<54:59:54, 22.44s/it] 15%|█▍        | 1542/10365 [9:20:48<54:59:46, 22.44s/it] 15%|█▍        | 1543/10365 [9:21:13<56:46:49, 23.17s/it] 15%|█▍        | 1544/10365 [9:21:37<57:54:28, 23.63s/it] 15%|█▍        | 1545/10365 [9:21:57<54:59:06, 22.44s/it] 15%|█▍        | 1546/10365 [9:22:24<57:53:51, 23.63s/it] 15%|█▍        | 1547/10365 [9:22:45<56:04:49, 22.90s/it] 15%|█▍        | 1548/10365 [9:23:07<55:41:04, 22.74s/it] 15%|█▍        | 1549/10365 [9:23:28<54:25:22, 22.22s/it] 15%|█▍        | 1550/10365 [9:23:46<51:22:38, 20.98s/it]                                                         {'loss': 1.1559, 'grad_norm': 1.0625, 'learning_rate': 9.45835441608132e-05, 'epoch': 0.15}
 15%|█▍        | 1550/10365 [9:23:46<51:22:38, 20.98s/it] 15%|█▍        | 1551/10365 [9:24:11<54:20:12, 22.19s/it] 15%|█▍        | 1552/10365 [9:24:32<53:36:23, 21.90s/it] 15%|█▍        | 1553/10365 [9:24:54<53:30:38, 21.86s/it] 15%|█▍        | 1554/10365 [9:25:17<54:32:29, 22.28s/it] 15%|█▌        | 1555/10365 [9:25:43<56:36:48, 23.13s/it] 15%|█▌        | 1556/10365 [9:26:00<52:13:05, 21.34s/it] 15%|█▌        | 1557/10365 [9:26:16<48:40:25, 19.89s/it] 15%|█▌        | 1558/10365 [9:26:36<48:38:05, 19.88s/it] 15%|█▌        | 1559/10365 [9:26:54<47:00:26, 19.22s/it] 15%|█▌        | 1560/10365 [9:27:11<45:41:44, 18.68s/it]                                                         {'loss': 1.0799, 'grad_norm': 1.1640625, 'learning_rate': 9.451473536083541e-05, 'epoch': 0.15}
 15%|█▌        | 1560/10365 [9:27:11<45:41:44, 18.68s/it] 15%|█▌        | 1561/10365 [9:27:34<48:49:22, 19.96s/it] 15%|█▌        | 1562/10365 [9:27:53<47:53:21, 19.58s/it] 15%|█▌        | 1563/10365 [9:28:14<49:10:08, 20.11s/it] 15%|█▌        | 1564/10365 [9:28:35<49:49:10, 20.38s/it] 15%|█▌        | 1565/10365 [9:28:53<47:38:16, 19.49s/it] 15%|█▌        | 1566/10365 [9:29:13<48:20:20, 19.78s/it] 15%|█▌        | 1567/10365 [9:29:35<50:03:28, 20.48s/it] 15%|█▌        | 1568/10365 [9:29:58<51:39:40, 21.14s/it] 15%|█▌        | 1569/10365 [9:30:23<54:15:19, 22.21s/it] 15%|█▌        | 1570/10365 [9:30:44<53:34:15, 21.93s/it]                                                         {'loss': 1.1504, 'grad_norm': 1.09375, 'learning_rate': 9.444551760825549e-05, 'epoch': 0.15}
 15%|█▌        | 1570/10365 [9:30:44<53:34:15, 21.93s/it] 15%|█▌        | 1571/10365 [9:31:06<53:27:56, 21.89s/it] 15%|█▌        | 1572/10365 [9:31:25<51:53:20, 21.24s/it] 15%|█▌        | 1573/10365 [9:31:51<54:51:36, 22.46s/it] 15%|█▌        | 1574/10365 [9:32:08<51:03:35, 20.91s/it] 15%|█▌        | 1575/10365 [9:32:30<51:57:33, 21.28s/it] 15%|█▌        | 1576/10365 [9:32:55<54:18:49, 22.25s/it] 15%|█▌        | 1577/10365 [9:33:15<52:57:06, 21.69s/it] 15%|█▌        | 1578/10365 [9:33:35<51:52:41, 21.25s/it] 15%|█▌        | 1579/10365 [9:33:50<46:59:24, 19.25s/it] 15%|█▌        | 1580/10365 [9:34:14<50:47:35, 20.81s/it]                                                         {'loss': 1.1042, 'grad_norm': 1.03125, 'learning_rate': 9.437589153897024e-05, 'epoch': 0.15}
 15%|█▌        | 1580/10365 [9:34:14<50:47:35, 20.81s/it] 15%|█▌        | 1581/10365 [9:34:37<52:00:07, 21.31s/it] 15%|█▌        | 1582/10365 [9:35:02<54:39:17, 22.40s/it] 15%|█▌        | 1583/10365 [9:35:23<53:46:19, 22.04s/it] 15%|█▌        | 1584/10365 [9:35:46<54:27:51, 22.33s/it] 15%|█▌        | 1585/10365 [9:36:11<56:47:59, 23.29s/it] 15%|█▌        | 1586/10365 [9:36:32<54:57:56, 22.54s/it] 15%|█▌        | 1587/10365 [9:36:50<51:17:13, 21.03s/it] 15%|█▌        | 1588/10365 [9:37:08<49:05:27, 20.14s/it] 15%|█▌        | 1589/10365 [9:37:30<50:43:20, 20.81s/it] 15%|█▌        | 1590/10365 [9:37:51<51:00:05, 20.92s/it]                                                         {'loss': 1.1322, 'grad_norm': 0.984375, 'learning_rate': 9.430585779262769e-05, 'epoch': 0.15}
 15%|█▌        | 1590/10365 [9:37:51<51:00:05, 20.92s/it] 15%|█▌        | 1591/10365 [9:38:15<53:06:57, 21.79s/it] 15%|█▌        | 1592/10365 [9:38:33<50:26:10, 20.70s/it] 15%|█▌        | 1593/10365 [9:38:55<51:13:06, 21.02s/it] 15%|█▌        | 1594/10365 [9:39:16<50:52:29, 20.88s/it] 15%|█▌        | 1595/10365 [9:39:36<50:37:49, 20.78s/it] 15%|█▌        | 1596/10365 [9:39:57<50:36:03, 20.77s/it] 15%|█▌        | 1597/10365 [9:40:18<50:35:20, 20.77s/it] 15%|█▌        | 1598/10365 [9:40:40<51:43:56, 21.24s/it] 15%|█▌        | 1599/10365 [9:41:02<52:11:22, 21.43s/it] 15%|█▌        | 1600/10365 [9:41:27<55:00:49, 22.60s/it]                                                         {'loss': 1.1129, 'grad_norm': 1.046875, 'learning_rate': 9.423541701262115e-05, 'epoch': 0.15}
 15%|█▌        | 1600/10365 [9:41:27<55:00:49, 22.60s/it] 15%|█▌        | 1601/10365 [9:41:47<52:51:30, 21.71s/it] 15%|█▌        | 1602/10365 [9:42:12<55:04:27, 22.63s/it] 15%|█▌        | 1603/10365 [9:42:31<52:18:24, 21.49s/it] 15%|█▌        | 1604/10365 [9:42:51<51:20:01, 21.09s/it] 15%|█▌        | 1605/10365 [9:43:16<54:15:21, 22.30s/it] 15%|█▌        | 1606/10365 [9:43:40<55:34:47, 22.84s/it] 16%|█▌        | 1607/10365 [9:44:03<55:27:41, 22.80s/it] 16%|█▌        | 1608/10365 [9:44:20<51:25:39, 21.14s/it] 16%|█▌        | 1609/10365 [9:44:38<49:05:57, 20.19s/it] 16%|█▌        | 1610/10365 [9:45:09<57:05:48, 23.48s/it]                                                         {'loss': 1.1595, 'grad_norm': 0.9375, 'learning_rate': 9.41645698460833e-05, 'epoch': 0.16}
 16%|█▌        | 1610/10365 [9:45:09<57:05:48, 23.48s/it] 16%|█▌        | 1611/10365 [9:45:29<54:47:24, 22.53s/it] 16%|█▌        | 1612/10365 [9:45:52<55:07:08, 22.67s/it] 16%|█▌        | 1613/10365 [9:46:13<53:50:06, 22.14s/it] 16%|█▌        | 1614/10365 [9:46:40<57:03:00, 23.47s/it] 16%|█▌        | 1615/10365 [9:47:06<59:08:00, 24.33s/it] 16%|█▌        | 1616/10365 [9:47:23<53:51:11, 22.16s/it] 16%|█▌        | 1617/10365 [9:47:47<55:13:55, 22.73s/it] 16%|█▌        | 1618/10365 [9:48:11<56:09:50, 23.12s/it] 16%|█▌        | 1619/10365 [9:48:38<58:52:32, 24.23s/it] 16%|█▌        | 1620/10365 [9:48:55<53:28:37, 22.01s/it]                                                         {'loss': 1.1182, 'grad_norm': 1.046875, 'learning_rate': 9.409331694388029e-05, 'epoch': 0.16}
 16%|█▌        | 1620/10365 [9:48:55<53:28:37, 22.01s/it] 16%|█▌        | 1621/10365 [9:49:13<50:50:57, 20.94s/it] 16%|█▌        | 1622/10365 [9:49:36<51:54:49, 21.38s/it] 16%|█▌        | 1623/10365 [9:49:55<50:28:44, 20.79s/it] 16%|█▌        | 1624/10365 [9:50:16<50:34:25, 20.83s/it] 16%|█▌        | 1625/10365 [9:50:35<49:06:47, 20.23s/it] 16%|█▌        | 1626/10365 [9:50:54<48:20:54, 19.92s/it] 16%|█▌        | 1627/10365 [9:51:16<49:53:08, 20.55s/it] 16%|█▌        | 1628/10365 [9:51:38<51:02:40, 21.03s/it] 16%|█▌        | 1629/10365 [9:51:54<47:24:57, 19.54s/it] 16%|█▌        | 1630/10365 [9:52:17<49:53:20, 20.56s/it]                                                         {'loss': 1.1141, 'grad_norm': 0.875, 'learning_rate': 9.402165896060565e-05, 'epoch': 0.16}
 16%|█▌        | 1630/10365 [9:52:17<49:53:20, 20.56s/it] 16%|█▌        | 1631/10365 [9:52:38<49:36:58, 20.45s/it] 16%|█▌        | 1632/10365 [9:53:03<53:13:54, 21.94s/it] 16%|█▌        | 1633/10365 [9:53:32<58:24:31, 24.08s/it] 16%|█▌        | 1634/10365 [9:53:49<53:14:55, 21.96s/it] 16%|█▌        | 1635/10365 [9:54:18<58:38:46, 24.18s/it] 16%|█▌        | 1636/10365 [9:54:39<55:54:19, 23.06s/it] 16%|█▌        | 1637/10365 [9:55:00<54:39:30, 22.54s/it] 16%|█▌        | 1638/10365 [9:55:20<52:26:56, 21.64s/it] 16%|█▌        | 1639/10365 [9:55:40<51:31:18, 21.26s/it] 16%|█▌        | 1640/10365 [9:55:58<49:14:05, 20.31s/it]                                                         {'loss': 1.1217, 'grad_norm': 0.984375, 'learning_rate': 9.394959655457442e-05, 'epoch': 0.16}
 16%|█▌        | 1640/10365 [9:55:58<49:14:05, 20.31s/it] 16%|█▌        | 1641/10365 [9:56:23<52:21:45, 21.61s/it] 16%|█▌        | 1642/10365 [9:56:45<52:25:04, 21.63s/it] 16%|█▌        | 1643/10365 [9:57:04<50:56:01, 21.02s/it] 16%|█▌        | 1644/10365 [9:57:29<53:40:28, 22.16s/it] 16%|█▌        | 1645/10365 [9:57:54<55:29:44, 22.91s/it] 16%|█▌        | 1646/10365 [9:58:15<54:20:38, 22.44s/it] 16%|█▌        | 1647/10365 [9:58:36<53:20:55, 22.03s/it] 16%|█▌        | 1648/10365 [9:58:56<51:37:37, 21.32s/it] 16%|█▌        | 1649/10365 [9:59:20<53:40:29, 22.17s/it] 16%|█▌        | 1650/10365 [9:59:46<56:35:53, 23.38s/it]                                                         {'loss': 1.1041, 'grad_norm': 0.84765625, 'learning_rate': 9.387713038781702e-05, 'epoch': 0.16}
 16%|█▌        | 1650/10365 [9:59:46<56:35:53, 23.38s/it] 16%|█▌        | 1651/10365 [10:00:06<54:08:02, 22.36s/it] 16%|█▌        | 1652/10365 [10:00:30<55:38:20, 22.99s/it] 16%|█▌        | 1653/10365 [10:00:54<56:21:37, 23.29s/it] 16%|█▌        | 1654/10365 [10:01:20<58:09:43, 24.04s/it] 16%|█▌        | 1655/10365 [10:01:41<55:59:42, 23.14s/it] 16%|█▌        | 1656/10365 [10:02:02<54:14:31, 22.42s/it] 16%|█▌        | 1657/10365 [10:02:22<52:22:42, 21.65s/it] 16%|█▌        | 1658/10365 [10:02:44<52:29:30, 21.70s/it] 16%|█▌        | 1659/10365 [10:03:04<51:32:08, 21.31s/it] 16%|█▌        | 1660/10365 [10:03:30<54:53:38, 22.70s/it]                                                          {'loss': 1.1265, 'grad_norm': 0.96875, 'learning_rate': 9.380426112607317e-05, 'epoch': 0.16}
 16%|█▌        | 1660/10365 [10:03:30<54:53:38, 22.70s/it] 16%|█▌        | 1661/10365 [10:03:49<51:55:35, 21.48s/it] 16%|█▌        | 1662/10365 [10:04:04<47:27:01, 19.63s/it] 16%|█▌        | 1663/10365 [10:04:25<48:14:51, 19.96s/it] 16%|█▌        | 1664/10365 [10:04:44<47:57:17, 19.84s/it] 16%|█▌        | 1665/10365 [10:05:07<49:46:48, 20.60s/it] 16%|█▌        | 1666/10365 [10:05:28<49:58:07, 20.68s/it] 16%|█▌        | 1667/10365 [10:05:48<50:01:26, 20.70s/it] 16%|█▌        | 1668/10365 [10:06:14<53:47:42, 22.27s/it] 16%|█▌        | 1669/10365 [10:06:34<52:02:08, 21.54s/it] 16%|█▌        | 1670/10365 [10:06:54<51:08:41, 21.18s/it]                                                          {'loss': 1.1668, 'grad_norm': 1.0, 'learning_rate': 9.373098943878574e-05, 'epoch': 0.16}
 16%|█▌        | 1670/10365 [10:06:54<51:08:41, 21.18s/it] 16%|█▌        | 1671/10365 [10:07:12<48:39:59, 20.15s/it] 16%|█▌        | 1672/10365 [10:07:32<48:43:08, 20.18s/it] 16%|█▌        | 1673/10365 [10:07:51<47:15:36, 19.57s/it] 16%|█▌        | 1674/10365 [10:08:11<47:59:51, 19.88s/it] 16%|█▌        | 1675/10365 [10:08:28<46:07:38, 19.11s/it] 16%|█▌        | 1676/10365 [10:08:50<48:00:03, 19.89s/it] 16%|█▌        | 1677/10365 [10:09:09<47:08:18, 19.53s/it] 16%|█▌        | 1678/10365 [10:09:30<48:09:52, 19.96s/it] 16%|█▌        | 1679/10365 [10:09:51<49:07:07, 20.36s/it] 16%|█▌        | 1680/10365 [10:10:13<49:55:35, 20.69s/it]                                                          {'loss': 1.122, 'grad_norm': 0.9609375, 'learning_rate': 9.365731599909476e-05, 'epoch': 0.16}
 16%|█▌        | 1680/10365 [10:10:13<49:55:35, 20.69s/it] 16%|█▌        | 1681/10365 [10:10:29<46:35:29, 19.31s/it] 16%|█▌        | 1682/10365 [10:10:51<48:28:39, 20.10s/it] 16%|█▌        | 1683/10365 [10:11:11<48:22:37, 20.06s/it] 16%|█▌        | 1684/10365 [10:11:37<52:53:19, 21.93s/it] 16%|█▋        | 1685/10365 [10:11:59<52:48:42, 21.90s/it] 16%|█▋        | 1686/10365 [10:12:17<50:33:22, 20.97s/it] 16%|█▋        | 1687/10365 [10:12:42<53:09:06, 22.05s/it] 16%|█▋        | 1688/10365 [10:13:03<52:00:39, 21.58s/it] 16%|█▋        | 1689/10365 [10:13:26<53:39:34, 22.27s/it] 16%|█▋        | 1690/10365 [10:13:48<52:54:31, 21.96s/it]                                                          {'loss': 1.1234, 'grad_norm': 0.9921875, 'learning_rate': 9.358324148383098e-05, 'epoch': 0.16}
 16%|█▋        | 1690/10365 [10:13:48<52:54:31, 21.96s/it] 16%|█▋        | 1691/10365 [10:14:08<51:56:53, 21.56s/it] 16%|█▋        | 1692/10365 [10:14:26<49:24:42, 20.51s/it] 16%|█▋        | 1693/10365 [10:14:45<48:03:37, 19.95s/it] 16%|█▋        | 1694/10365 [10:15:06<48:31:47, 20.15s/it] 16%|█▋        | 1695/10365 [10:15:29<51:13:03, 21.27s/it] 16%|█▋        | 1696/10365 [10:15:50<50:55:55, 21.15s/it] 16%|█▋        | 1697/10365 [10:16:13<52:04:32, 21.63s/it] 16%|█▋        | 1698/10365 [10:16:33<50:32:32, 20.99s/it] 16%|█▋        | 1699/10365 [10:16:52<49:35:46, 20.60s/it] 16%|█▋        | 1700/10365 [10:17:18<53:30:58, 22.23s/it]                                                          {'loss': 1.1136, 'grad_norm': 0.98828125, 'learning_rate': 9.350876657350992e-05, 'epoch': 0.16}
 16%|█▋        | 1700/10365 [10:17:18<53:30:58, 22.23s/it] 16%|█▋        | 1701/10365 [10:17:38<51:29:44, 21.40s/it] 16%|█▋        | 1702/10365 [10:17:56<49:13:17, 20.45s/it] 16%|█▋        | 1703/10365 [10:18:16<48:52:55, 20.32s/it] 16%|█▋        | 1704/10365 [10:18:34<47:24:59, 19.71s/it] 16%|█▋        | 1705/10365 [10:18:51<45:26:32, 18.89s/it] 16%|█▋        | 1706/10365 [10:19:12<46:25:25, 19.30s/it] 16%|█▋        | 1707/10365 [10:19:29<45:21:52, 18.86s/it] 16%|█▋        | 1708/10365 [10:19:59<53:08:43, 22.10s/it] 16%|█▋        | 1709/10365 [10:20:15<48:51:43, 20.32s/it] 16%|█▋        | 1710/10365 [10:20:38<50:19:37, 20.93s/it]                                                          {'loss': 1.1206, 'grad_norm': 1.1015625, 'learning_rate': 9.343389195232542e-05, 'epoch': 0.16}
 16%|█▋        | 1710/10365 [10:20:38<50:19:37, 20.93s/it] 17%|█▋        | 1711/10365 [10:20:54<46:52:45, 19.50s/it] 17%|█▋        | 1712/10365 [10:21:18<50:19:50, 20.94s/it] 17%|█▋        | 1713/10365 [10:21:39<50:40:40, 21.09s/it] 17%|█▋        | 1714/10365 [10:22:02<51:54:45, 21.60s/it] 17%|█▋        | 1715/10365 [10:22:17<46:42:52, 19.44s/it] 17%|█▋        | 1716/10365 [10:22:35<45:59:11, 19.14s/it] 17%|█▋        | 1717/10365 [10:22:54<45:50:11, 19.08s/it] 17%|█▋        | 1718/10365 [10:23:17<48:18:14, 20.11s/it] 17%|█▋        | 1719/10365 [10:23:39<50:08:19, 20.88s/it] 17%|█▋        | 1720/10365 [10:24:02<51:11:42, 21.32s/it]                                                          {'loss': 1.1504, 'grad_norm': 0.9609375, 'learning_rate': 9.335861830814341e-05, 'epoch': 0.17}
 17%|█▋        | 1720/10365 [10:24:02<51:11:42, 21.32s/it] 17%|█▋        | 1721/10365 [10:24:17<46:49:38, 19.50s/it] 17%|█▋        | 1722/10365 [10:24:37<47:17:29, 19.70s/it] 17%|█▋        | 1723/10365 [10:25:00<49:49:48, 20.76s/it] 17%|█▋        | 1724/10365 [10:25:26<53:23:21, 22.24s/it] 17%|█▋        | 1725/10365 [10:25:51<55:07:31, 22.97s/it] 17%|█▋        | 1726/10365 [10:26:15<55:54:05, 23.30s/it] 17%|█▋        | 1727/10365 [10:26:36<54:09:58, 22.57s/it] 17%|█▋        | 1728/10365 [10:26:54<51:31:14, 21.47s/it] 17%|█▋        | 1729/10365 [10:27:13<49:12:02, 20.51s/it] 17%|█▋        | 1730/10365 [10:27:36<51:22:03, 21.42s/it]                                                          {'loss': 1.1139, 'grad_norm': 1.0703125, 'learning_rate': 9.328294633249566e-05, 'epoch': 0.17}
 17%|█▋        | 1730/10365 [10:27:36<51:22:03, 21.42s/it] 17%|█▋        | 1731/10365 [10:27:55<49:37:15, 20.69s/it] 17%|█▋        | 1732/10365 [10:28:17<50:32:07, 21.07s/it] 17%|█▋        | 1733/10365 [10:28:49<58:32:00, 24.41s/it] 17%|█▋        | 1734/10365 [10:29:10<55:28:19, 23.14s/it] 17%|█▋        | 1735/10365 [10:29:36<58:01:58, 24.21s/it] 17%|█▋        | 1736/10365 [10:30:03<59:49:11, 24.96s/it] 17%|█▋        | 1737/10365 [10:30:20<54:23:59, 22.70s/it] 17%|█▋        | 1738/10365 [10:30:40<51:55:37, 21.67s/it] 17%|█▋        | 1739/10365 [10:31:02<52:12:11, 21.79s/it] 17%|█▋        | 1740/10365 [10:31:24<52:18:36, 21.83s/it]                                                          {'loss': 1.0863, 'grad_norm': 0.98828125, 'learning_rate': 9.320687672057335e-05, 'epoch': 0.17}
 17%|█▋        | 1740/10365 [10:31:24<52:18:36, 21.83s/it] 17%|█▋        | 1741/10365 [10:31:44<51:29:29, 21.49s/it] 17%|█▋        | 1742/10365 [10:32:04<49:49:48, 20.80s/it] 17%|█▋        | 1743/10365 [10:32:31<54:40:55, 22.83s/it] 17%|█▋        | 1744/10365 [10:32:51<52:43:28, 22.02s/it] 17%|█▋        | 1745/10365 [10:33:13<52:30:02, 21.93s/it] 17%|█▋        | 1746/10365 [10:33:33<51:04:18, 21.33s/it] 17%|█▋        | 1747/10365 [10:33:52<49:35:47, 20.72s/it] 17%|█▋        | 1748/10365 [10:34:12<49:13:48, 20.57s/it] 17%|█▋        | 1749/10365 [10:34:29<46:08:28, 19.28s/it] 17%|█▋        | 1750/10365 [10:34:49<46:58:50, 19.63s/it]                                                          {'loss': 1.1045, 'grad_norm': 0.9921875, 'learning_rate': 9.31304101712207e-05, 'epoch': 0.17}
 17%|█▋        | 1750/10365 [10:34:49<46:58:50, 19.63s/it] 17%|█▋        | 1751/10365 [10:35:05<44:06:02, 18.43s/it] 17%|█▋        | 1752/10365 [10:35:26<46:09:27, 19.29s/it] 17%|█▋        | 1753/10365 [10:35:44<45:22:25, 18.97s/it] 17%|█▋        | 1754/10365 [10:36:05<46:45:06, 19.55s/it] 17%|█▋        | 1755/10365 [10:36:21<43:59:03, 18.39s/it] 17%|█▋        | 1756/10365 [10:36:40<44:37:46, 18.66s/it] 17%|█▋        | 1757/10365 [10:37:03<47:46:53, 19.98s/it] 17%|█▋        | 1758/10365 [10:37:29<51:38:45, 21.60s/it] 17%|█▋        | 1759/10365 [10:37:52<52:56:43, 22.15s/it] 17%|█▋        | 1760/10365 [10:38:15<53:35:44, 22.42s/it]                                                          {'loss': 1.1122, 'grad_norm': 0.984375, 'learning_rate': 9.305354738692858e-05, 'epoch': 0.17}
 17%|█▋        | 1760/10365 [10:38:15<53:35:44, 22.42s/it] 17%|█▋        | 1761/10365 [10:38:36<52:18:48, 21.89s/it] 17%|█▋        | 1762/10365 [10:39:00<53:54:29, 22.56s/it] 17%|█▋        | 1763/10365 [10:39:24<54:53:44, 22.97s/it] 17%|█▋        | 1764/10365 [10:39:49<56:43:56, 23.75s/it] 17%|█▋        | 1765/10365 [10:40:11<55:28:23, 23.22s/it] 17%|█▋        | 1766/10365 [10:40:30<51:57:10, 21.75s/it] 17%|█▋        | 1767/10365 [10:40:54<53:34:06, 22.43s/it] 17%|█▋        | 1768/10365 [10:41:15<52:48:41, 22.11s/it] 17%|█▋        | 1769/10365 [10:41:39<54:15:51, 22.73s/it] 17%|█▋        | 1770/10365 [10:42:02<54:01:38, 22.63s/it]                                                          {'loss': 1.1288, 'grad_norm': 0.98046875, 'learning_rate': 9.2976289073828e-05, 'epoch': 0.17}
 17%|█▋        | 1770/10365 [10:42:02<54:01:38, 22.63s/it] 17%|█▋        | 1771/10365 [10:42:23<52:54:32, 22.16s/it] 17%|█▋        | 1772/10365 [10:42:43<51:51:05, 21.72s/it] 17%|█▋        | 1773/10365 [10:43:04<50:54:16, 21.33s/it] 17%|█▋        | 1774/10365 [10:43:28<53:09:07, 22.27s/it] 17%|█▋        | 1775/10365 [10:43:52<53:53:20, 22.58s/it] 17%|█▋        | 1776/10365 [10:44:14<53:33:40, 22.45s/it] 17%|█▋        | 1777/10365 [10:44:38<55:05:57, 23.10s/it] 17%|█▋        | 1778/10365 [10:45:01<54:55:25, 23.03s/it] 17%|█▋        | 1779/10365 [10:45:22<53:26:49, 22.41s/it] 17%|█▋        | 1780/10365 [10:45:45<53:34:43, 22.47s/it]                                                          {'loss': 1.0905, 'grad_norm': 0.92578125, 'learning_rate': 9.289863594168365e-05, 'epoch': 0.17}
 17%|█▋        | 1780/10365 [10:45:45<53:34:43, 22.47s/it] 17%|█▋        | 1781/10365 [10:46:03<50:52:23, 21.34s/it] 17%|█▋        | 1782/10365 [10:46:23<49:53:28, 20.93s/it] 17%|█▋        | 1783/10365 [10:46:47<51:46:23, 21.72s/it] 17%|█▋        | 1784/10365 [10:47:09<51:58:37, 21.81s/it] 17%|█▋        | 1785/10365 [10:47:32<52:57:08, 22.22s/it] 17%|█▋        | 1786/10365 [10:47:51<50:24:27, 21.15s/it] 17%|█▋        | 1787/10365 [10:48:11<49:52:20, 20.93s/it] 17%|█▋        | 1788/10365 [10:48:30<48:27:53, 20.34s/it] 17%|█▋        | 1789/10365 [10:48:51<49:05:44, 20.61s/it] 17%|█▋        | 1790/10365 [10:49:10<47:25:40, 19.91s/it]                                                          {'loss': 1.0989, 'grad_norm': 0.91796875, 'learning_rate': 9.28205887038874e-05, 'epoch': 0.17}
 17%|█▋        | 1790/10365 [10:49:10<47:25:40, 19.91s/it] 17%|█▋        | 1791/10365 [10:49:31<48:27:00, 20.34s/it] 17%|█▋        | 1792/10365 [10:49:51<48:17:09, 20.28s/it] 17%|█▋        | 1793/10365 [10:50:11<47:59:41, 20.16s/it] 17%|█▋        | 1794/10365 [10:50:31<48:02:19, 20.18s/it] 17%|█▋        | 1795/10365 [10:50:49<45:57:11, 19.30s/it] 17%|█▋        | 1796/10365 [10:51:06<44:20:37, 18.63s/it] 17%|█▋        | 1797/10365 [10:51:28<47:05:36, 19.79s/it] 17%|█▋        | 1798/10365 [10:51:48<47:27:02, 19.94s/it] 17%|█▋        | 1799/10365 [10:52:06<45:59:33, 19.33s/it] 17%|█▋        | 1800/10365 [10:52:24<45:03:10, 18.94s/it]                                                          {'loss': 1.1189, 'grad_norm': 0.96875, 'learning_rate': 9.274214807745179e-05, 'epoch': 0.17}
 17%|█▋        | 1800/10365 [10:52:24<45:03:10, 18.94s/it] 17%|█▋        | 1801/10365 [10:52:39<42:18:23, 17.78s/it] 17%|█▋        | 1802/10365 [10:53:00<43:57:53, 18.48s/it] 17%|█▋        | 1803/10365 [10:53:19<44:19:55, 18.64s/it] 17%|█▋        | 1804/10365 [10:53:38<45:00:29, 18.93s/it] 17%|█▋        | 1805/10365 [10:53:56<43:54:34, 18.47s/it] 17%|█▋        | 1806/10365 [10:54:13<43:07:25, 18.14s/it] 17%|█▋        | 1807/10365 [10:54:36<46:44:10, 19.66s/it] 17%|█▋        | 1808/10365 [10:54:58<48:30:29, 20.41s/it] 17%|█▋        | 1809/10365 [10:55:19<48:55:20, 20.58s/it] 17%|█▋        | 1810/10365 [10:55:39<48:20:41, 20.34s/it]                                                          {'loss': 1.1362, 'grad_norm': 0.9765625, 'learning_rate': 9.266331478300328e-05, 'epoch': 0.17}
 17%|█▋        | 1810/10365 [10:55:39<48:20:41, 20.34s/it] 17%|█▋        | 1811/10365 [10:55:59<48:17:48, 20.33s/it] 17%|█▋        | 1812/10365 [10:56:26<52:31:27, 22.11s/it] 17%|█▋        | 1813/10365 [10:56:50<54:09:57, 22.80s/it] 18%|█▊        | 1814/10365 [10:57:11<52:48:38, 22.23s/it] 18%|█▊        | 1815/10365 [10:57:35<54:09:23, 22.80s/it] 18%|█▊        | 1816/10365 [10:57:52<49:51:43, 21.00s/it] 18%|█▊        | 1817/10365 [10:58:11<48:41:23, 20.51s/it] 18%|█▊        | 1818/10365 [10:58:34<49:59:25, 21.06s/it] 18%|█▊        | 1819/10365 [10:58:52<47:59:58, 20.22s/it] 18%|█▊        | 1820/10365 [10:59:13<48:40:59, 20.51s/it]                                                          {'loss': 1.1062, 'grad_norm': 0.90625, 'learning_rate': 9.25840895447758e-05, 'epoch': 0.18}
 18%|█▊        | 1820/10365 [10:59:13<48:40:59, 20.51s/it] 18%|█▊        | 1821/10365 [10:59:35<49:38:27, 20.92s/it] 18%|█▊        | 1822/10365 [10:59:53<47:53:10, 20.18s/it] 18%|█▊        | 1823/10365 [11:00:17<50:09:14, 21.14s/it] 18%|█▊        | 1824/10365 [11:00:44<54:28:00, 22.96s/it] 18%|█▊        | 1825/10365 [11:01:05<53:12:36, 22.43s/it] 18%|█▊        | 1826/10365 [11:01:22<49:15:22, 20.77s/it] 18%|█▊        | 1827/10365 [11:01:40<47:14:18, 19.92s/it] 18%|█▊        | 1828/10365 [11:02:01<47:53:45, 20.20s/it] 18%|█▊        | 1829/10365 [11:02:21<48:01:00, 20.25s/it] 18%|█▊        | 1830/10365 [11:02:41<47:28:42, 20.03s/it]                                                          {'loss': 1.1037, 'grad_norm': 0.98046875, 'learning_rate': 9.2504473090604e-05, 'epoch': 0.18}
 18%|█▊        | 1830/10365 [11:02:41<47:28:42, 20.03s/it] 18%|█▊        | 1831/10365 [11:03:03<48:57:57, 20.66s/it] 18%|█▊        | 1832/10365 [11:03:25<49:44:45, 20.99s/it] 18%|█▊        | 1833/10365 [11:03:51<53:44:53, 22.68s/it] 18%|█▊        | 1834/10365 [11:04:15<54:22:27, 22.95s/it] 18%|█▊        | 1835/10365 [11:04:34<52:02:57, 21.97s/it] 18%|█▊        | 1836/10365 [11:04:53<49:56:03, 21.08s/it] 18%|█▊        | 1837/10365 [11:05:14<49:48:49, 21.03s/it] 18%|█▊        | 1838/10365 [11:05:38<51:41:09, 21.82s/it] 18%|█▊        | 1839/10365 [11:06:00<51:33:20, 21.77s/it] 18%|█▊        | 1840/10365 [11:06:20<50:28:46, 21.32s/it]                                                          {'loss': 1.1278, 'grad_norm': 1.09375, 'learning_rate': 9.24244661519166e-05, 'epoch': 0.18}
 18%|█▊        | 1840/10365 [11:06:20<50:28:46, 21.32s/it] 18%|█▊        | 1841/10365 [11:06:39<48:51:15, 20.63s/it] 18%|█▊        | 1842/10365 [11:07:00<49:11:59, 20.78s/it] 18%|█▊        | 1843/10365 [11:07:21<49:09:54, 20.77s/it] 18%|█▊        | 1844/10365 [11:07:46<52:03:56, 22.00s/it] 18%|█▊        | 1845/10365 [11:08:12<54:58:17, 23.23s/it] 18%|█▊        | 1846/10365 [11:08:36<55:56:48, 23.64s/it] 18%|█▊        | 1847/10365 [11:09:10<62:58:40, 26.62s/it] 18%|█▊        | 1848/10365 [11:09:31<59:15:04, 25.04s/it] 18%|█▊        | 1849/10365 [11:09:54<57:48:34, 24.44s/it] 18%|█▊        | 1850/10365 [11:10:16<55:50:57, 23.61s/it]                                                          {'loss': 1.1094, 'grad_norm': 1.0, 'learning_rate': 9.234406946372969e-05, 'epoch': 0.18}
 18%|█▊        | 1850/10365 [11:10:16<55:50:57, 23.61s/it] 18%|█▊        | 1851/10365 [11:10:40<55:59:22, 23.67s/it] 18%|█▊        | 1852/10365 [11:10:57<51:36:12, 21.82s/it] 18%|█▊        | 1853/10365 [11:11:16<49:19:33, 20.86s/it] 18%|█▊        | 1854/10365 [11:11:33<46:24:19, 19.63s/it] 18%|█▊        | 1855/10365 [11:12:02<53:01:47, 22.43s/it] 18%|█▊        | 1856/10365 [11:12:25<53:39:13, 22.70s/it] 18%|█▊        | 1857/10365 [11:12:45<51:29:51, 21.79s/it] 18%|█▊        | 1858/10365 [11:13:09<53:11:09, 22.51s/it] 18%|█▊        | 1859/10365 [11:13:29<51:09:39, 21.65s/it] 18%|█▊        | 1860/10365 [11:13:54<53:30:05, 22.65s/it]                                                          {'loss': 1.0927, 'grad_norm': 0.87890625, 'learning_rate': 9.226328376463991e-05, 'epoch': 0.18}
 18%|█▊        | 1860/10365 [11:13:54<53:30:05, 22.65s/it] 18%|█▊        | 1861/10365 [11:14:12<50:36:44, 21.43s/it] 18%|█▊        | 1862/10365 [11:14:31<48:47:36, 20.66s/it] 18%|█▊        | 1863/10365 [11:14:50<47:54:40, 20.29s/it] 18%|█▊        | 1864/10365 [11:15:13<49:21:43, 20.90s/it] 18%|█▊        | 1865/10365 [11:15:31<47:43:56, 20.22s/it] 18%|█▊        | 1866/10365 [11:15:50<46:50:04, 19.84s/it] 18%|█▊        | 1867/10365 [11:16:09<46:09:12, 19.55s/it] 18%|█▊        | 1868/10365 [11:16:28<45:34:50, 19.31s/it] 18%|█▊        | 1869/10365 [11:16:49<46:46:58, 19.82s/it] 18%|█▊        | 1870/10365 [11:17:13<49:54:33, 21.15s/it]                                                          {'loss': 1.0888, 'grad_norm': 0.89453125, 'learning_rate': 9.218210979681772e-05, 'epoch': 0.18}
 18%|█▊        | 1870/10365 [11:17:13<49:54:33, 21.15s/it] 18%|█▊        | 1871/10365 [11:17:32<48:28:32, 20.55s/it] 18%|█▊        | 1872/10365 [11:17:50<46:31:35, 19.72s/it] 18%|█▊        | 1873/10365 [11:18:15<50:18:23, 21.33s/it] 18%|█▊        | 1874/10365 [11:18:35<49:00:00, 20.78s/it] 18%|█▊        | 1875/10365 [11:18:56<49:16:30, 20.89s/it] 18%|█▊        | 1876/10365 [11:19:13<46:35:39, 19.76s/it] 18%|█▊        | 1877/10365 [11:19:30<44:48:10, 19.00s/it] 18%|█▊        | 1878/10365 [11:19:48<44:11:48, 18.75s/it] 18%|█▊        | 1879/10365 [11:20:12<47:54:42, 20.33s/it] 18%|█▊        | 1880/10365 [11:20:35<49:42:00, 21.09s/it]                                                          {'loss': 1.0967, 'grad_norm': 1.0078125, 'learning_rate': 9.21005483060006e-05, 'epoch': 0.18}
 18%|█▊        | 1880/10365 [11:20:35<49:42:00, 21.09s/it] 18%|█▊        | 1881/10365 [11:20:56<49:31:56, 21.02s/it] 18%|█▊        | 1882/10365 [11:21:15<48:17:56, 20.50s/it] 18%|█▊        | 1883/10365 [11:21:35<47:59:09, 20.37s/it] 18%|█▊        | 1884/10365 [11:21:58<49:47:28, 21.14s/it] 18%|█▊        | 1885/10365 [11:22:18<48:43:36, 20.69s/it] 18%|█▊        | 1886/10365 [11:22:36<46:37:24, 19.80s/it] 18%|█▊        | 1887/10365 [11:22:59<49:07:51, 20.86s/it] 18%|█▊        | 1888/10365 [11:23:24<52:17:48, 22.21s/it] 18%|█▊        | 1889/10365 [11:23:47<52:21:00, 22.23s/it] 18%|█▊        | 1890/10365 [11:24:06<50:13:17, 21.33s/it]                                                          {'loss': 1.1196, 'grad_norm': 0.96875, 'learning_rate': 9.201860004148613e-05, 'epoch': 0.18}
 18%|█▊        | 1890/10365 [11:24:06<50:13:17, 21.33s/it] 18%|█▊        | 1891/10365 [11:24:29<51:08:18, 21.73s/it] 18%|█▊        | 1892/10365 [11:24:49<50:30:07, 21.46s/it] 18%|█▊        | 1893/10365 [11:25:08<48:44:56, 20.71s/it] 18%|█▊        | 1894/10365 [11:25:26<46:26:38, 19.74s/it] 18%|█▊        | 1895/10365 [11:25:49<48:51:44, 20.77s/it] 18%|█▊        | 1896/10365 [11:26:12<50:11:50, 21.34s/it] 18%|█▊        | 1897/10365 [11:26:30<47:52:48, 20.36s/it] 18%|█▊        | 1898/10365 [11:26:51<48:16:03, 20.52s/it] 18%|█▊        | 1899/10365 [11:27:11<48:28:02, 20.61s/it] 18%|█▊        | 1900/10365 [11:27:35<50:12:37, 21.35s/it]                                                          {'loss': 1.0991, 'grad_norm': 0.87890625, 'learning_rate': 9.193626575612512e-05, 'epoch': 0.18}
 18%|█▊        | 1900/10365 [11:27:35<50:12:37, 21.35s/it] 18%|█▊        | 1901/10365 [11:27:52<47:20:01, 20.13s/it] 18%|█▊        | 1902/10365 [11:28:09<45:27:24, 19.34s/it] 18%|█▊        | 1903/10365 [11:28:30<46:38:00, 19.84s/it] 18%|█▊        | 1904/10365 [11:28:53<48:35:37, 20.68s/it] 18%|█▊        | 1905/10365 [11:29:13<48:14:08, 20.53s/it] 18%|█▊        | 1906/10365 [11:29:37<50:19:25, 21.42s/it] 18%|█▊        | 1907/10365 [11:29:58<50:06:49, 21.33s/it] 18%|█▊        | 1908/10365 [11:30:17<48:30:00, 20.65s/it] 18%|█▊        | 1909/10365 [11:30:38<49:03:57, 20.89s/it] 18%|█▊        | 1910/10365 [11:30:56<46:42:01, 19.88s/it]                                                          {'loss': 1.1069, 'grad_norm': 0.96875, 'learning_rate': 9.185354620631481e-05, 'epoch': 0.18}
 18%|█▊        | 1910/10365 [11:30:56<46:42:01, 19.88s/it] 18%|█▊        | 1911/10365 [11:31:16<46:36:48, 19.85s/it] 18%|█▊        | 1912/10365 [11:31:37<47:33:02, 20.25s/it] 18%|█▊        | 1913/10365 [11:31:56<46:50:19, 19.95s/it] 18%|█▊        | 1914/10365 [11:32:11<43:31:58, 18.54s/it] 18%|█▊        | 1915/10365 [11:32:37<48:39:18, 20.73s/it] 18%|█▊        | 1916/10365 [11:32:59<49:26:48, 21.07s/it] 18%|█▊        | 1917/10365 [11:33:22<50:36:52, 21.57s/it] 19%|█▊        | 1918/10365 [11:33:42<49:28:45, 21.09s/it] 19%|█▊        | 1919/10365 [11:34:04<50:10:04, 21.38s/it] 19%|█▊        | 1920/10365 [11:34:23<48:39:04, 20.74s/it]                                                          {'loss': 1.1259, 'grad_norm': 0.9765625, 'learning_rate': 9.177044215199171e-05, 'epoch': 0.19}
 19%|█▊        | 1920/10365 [11:34:23<48:39:04, 20.74s/it] 19%|█▊        | 1921/10365 [11:34:41<46:43:33, 19.92s/it] 19%|█▊        | 1922/10365 [11:35:02<47:35:55, 20.30s/it] 19%|█▊        | 1923/10365 [11:35:23<47:44:01, 20.36s/it] 19%|█▊        | 1924/10365 [11:35:44<48:32:47, 20.70s/it] 19%|█▊        | 1925/10365 [11:35:59<44:31:54, 18.99s/it] 19%|█▊        | 1926/10365 [11:36:21<46:22:32, 19.78s/it] 19%|█▊        | 1927/10365 [11:36:43<48:24:34, 20.65s/it] 19%|█▊        | 1928/10365 [11:37:04<48:25:20, 20.66s/it] 19%|█▊        | 1929/10365 [11:37:22<46:10:22, 19.70s/it] 19%|█▊        | 1930/10365 [11:37:40<44:52:59, 19.16s/it]                                                          {'loss': 1.1196, 'grad_norm': 1.0234375, 'learning_rate': 9.168695435662482e-05, 'epoch': 0.19}
 19%|█▊        | 1930/10365 [11:37:40<44:52:59, 19.16s/it] 19%|█▊        | 1931/10365 [11:37:57<43:56:09, 18.75s/it] 19%|█▊        | 1932/10365 [11:38:16<44:09:59, 18.85s/it] 19%|█▊        | 1933/10365 [11:38:42<48:41:06, 20.79s/it] 19%|█▊        | 1934/10365 [11:39:02<48:25:50, 20.68s/it] 19%|█▊        | 1935/10365 [11:39:27<51:03:37, 21.81s/it] 19%|█▊        | 1936/10365 [11:39:51<52:46:31, 22.54s/it] 19%|█▊        | 1937/10365 [11:40:15<53:55:37, 23.03s/it] 19%|█▊        | 1938/10365 [11:40:38<53:52:17, 23.01s/it] 19%|█▊        | 1939/10365 [11:41:04<55:44:21, 23.81s/it] 19%|█▊        | 1940/10365 [11:41:24<53:37:42, 22.92s/it]                                                          {'loss': 1.124, 'grad_norm': 0.9765625, 'learning_rate': 9.160308358720851e-05, 'epoch': 0.19}
 19%|█▊        | 1940/10365 [11:41:24<53:37:42, 22.92s/it] 19%|█▊        | 1941/10365 [11:41:40<48:32:46, 20.75s/it] 19%|█▊        | 1942/10365 [11:42:01<48:43:52, 20.83s/it] 19%|█▊        | 1943/10365 [11:42:20<47:13:32, 20.19s/it] 19%|█▉        | 1944/10365 [11:42:44<50:16:55, 21.50s/it] 19%|█▉        | 1945/10365 [11:43:10<52:50:49, 22.59s/it] 19%|█▉        | 1946/10365 [11:43:30<51:34:42, 22.06s/it] 19%|█▉        | 1947/10365 [11:43:52<51:26:47, 22.00s/it] 19%|█▉        | 1948/10365 [11:44:11<48:58:04, 20.94s/it] 19%|█▉        | 1949/10365 [11:44:30<48:00:37, 20.54s/it] 19%|█▉        | 1950/10365 [11:44:56<51:26:33, 22.01s/it]                                                          {'loss': 1.1221, 'grad_norm': 0.953125, 'learning_rate': 9.151883061425546e-05, 'epoch': 0.19}
 19%|█▉        | 1950/10365 [11:44:56<51:26:33, 22.01s/it] 19%|█▉        | 1951/10365 [11:45:20<52:45:20, 22.57s/it] 19%|█▉        | 1952/10365 [11:45:40<50:59:50, 21.82s/it] 19%|█▉        | 1953/10365 [11:46:03<51:54:30, 22.21s/it] 19%|█▉        | 1954/10365 [11:46:24<51:11:28, 21.91s/it] 19%|█▉        | 1955/10365 [11:46:50<53:55:50, 23.09s/it] 19%|█▉        | 1956/10365 [11:47:13<54:00:56, 23.12s/it] 19%|█▉        | 1957/10365 [11:47:35<53:28:16, 22.89s/it] 19%|█▉        | 1958/10365 [11:47:59<53:59:33, 23.12s/it] 19%|█▉        | 1959/10365 [11:48:19<51:29:57, 22.06s/it] 19%|█▉        | 1960/10365 [11:48:35<47:41:56, 20.43s/it]                                                          {'loss': 1.1212, 'grad_norm': 0.984375, 'learning_rate': 9.143419621178969e-05, 'epoch': 0.19}
 19%|█▉        | 1960/10365 [11:48:35<47:41:56, 20.43s/it] 19%|█▉        | 1961/10365 [11:49:02<52:02:09, 22.29s/it] 19%|█▉        | 1962/10365 [11:49:20<49:10:04, 21.06s/it] 19%|█▉        | 1963/10365 [11:49:46<52:43:48, 22.59s/it] 19%|█▉        | 1964/10365 [11:50:06<50:23:23, 21.59s/it] 19%|█▉        | 1965/10365 [11:50:23<47:36:26, 20.40s/it] 19%|█▉        | 1966/10365 [11:50:37<43:10:29, 18.51s/it] 19%|█▉        | 1967/10365 [11:50:59<45:31:59, 19.52s/it] 19%|█▉        | 1968/10365 [11:51:22<47:57:51, 20.56s/it] 19%|█▉        | 1969/10365 [11:51:40<45:45:08, 19.62s/it] 19%|█▉        | 1970/10365 [11:51:58<45:01:01, 19.30s/it]                                                          {'loss': 1.0706, 'grad_norm': 1.078125, 'learning_rate': 9.13491811573393e-05, 'epoch': 0.19}
 19%|█▉        | 1970/10365 [11:51:58<45:01:01, 19.30s/it] 19%|█▉        | 1971/10365 [11:52:15<43:26:17, 18.63s/it] 19%|█▉        | 1972/10365 [11:52:35<44:15:07, 18.98s/it] 19%|█▉        | 1973/10365 [11:52:58<47:07:28, 20.22s/it] 19%|█▉        | 1974/10365 [11:53:18<47:13:29, 20.26s/it] 19%|█▉        | 1975/10365 [11:53:38<46:29:39, 19.95s/it] 19%|█▉        | 1976/10365 [11:53:58<46:48:05, 20.08s/it] 19%|█▉        | 1977/10365 [11:54:22<49:10:28, 21.11s/it] 19%|█▉        | 1978/10365 [11:54:38<45:55:34, 19.71s/it] 19%|█▉        | 1979/10365 [11:54:56<44:48:14, 19.23s/it] 19%|█▉        | 1980/10365 [11:55:20<48:03:49, 20.64s/it]                                                          {'loss': 1.0805, 'grad_norm': 1.0234375, 'learning_rate': 9.126378623192945e-05, 'epoch': 0.19}
 19%|█▉        | 1980/10365 [11:55:20<48:03:49, 20.64s/it] 19%|█▉        | 1981/10365 [11:55:41<48:00:01, 20.61s/it] 19%|█▉        | 1982/10365 [11:55:59<46:25:59, 19.94s/it] 19%|█▉        | 1983/10365 [11:56:20<47:11:17, 20.27s/it] 19%|█▉        | 1984/10365 [11:56:42<48:04:27, 20.65s/it] 19%|█▉        | 1985/10365 [11:56:59<45:41:12, 19.63s/it] 19%|█▉        | 1986/10365 [11:57:17<44:44:38, 19.22s/it] 19%|█▉        | 1987/10365 [11:57:40<47:16:24, 20.31s/it] 19%|█▉        | 1988/10365 [11:57:59<46:36:33, 20.03s/it] 19%|█▉        | 1989/10365 [11:58:18<45:53:34, 19.72s/it] 19%|█▉        | 1990/10365 [11:58:46<51:13:45, 22.02s/it]                                                          {'loss': 1.1456, 'grad_norm': 0.984375, 'learning_rate': 9.117801222007513e-05, 'epoch': 0.19}
 19%|█▉        | 1990/10365 [11:58:46<51:13:45, 22.02s/it] 19%|█▉        | 1991/10365 [11:59:07<50:44:14, 21.81s/it] 19%|█▉        | 1992/10365 [11:59:26<48:42:05, 20.94s/it] 19%|█▉        | 1993/10365 [11:59:44<46:54:03, 20.17s/it] 19%|█▉        | 1994/10365 [12:00:09<49:43:44, 21.39s/it] 19%|█▉        | 1995/10365 [12:00:32<51:02:06, 21.95s/it] 19%|█▉        | 1996/10365 [12:00:50<48:19:05, 20.78s/it] 19%|█▉        | 1997/10365 [12:01:09<47:22:11, 20.38s/it] 19%|█▉        | 1998/10365 [12:01:31<47:57:20, 20.63s/it] 19%|█▉        | 1999/10365 [12:01:48<45:31:01, 19.59s/it] 19%|█▉        | 2000/10365 [12:02:06<44:29:14, 19.15s/it]                                                          {'loss': 1.1126, 'grad_norm': 1.09375, 'learning_rate': 9.109185990977393e-05, 'epoch': 0.19}
 19%|█▉        | 2000/10365 [12:02:06<44:29:14, 19.15s/it][INFO|trainer.py:3719] 2024-05-30 22:56:31,663 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-30 22:56:31,663 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-30 22:56:31,663 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:47,  1.76s/it][A
  5%|▍         | 3/63 [00:08<03:16,  3.27s/it][A
  6%|▋         | 4/63 [00:13<03:47,  3.86s/it][A
  8%|▊         | 5/63 [00:18<04:06,  4.25s/it][A
 10%|▉         | 6/63 [00:23<04:11,  4.41s/it][A
 11%|█         | 7/63 [00:28<04:16,  4.59s/it][A
 13%|█▎        | 8/63 [00:33<04:14,  4.63s/it][A
 14%|█▍        | 9/63 [00:38<04:17,  4.76s/it][A
 16%|█▌        | 10/63 [00:43<04:26,  5.02s/it][A
 17%|█▋        | 11/63 [00:49<04:35,  5.29s/it][A
 19%|█▉        | 12/63 [00:54<04:21,  5.12s/it][A
 21%|██        | 13/63 [00:59<04:15,  5.11s/it][A
 22%|██▏       | 14/63 [01:04<04:02,  4.95s/it][A
 24%|██▍       | 15/63 [01:09<04:00,  5.00s/it][A
 25%|██▌       | 16/63 [01:14<03:54,  4.99s/it][A
 27%|██▋       | 17/63 [01:19<03:50,  5.02s/it][A
 29%|██▊       | 18/63 [01:24<03:51,  5.15s/it][A
 30%|███       | 19/63 [01:30<03:52,  5.29s/it][A
 32%|███▏      | 20/63 [01:35<03:51,  5.38s/it][A
 33%|███▎      | 21/63 [01:40<03:34,  5.11s/it][A
 35%|███▍      | 22/63 [01:47<03:47,  5.55s/it][A
 37%|███▋      | 23/63 [01:50<03:19,  5.00s/it][A
 38%|███▊      | 24/63 [01:56<03:22,  5.18s/it][A
 40%|███▉      | 25/63 [02:02<03:22,  5.34s/it][A
 41%|████▏     | 26/63 [02:06<03:12,  5.20s/it][A
 43%|████▎     | 27/63 [02:12<03:12,  5.35s/it][A
 44%|████▍     | 28/63 [02:18<03:14,  5.56s/it][A
 46%|████▌     | 29/63 [02:25<03:23,  5.97s/it][A
 48%|████▊     | 30/63 [02:29<03:01,  5.49s/it][A
 49%|████▉     | 31/63 [02:35<02:51,  5.37s/it][A
 51%|█████     | 32/63 [02:39<02:34,  4.98s/it][A
 52%|█████▏    | 33/63 [02:45<02:37,  5.26s/it][A
 54%|█████▍    | 34/63 [02:48<02:17,  4.76s/it][A
 56%|█████▌    | 35/63 [02:53<02:13,  4.76s/it][A
 57%|█████▋    | 36/63 [02:57<02:04,  4.60s/it][A
 59%|█████▊    | 37/63 [03:04<02:14,  5.19s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.30s/it][A
 62%|██████▏   | 39/63 [03:14<02:01,  5.07s/it][A
 63%|██████▎   | 40/63 [03:19<01:57,  5.10s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.15s/it][A
 67%|██████▋   | 42/63 [03:31<01:59,  5.67s/it][A
 68%|██████▊   | 43/63 [03:37<01:53,  5.67s/it][A
 70%|██████▉   | 44/63 [03:41<01:42,  5.39s/it][A
 71%|███████▏  | 45/63 [03:48<01:45,  5.85s/it][A
 73%|███████▎  | 46/63 [03:54<01:38,  5.82s/it][A
 75%|███████▍  | 47/63 [04:00<01:32,  5.78s/it][A
 76%|███████▌  | 48/63 [04:07<01:31,  6.12s/it][A
 78%|███████▊  | 49/63 [04:11<01:18,  5.64s/it][A
 79%|███████▉  | 50/63 [04:18<01:16,  5.91s/it][A
 81%|████████  | 51/63 [04:23<01:09,  5.80s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.13s/it][A
 84%|████████▍ | 53/63 [04:36<00:59,  5.93s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.82s/it][A
 87%|████████▋ | 55/63 [04:46<00:43,  5.38s/it][A
 89%|████████▉ | 56/63 [04:51<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.31s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.21s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.16s/it][A
 95%|█████████▌| 60/63 [05:10<00:14,  4.89s/it][A
 97%|█████████▋| 61/63 [05:17<00:10,  5.41s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.67s/it][A
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A                                                          
                                               [A{'eval_loss': 1.1128840446472168, 'eval_runtime': 336.3994, 'eval_samples_per_second': 14.863, 'eval_steps_per_second': 0.187, 'epoch': 0.19}
 19%|█▉        | 2000/10365 [12:07:42<44:29:14, 19.15s/it]
100%|██████████| 63/63 [05:29<00:00,  5.83s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-30 23:02:10,361 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-2000
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-30 23:02:10,409 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-30 23:02:10,410 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-2000/special_tokens_map.json
 19%|█▉        | 2001/10365 [12:08:15<288:41:43, 124.26s/it] 19%|█▉        | 2002/10365 [12:08:38<217:37:14, 93.68s/it]  19%|█▉        | 2003/10365 [12:08:55<164:23:33, 70.77s/it] 19%|█▉        | 2004/10365 [12:09:13<127:32:34, 54.92s/it] 19%|█▉        | 2005/10365 [12:09:36<105:15:39, 45.33s/it] 19%|█▉        | 2006/10365 [12:09:59<89:41:11, 38.63s/it]  19%|█▉        | 2007/10365 [12:10:18<75:51:52, 32.68s/it] 19%|█▉        | 2008/10365 [12:10:40<69:01:38, 29.74s/it] 19%|█▉        | 2009/10365 [12:11:01<62:56:01, 27.11s/it] 19%|█▉        | 2010/10365 [12:11:22<58:20:34, 25.14s/it]                                                          {'loss': 1.0898, 'grad_norm': 1.046875, 'learning_rate': 9.10053300924989e-05, 'epoch': 0.19}
 19%|█▉        | 2010/10365 [12:11:22<58:20:34, 25.14s/it] 19%|█▉        | 2011/10365 [12:11:45<56:53:10, 24.51s/it] 19%|█▉        | 2012/10365 [12:12:07<54:56:29, 23.68s/it] 19%|█▉        | 2013/10365 [12:12:24<50:38:12, 21.83s/it] 19%|█▉        | 2014/10365 [12:12:45<49:36:17, 21.38s/it] 19%|█▉        | 2015/10365 [12:13:05<48:51:44, 21.07s/it] 19%|█▉        | 2016/10365 [12:13:22<46:22:32, 20.00s/it] 19%|█▉        | 2017/10365 [12:13:39<44:07:54, 19.03s/it] 19%|█▉        | 2018/10365 [12:14:03<47:38:16, 20.55s/it] 19%|█▉        | 2019/10365 [12:14:23<46:53:46, 20.23s/it] 19%|█▉        | 2020/10365 [12:14:42<46:17:54, 19.97s/it]                                                          {'loss': 1.1273, 'grad_norm': 0.98046875, 'learning_rate': 9.091842356319114e-05, 'epoch': 0.19}
 19%|█▉        | 2020/10365 [12:14:42<46:17:54, 19.97s/it] 19%|█▉        | 2021/10365 [12:15:05<48:23:58, 20.88s/it] 20%|█▉        | 2022/10365 [12:15:25<47:23:00, 20.45s/it] 20%|█▉        | 2023/10365 [12:15:44<46:27:50, 20.05s/it] 20%|█▉        | 2024/10365 [12:16:09<50:03:07, 21.60s/it] 20%|█▉        | 2025/10365 [12:16:31<50:24:48, 21.76s/it] 20%|█▉        | 2026/10365 [12:16:51<49:10:08, 21.23s/it] 20%|█▉        | 2027/10365 [12:17:12<48:35:44, 20.98s/it] 20%|█▉        | 2028/10365 [12:17:31<47:25:55, 20.48s/it] 20%|█▉        | 2029/10365 [12:17:50<46:28:31, 20.07s/it] 20%|█▉        | 2030/10365 [12:18:16<50:24:14, 21.77s/it]                                                          {'loss': 1.0983, 'grad_norm': 0.98828125, 'learning_rate': 9.08311411202526e-05, 'epoch': 0.2}
 20%|█▉        | 2030/10365 [12:18:16<50:24:14, 21.77s/it] 20%|█▉        | 2031/10365 [12:18:34<48:09:33, 20.80s/it] 20%|█▉        | 2032/10365 [12:18:56<48:57:08, 21.15s/it] 20%|█▉        | 2033/10365 [12:19:24<53:53:52, 23.29s/it] 20%|█▉        | 2034/10365 [12:19:46<52:28:22, 22.67s/it] 20%|█▉        | 2035/10365 [12:20:04<49:46:26, 21.51s/it] 20%|█▉        | 2036/10365 [12:20:24<48:31:08, 20.97s/it] 20%|█▉        | 2037/10365 [12:20:40<44:46:01, 19.35s/it] 20%|█▉        | 2038/10365 [12:21:05<48:55:12, 21.15s/it] 20%|█▉        | 2039/10365 [12:21:26<48:59:54, 21.19s/it] 20%|█▉        | 2040/10365 [12:21:52<52:23:38, 22.66s/it]                                                          {'loss': 1.0416, 'grad_norm': 0.96875, 'learning_rate': 9.07434835655387e-05, 'epoch': 0.2}
 20%|█▉        | 2040/10365 [12:21:52<52:23:38, 22.66s/it] 20%|█▉        | 2041/10365 [12:22:16<53:06:17, 22.97s/it] 20%|█▉        | 2042/10365 [12:22:41<54:20:32, 23.51s/it] 20%|█▉        | 2043/10365 [12:23:04<54:15:49, 23.47s/it] 20%|█▉        | 2044/10365 [12:23:24<51:20:42, 22.21s/it] 20%|█▉        | 2045/10365 [12:23:45<50:53:58, 22.02s/it] 20%|█▉        | 2046/10365 [12:24:11<53:22:30, 23.10s/it] 20%|█▉        | 2047/10365 [12:24:39<56:44:31, 24.56s/it] 20%|█▉        | 2048/10365 [12:24:59<53:43:41, 23.26s/it] 20%|█▉        | 2049/10365 [12:25:17<50:18:17, 21.78s/it] 20%|█▉        | 2050/10365 [12:25:41<51:35:53, 22.34s/it]                                                          {'loss': 1.1007, 'grad_norm': 0.96484375, 'learning_rate': 9.065545170435101e-05, 'epoch': 0.2}
 20%|█▉        | 2050/10365 [12:25:41<51:35:53, 22.34s/it] 20%|█▉        | 2051/10365 [12:26:05<53:05:59, 22.99s/it] 20%|█▉        | 2052/10365 [12:26:28<52:49:27, 22.88s/it] 20%|█▉        | 2053/10365 [12:26:50<52:27:18, 22.72s/it] 20%|█▉        | 2054/10365 [12:27:11<50:40:13, 21.95s/it] 20%|█▉        | 2055/10365 [12:27:33<50:54:37, 22.06s/it] 20%|█▉        | 2056/10365 [12:27:58<52:51:29, 22.90s/it] 20%|█▉        | 2057/10365 [12:28:21<52:53:20, 22.92s/it] 20%|█▉        | 2058/10365 [12:28:38<49:10:23, 21.31s/it] 20%|█▉        | 2059/10365 [12:28:56<46:54:29, 20.33s/it] 20%|█▉        | 2060/10365 [12:29:18<48:05:17, 20.84s/it]                                                          {'loss': 1.0731, 'grad_norm': 1.046875, 'learning_rate': 9.056704634542976e-05, 'epoch': 0.2}
 20%|█▉        | 2060/10365 [12:29:18<48:05:17, 20.84s/it] 20%|█▉        | 2061/10365 [12:29:39<47:45:39, 20.71s/it] 20%|█▉        | 2062/10365 [12:29:59<47:12:47, 20.47s/it] 20%|█▉        | 2063/10365 [12:30:22<49:20:41, 21.40s/it] 20%|█▉        | 2064/10365 [12:30:41<47:18:46, 20.52s/it] 20%|█▉        | 2065/10365 [12:31:01<47:04:30, 20.42s/it] 20%|█▉        | 2066/10365 [12:31:19<45:21:10, 19.67s/it] 20%|█▉        | 2067/10365 [12:31:39<46:01:36, 19.97s/it] 20%|█▉        | 2068/10365 [12:31:57<44:17:51, 19.22s/it] 20%|█▉        | 2069/10365 [12:32:19<46:13:21, 20.06s/it] 20%|█▉        | 2070/10365 [12:32:43<49:06:29, 21.31s/it]                                                          {'loss': 1.0945, 'grad_norm': 1.1171875, 'learning_rate': 9.047826830094652e-05, 'epoch': 0.2}
 20%|█▉        | 2070/10365 [12:32:43<49:06:29, 21.31s/it] 20%|█▉        | 2071/10365 [12:32:57<44:07:10, 19.15s/it] 20%|█▉        | 2072/10365 [12:33:12<41:13:45, 17.90s/it] 20%|██        | 2073/10365 [12:33:29<40:24:30, 17.54s/it] 20%|██        | 2074/10365 [12:33:46<39:53:59, 17.32s/it] 20%|██        | 2075/10365 [12:34:07<42:25:53, 18.43s/it] 20%|██        | 2076/10365 [12:34:29<45:21:03, 19.70s/it] 20%|██        | 2077/10365 [12:34:50<45:38:15, 19.82s/it] 20%|██        | 2078/10365 [12:35:11<46:47:54, 20.33s/it] 20%|██        | 2079/10365 [12:35:33<48:01:30, 20.87s/it] 20%|██        | 2080/10365 [12:35:54<47:58:11, 20.84s/it]                                                          {'loss': 1.0891, 'grad_norm': 0.9921875, 'learning_rate': 9.038911838649667e-05, 'epoch': 0.2}
 20%|██        | 2080/10365 [12:35:54<47:58:11, 20.84s/it] 20%|██        | 2081/10365 [12:36:11<45:23:15, 19.72s/it] 20%|██        | 2082/10365 [12:36:31<45:47:12, 19.90s/it] 20%|██        | 2083/10365 [12:36:53<46:54:49, 20.39s/it] 20%|██        | 2084/10365 [12:37:20<51:44:20, 22.49s/it] 20%|██        | 2085/10365 [12:37:43<51:38:06, 22.45s/it] 20%|██        | 2086/10365 [12:37:58<46:47:46, 20.35s/it] 20%|██        | 2087/10365 [12:38:27<52:42:50, 22.92s/it] 20%|██        | 2088/10365 [12:38:47<50:43:02, 22.06s/it] 20%|██        | 2089/10365 [12:39:08<49:44:20, 21.64s/it] 20%|██        | 2090/10365 [12:39:28<48:51:59, 21.26s/it]                                                          {'loss': 1.0918, 'grad_norm': 1.0703125, 'learning_rate': 9.029959742109188e-05, 'epoch': 0.2}
 20%|██        | 2090/10365 [12:39:28<48:51:59, 21.26s/it] 20%|██        | 2091/10365 [12:39:50<49:01:04, 21.33s/it] 20%|██        | 2092/10365 [12:40:13<50:27:55, 21.96s/it] 20%|██        | 2093/10365 [12:40:35<50:32:50, 22.00s/it] 20%|██        | 2094/10365 [12:41:00<52:09:28, 22.70s/it] 20%|██        | 2095/10365 [12:41:19<50:08:48, 21.83s/it] 20%|██        | 2096/10365 [12:41:36<46:31:51, 20.26s/it] 20%|██        | 2097/10365 [12:41:56<46:21:12, 20.18s/it] 20%|██        | 2098/10365 [12:42:14<44:38:45, 19.44s/it] 20%|██        | 2099/10365 [12:42:32<44:05:37, 19.20s/it] 20%|██        | 2100/10365 [12:42:52<44:08:34, 19.23s/it]                                                          {'loss': 1.0953, 'grad_norm': 1.1171875, 'learning_rate': 9.020970622715273e-05, 'epoch': 0.2}
 20%|██        | 2100/10365 [12:42:52<44:08:34, 19.23s/it] 20%|██        | 2101/10365 [12:43:16<47:27:38, 20.68s/it] 20%|██        | 2102/10365 [12:43:38<48:26:19, 21.10s/it] 20%|██        | 2103/10365 [12:43:58<47:57:45, 20.90s/it] 20%|██        | 2104/10365 [12:44:18<47:06:02, 20.53s/it] 20%|██        | 2105/10365 [12:44:43<50:02:58, 21.81s/it] 20%|██        | 2106/10365 [12:45:08<52:48:54, 23.02s/it] 20%|██        | 2107/10365 [12:45:29<50:46:29, 22.13s/it] 20%|██        | 2108/10365 [12:45:53<52:08:43, 22.74s/it] 20%|██        | 2109/10365 [12:46:15<51:36:48, 22.51s/it] 20%|██        | 2110/10365 [12:46:32<48:21:58, 21.09s/it]                                                          {'loss': 1.0867, 'grad_norm': 0.95703125, 'learning_rate': 9.011944563050093e-05, 'epoch': 0.2}
 20%|██        | 2110/10365 [12:46:32<48:21:58, 21.09s/it] 20%|██        | 2111/10365 [12:46:58<51:39:04, 22.53s/it] 20%|██        | 2112/10365 [12:47:17<48:44:18, 21.26s/it] 20%|██        | 2113/10365 [12:47:38<48:50:42, 21.31s/it] 20%|██        | 2114/10365 [12:48:02<50:45:08, 22.14s/it] 20%|██        | 2115/10365 [12:48:27<52:32:11, 22.93s/it] 20%|██        | 2116/10365 [12:48:46<49:36:17, 21.65s/it] 20%|██        | 2117/10365 [12:49:10<51:39:14, 22.55s/it] 20%|██        | 2118/10365 [12:49:34<52:32:50, 22.94s/it] 20%|██        | 2119/10365 [12:49:55<51:27:35, 22.47s/it] 20%|██        | 2120/10365 [12:50:13<48:20:24, 21.11s/it]                                                          {'loss': 1.1074, 'grad_norm': 0.9609375, 'learning_rate': 9.002881646035196e-05, 'epoch': 0.2}
 20%|██        | 2120/10365 [12:50:13<48:20:24, 21.11s/it] 20%|██        | 2121/10365 [12:50:33<47:02:37, 20.54s/it] 20%|██        | 2122/10365 [12:50:52<46:02:14, 20.11s/it] 20%|██        | 2123/10365 [12:51:09<44:28:15, 19.42s/it] 20%|██        | 2124/10365 [12:51:31<45:44:49, 19.98s/it] 21%|██        | 2125/10365 [12:51:53<47:12:31, 20.63s/it] 21%|██        | 2126/10365 [12:52:12<46:01:15, 20.11s/it] 21%|██        | 2127/10365 [12:52:32<45:57:05, 20.08s/it] 21%|██        | 2128/10365 [12:52:58<50:01:34, 21.86s/it] 21%|██        | 2129/10365 [12:53:20<50:11:14, 21.94s/it] 21%|██        | 2130/10365 [12:53:40<48:40:47, 21.28s/it]                                                          {'loss': 1.1265, 'grad_norm': 0.94140625, 'learning_rate': 8.99378195493073e-05, 'epoch': 0.21}
 21%|██        | 2130/10365 [12:53:40<48:40:47, 21.28s/it] 21%|██        | 2131/10365 [12:53:59<47:35:18, 20.81s/it] 21%|██        | 2132/10365 [12:54:20<47:18:25, 20.69s/it] 21%|██        | 2133/10365 [12:54:39<46:13:36, 20.22s/it] 21%|██        | 2134/10365 [12:54:59<46:03:15, 20.14s/it] 21%|██        | 2135/10365 [12:55:18<45:35:39, 19.94s/it] 21%|██        | 2136/10365 [12:55:38<45:23:55, 19.86s/it] 21%|██        | 2137/10365 [12:56:00<46:31:41, 20.36s/it] 21%|██        | 2138/10365 [12:56:19<46:13:53, 20.23s/it] 21%|██        | 2139/10365 [12:56:40<46:08:26, 20.19s/it] 21%|██        | 2140/10365 [12:56:59<45:34:12, 19.95s/it]                                                          {'loss': 1.1122, 'grad_norm': 0.90625, 'learning_rate': 8.984645573334685e-05, 'epoch': 0.21}
 21%|██        | 2140/10365 [12:56:59<45:34:12, 19.95s/it] 21%|██        | 2141/10365 [12:57:18<44:59:43, 19.70s/it] 21%|██        | 2142/10365 [12:57:34<42:40:18, 18.68s/it] 21%|██        | 2143/10365 [12:57:55<44:20:43, 19.42s/it] 21%|██        | 2144/10365 [12:58:17<45:34:51, 19.96s/it] 21%|██        | 2145/10365 [12:58:34<43:37:47, 19.11s/it] 21%|██        | 2146/10365 [12:58:57<46:14:05, 20.25s/it] 21%|██        | 2147/10365 [12:59:15<44:31:04, 19.50s/it] 21%|██        | 2148/10365 [12:59:38<47:19:51, 20.74s/it] 21%|██        | 2149/10365 [12:59:56<45:34:05, 19.97s/it] 21%|██        | 2150/10365 [13:00:17<46:10:47, 20.24s/it]                                                          {'loss': 1.0912, 'grad_norm': 1.0390625, 'learning_rate': 8.975472585182119e-05, 'epoch': 0.21}
 21%|██        | 2150/10365 [13:00:17<46:10:47, 20.24s/it] 21%|██        | 2151/10365 [13:00:44<50:51:49, 22.29s/it] 21%|██        | 2152/10365 [13:01:05<49:30:26, 21.70s/it] 21%|██        | 2153/10365 [13:01:24<47:41:12, 20.91s/it] 21%|██        | 2154/10365 [13:01:45<47:50:48, 20.98s/it] 21%|██        | 2155/10365 [13:02:01<44:33:53, 19.54s/it] 21%|██        | 2156/10365 [13:02:16<41:41:12, 18.28s/it] 21%|██        | 2157/10365 [13:02:38<44:07:45, 19.35s/it] 21%|██        | 2158/10365 [13:02:56<43:18:10, 18.99s/it] 21%|██        | 2159/10365 [13:03:21<47:16:49, 20.74s/it] 21%|██        | 2160/10365 [13:03:45<49:36:59, 21.77s/it]                                                          {'loss': 1.0893, 'grad_norm': 1.0234375, 'learning_rate': 8.966263074744396e-05, 'epoch': 0.21}
 21%|██        | 2160/10365 [13:03:45<49:36:59, 21.77s/it] 21%|██        | 2161/10365 [13:04:07<49:39:56, 21.79s/it] 21%|██        | 2162/10365 [13:04:27<48:02:17, 21.08s/it] 21%|██        | 2163/10365 [13:04:50<49:47:15, 21.85s/it] 21%|██        | 2164/10365 [13:05:06<45:56:22, 20.17s/it] 21%|██        | 2165/10365 [13:05:28<46:39:33, 20.48s/it] 21%|██        | 2166/10365 [13:05:45<44:16:32, 19.44s/it] 21%|██        | 2167/10365 [13:05:59<40:49:26, 17.93s/it] 21%|██        | 2168/10365 [13:06:19<42:14:42, 18.55s/it] 21%|██        | 2169/10365 [13:06:40<43:57:51, 19.31s/it] 21%|██        | 2170/10365 [13:06:58<42:40:51, 18.75s/it]                                                          {'loss': 1.095, 'grad_norm': 1.0390625, 'learning_rate': 8.957017126628406e-05, 'epoch': 0.21}
 21%|██        | 2170/10365 [13:06:58<42:40:51, 18.75s/it] 21%|██        | 2171/10365 [13:07:25<48:52:45, 21.47s/it] 21%|██        | 2172/10365 [13:07:49<50:26:08, 22.16s/it] 21%|██        | 2173/10365 [13:08:16<53:49:02, 23.65s/it] 21%|██        | 2174/10365 [13:08:35<50:13:21, 22.07s/it] 21%|██        | 2175/10365 [13:08:58<50:41:35, 22.28s/it] 21%|██        | 2176/10365 [13:09:16<48:13:03, 21.20s/it] 21%|██        | 2177/10365 [13:09:34<45:46:32, 20.13s/it] 21%|██        | 2178/10365 [13:09:56<46:58:24, 20.66s/it] 21%|██        | 2179/10365 [13:10:15<46:01:46, 20.24s/it] 21%|██        | 2180/10365 [13:10:34<45:18:02, 19.92s/it]                                                          {'loss': 1.1048, 'grad_norm': 0.89453125, 'learning_rate': 8.947734825775785e-05, 'epoch': 0.21}
 21%|██        | 2180/10365 [13:10:34<45:18:02, 19.92s/it] 21%|██        | 2181/10365 [13:10:58<48:03:13, 21.14s/it] 21%|██        | 2182/10365 [13:11:21<49:31:04, 21.78s/it] 21%|██        | 2183/10365 [13:11:38<46:02:10, 20.26s/it] 21%|██        | 2184/10365 [13:12:02<48:21:51, 21.28s/it] 21%|██        | 2185/10365 [13:12:21<46:51:01, 20.62s/it] 21%|██        | 2186/10365 [13:12:38<44:36:24, 19.63s/it] 21%|██        | 2187/10365 [13:12:57<44:22:20, 19.53s/it] 21%|██        | 2188/10365 [13:13:18<45:00:12, 19.81s/it] 21%|██        | 2189/10365 [13:13:42<47:56:24, 21.11s/it] 21%|██        | 2190/10365 [13:14:09<51:44:14, 22.78s/it]                                                          {'loss': 1.1261, 'grad_norm': 1.046875, 'learning_rate': 8.938416257462139e-05, 'epoch': 0.21}
 21%|██        | 2190/10365 [13:14:09<51:44:14, 22.78s/it] 21%|██        | 2191/10365 [13:14:27<48:20:03, 21.29s/it] 21%|██        | 2192/10365 [13:14:48<48:15:55, 21.26s/it] 21%|██        | 2193/10365 [13:15:10<48:37:52, 21.42s/it] 21%|██        | 2194/10365 [13:15:33<50:05:23, 22.07s/it] 21%|██        | 2195/10365 [13:15:53<48:53:29, 21.54s/it] 21%|██        | 2196/10365 [13:16:14<48:23:10, 21.32s/it] 21%|██        | 2197/10365 [13:16:40<51:18:16, 22.61s/it] 21%|██        | 2198/10365 [13:17:00<49:25:14, 21.78s/it] 21%|██        | 2199/10365 [13:17:24<50:46:56, 22.39s/it] 21%|██        | 2200/10365 [13:17:44<49:30:21, 21.83s/it]                                                          {'loss': 1.0531, 'grad_norm': 1.0078125, 'learning_rate': 8.929061507296265e-05, 'epoch': 0.21}
 21%|██        | 2200/10365 [13:17:44<49:30:21, 21.83s/it] 21%|██        | 2201/10365 [13:18:08<51:13:21, 22.59s/it] 21%|██        | 2202/10365 [13:18:31<51:15:00, 22.60s/it] 21%|██▏       | 2203/10365 [13:18:56<52:31:19, 23.17s/it] 21%|██▏       | 2204/10365 [13:19:18<52:08:07, 23.00s/it] 21%|██▏       | 2205/10365 [13:19:41<51:46:26, 22.84s/it] 21%|██▏       | 2206/10365 [13:20:01<49:53:37, 22.01s/it] 21%|██▏       | 2207/10365 [13:20:22<49:08:12, 21.68s/it] 21%|██▏       | 2208/10365 [13:20:39<46:30:07, 20.52s/it] 21%|██▏       | 2209/10365 [13:20:58<45:16:10, 19.98s/it] 21%|██▏       | 2210/10365 [13:21:14<42:32:57, 18.78s/it]                                                          {'loss': 1.0735, 'grad_norm': 1.0625, 'learning_rate': 8.919670661219353e-05, 'epoch': 0.21}
 21%|██▏       | 2210/10365 [13:21:14<42:32:57, 18.78s/it] 21%|██▏       | 2211/10365 [13:21:34<42:57:49, 18.97s/it] 21%|██▏       | 2212/10365 [13:21:58<46:39:08, 20.60s/it] 21%|██▏       | 2213/10365 [13:22:22<48:49:36, 21.56s/it] 21%|██▏       | 2214/10365 [13:22:40<46:14:58, 20.43s/it] 21%|██▏       | 2215/10365 [13:22:58<44:46:17, 19.78s/it] 21%|██▏       | 2216/10365 [13:23:20<46:14:57, 20.43s/it] 21%|██▏       | 2217/10365 [13:23:39<45:39:43, 20.17s/it] 21%|██▏       | 2218/10365 [13:24:07<50:35:05, 22.35s/it] 21%|██▏       | 2219/10365 [13:24:29<50:31:53, 22.33s/it] 21%|██▏       | 2220/10365 [13:24:49<49:00:14, 21.66s/it]                                                          {'loss': 1.1011, 'grad_norm': 1.0234375, 'learning_rate': 8.910243805504203e-05, 'epoch': 0.21}
 21%|██▏       | 2220/10365 [13:24:49<49:00:14, 21.66s/it] 21%|██▏       | 2221/10365 [13:25:07<46:14:18, 20.44s/it] 21%|██▏       | 2222/10365 [13:25:27<46:14:26, 20.44s/it] 21%|██▏       | 2223/10365 [13:25:52<49:24:44, 21.85s/it] 21%|██▏       | 2224/10365 [13:26:15<50:17:04, 22.24s/it] 21%|██▏       | 2225/10365 [13:26:35<48:18:11, 21.36s/it] 21%|██▏       | 2226/10365 [13:27:00<51:02:29, 22.58s/it] 21%|██▏       | 2227/10365 [13:27:22<50:12:55, 22.21s/it] 21%|██▏       | 2228/10365 [13:27:42<48:51:45, 21.62s/it] 22%|██▏       | 2229/10365 [13:28:02<47:43:55, 21.12s/it] 22%|██▏       | 2230/10365 [13:28:20<45:52:39, 20.30s/it]                                                          {'loss': 1.1166, 'grad_norm': 0.9453125, 'learning_rate': 8.900781026754435e-05, 'epoch': 0.22}
 22%|██▏       | 2230/10365 [13:28:20<45:52:39, 20.30s/it] 22%|██▏       | 2231/10365 [13:28:43<47:23:19, 20.97s/it] 22%|██▏       | 2232/10365 [13:28:58<43:49:37, 19.40s/it] 22%|██▏       | 2233/10365 [13:29:18<44:13:54, 19.58s/it] 22%|██▏       | 2234/10365 [13:29:40<45:16:37, 20.05s/it] 22%|██▏       | 2235/10365 [13:30:02<46:49:00, 20.73s/it] 22%|██▏       | 2236/10365 [13:30:24<47:44:27, 21.14s/it] 22%|██▏       | 2237/10365 [13:30:44<47:13:46, 20.92s/it] 22%|██▏       | 2238/10365 [13:31:03<45:55:48, 20.35s/it] 22%|██▏       | 2239/10365 [13:31:24<46:11:43, 20.47s/it] 22%|██▏       | 2240/10365 [13:31:43<45:03:49, 19.97s/it]                                                          {'loss': 1.0891, 'grad_norm': 0.9453125, 'learning_rate': 8.891282411903691e-05, 'epoch': 0.22}
 22%|██▏       | 2240/10365 [13:31:43<45:03:49, 19.97s/it] 22%|██▏       | 2241/10365 [13:32:01<44:04:32, 19.53s/it] 22%|██▏       | 2242/10365 [13:32:19<42:44:10, 18.94s/it] 22%|██▏       | 2243/10365 [13:32:38<42:36:40, 18.89s/it] 22%|██▏       | 2244/10365 [13:33:01<45:33:41, 20.20s/it] 22%|██▏       | 2245/10365 [13:33:25<48:15:10, 21.39s/it] 22%|██▏       | 2246/10365 [13:33:45<46:57:17, 20.82s/it] 22%|██▏       | 2247/10365 [13:34:01<43:35:37, 19.33s/it] 22%|██▏       | 2248/10365 [13:34:17<41:44:43, 18.51s/it] 22%|██▏       | 2249/10365 [13:34:47<49:39:00, 22.02s/it] 22%|██▏       | 2250/10365 [13:35:09<49:10:40, 21.82s/it]                                                          {'loss': 1.0831, 'grad_norm': 1.0, 'learning_rate': 8.881748048214833e-05, 'epoch': 0.22}
 22%|██▏       | 2250/10365 [13:35:09<49:10:40, 21.82s/it] 22%|██▏       | 2251/10365 [13:35:33<50:56:28, 22.60s/it] 22%|██▏       | 2252/10365 [13:35:56<51:15:10, 22.74s/it] 22%|██▏       | 2253/10365 [13:36:22<53:00:47, 23.53s/it] 22%|██▏       | 2254/10365 [13:36:44<52:27:16, 23.28s/it] 22%|██▏       | 2255/10365 [13:37:07<52:17:31, 23.21s/it] 22%|██▏       | 2256/10365 [13:37:27<49:53:17, 22.15s/it] 22%|██▏       | 2257/10365 [13:37:51<50:59:45, 22.64s/it] 22%|██▏       | 2258/10365 [13:38:11<49:34:06, 22.01s/it] 22%|██▏       | 2259/10365 [13:38:29<46:29:24, 20.65s/it] 22%|██▏       | 2260/10365 [13:38:47<44:44:28, 19.87s/it]                                                          {'loss': 1.1047, 'grad_norm': 0.94140625, 'learning_rate': 8.872178023279145e-05, 'epoch': 0.22}
 22%|██▏       | 2260/10365 [13:38:47<44:44:28, 19.87s/it] 22%|██▏       | 2261/10365 [13:39:10<47:00:53, 20.89s/it] 22%|██▏       | 2262/10365 [13:39:31<47:15:05, 20.99s/it] 22%|██▏       | 2263/10365 [13:39:53<48:00:49, 21.33s/it] 22%|██▏       | 2264/10365 [13:40:13<46:42:57, 20.76s/it] 22%|██▏       | 2265/10365 [13:40:30<44:31:02, 19.79s/it] 22%|██▏       | 2266/10365 [13:40:52<45:53:18, 20.40s/it] 22%|██▏       | 2267/10365 [13:41:14<46:49:51, 20.82s/it] 22%|██▏       | 2268/10365 [13:41:35<46:37:57, 20.73s/it] 22%|██▏       | 2269/10365 [13:41:59<48:50:10, 21.72s/it] 22%|██▏       | 2270/10365 [13:42:19<47:38:34, 21.19s/it]                                                          {'loss': 1.0725, 'grad_norm': 1.046875, 'learning_rate': 8.862572425015528e-05, 'epoch': 0.22}
 22%|██▏       | 2270/10365 [13:42:19<47:38:34, 21.19s/it] 22%|██▏       | 2271/10365 [13:42:38<46:41:04, 20.76s/it] 22%|██▏       | 2272/10365 [13:42:56<44:34:57, 19.83s/it] 22%|██▏       | 2273/10365 [13:43:14<43:25:28, 19.32s/it] 22%|██▏       | 2274/10365 [13:43:34<44:04:34, 19.61s/it] 22%|██▏       | 2275/10365 [13:43:56<45:13:18, 20.12s/it] 22%|██▏       | 2276/10365 [13:44:18<46:44:08, 20.80s/it] 22%|██▏       | 2277/10365 [13:44:38<45:50:45, 20.41s/it] 22%|██▏       | 2278/10365 [13:44:56<44:25:34, 19.78s/it] 22%|██▏       | 2279/10365 [13:45:17<45:10:37, 20.11s/it] 22%|██▏       | 2280/10365 [13:45:36<44:52:17, 19.98s/it]                                                          {'loss': 1.0936, 'grad_norm': 1.0625, 'learning_rate': 8.85293134166969e-05, 'epoch': 0.22}
 22%|██▏       | 2280/10365 [13:45:36<44:52:17, 19.98s/it] 22%|██▏       | 2281/10365 [13:45:59<46:27:15, 20.69s/it] 22%|██▏       | 2282/10365 [13:46:21<47:18:08, 21.07s/it] 22%|██▏       | 2283/10365 [13:46:46<49:52:15, 22.21s/it] 22%|██▏       | 2284/10365 [13:47:07<49:06:03, 21.87s/it] 22%|██▏       | 2285/10365 [13:47:27<48:14:55, 21.50s/it] 22%|██▏       | 2286/10365 [13:47:46<46:06:32, 20.55s/it] 22%|██▏       | 2287/10365 [13:48:06<46:11:35, 20.59s/it] 22%|██▏       | 2288/10365 [13:48:26<45:32:06, 20.30s/it] 22%|██▏       | 2289/10365 [13:48:49<47:37:17, 21.23s/it] 22%|██▏       | 2290/10365 [13:49:07<45:14:28, 20.17s/it]                                                          {'loss': 1.0892, 'grad_norm': 0.8984375, 'learning_rate': 8.843254861813341e-05, 'epoch': 0.22}
 22%|██▏       | 2290/10365 [13:49:07<45:14:28, 20.17s/it] 22%|██▏       | 2291/10365 [13:49:25<43:35:09, 19.43s/it] 22%|██▏       | 2292/10365 [13:49:44<43:43:27, 19.50s/it] 22%|██▏       | 2293/10365 [13:50:14<50:17:53, 22.43s/it] 22%|██▏       | 2294/10365 [13:50:32<47:12:02, 21.05s/it] 22%|██▏       | 2295/10365 [13:50:49<44:34:05, 19.88s/it] 22%|██▏       | 2296/10365 [13:51:09<44:52:30, 20.02s/it] 22%|██▏       | 2297/10365 [13:51:29<44:33:00, 19.88s/it] 22%|██▏       | 2298/10365 [13:51:45<42:07:34, 18.80s/it] 22%|██▏       | 2299/10365 [13:52:05<43:07:36, 19.25s/it] 22%|██▏       | 2300/10365 [13:52:27<44:35:01, 19.90s/it]                                                          {'loss': 1.1218, 'grad_norm': 1.0, 'learning_rate': 8.833543074343373e-05, 'epoch': 0.22}
 22%|██▏       | 2300/10365 [13:52:27<44:35:01, 19.90s/it] 22%|██▏       | 2301/10365 [13:52:50<47:06:41, 21.03s/it] 22%|██▏       | 2302/10365 [13:53:06<43:37:33, 19.48s/it] 22%|██▏       | 2303/10365 [13:53:30<46:50:29, 20.92s/it] 22%|██▏       | 2304/10365 [13:53:47<44:17:53, 19.78s/it] 22%|██▏       | 2305/10365 [13:54:04<41:54:29, 18.72s/it] 22%|██▏       | 2306/10365 [13:54:25<43:41:43, 19.52s/it] 22%|██▏       | 2307/10365 [13:54:42<42:00:04, 18.76s/it] 22%|██▏       | 2308/10365 [13:55:00<41:26:19, 18.52s/it] 22%|██▏       | 2309/10365 [13:55:19<41:57:19, 18.75s/it] 22%|██▏       | 2310/10365 [13:55:41<43:51:51, 19.60s/it]                                                          {'loss': 1.1023, 'grad_norm': 0.96484375, 'learning_rate': 8.823796068481043e-05, 'epoch': 0.22}
 22%|██▏       | 2310/10365 [13:55:41<43:51:51, 19.60s/it] 22%|██▏       | 2311/10365 [13:56:01<44:24:50, 19.85s/it] 22%|██▏       | 2312/10365 [13:56:21<44:09:11, 19.74s/it] 22%|██▏       | 2313/10365 [13:56:41<44:11:53, 19.76s/it] 22%|██▏       | 2314/10365 [13:57:03<45:39:17, 20.41s/it] 22%|██▏       | 2315/10365 [13:57:23<45:24:07, 20.30s/it] 22%|██▏       | 2316/10365 [13:57:38<42:14:20, 18.89s/it] 22%|██▏       | 2317/10365 [13:58:02<45:47:27, 20.48s/it] 22%|██▏       | 2318/10365 [13:58:23<45:59:34, 20.58s/it] 22%|██▏       | 2319/10365 [13:58:40<43:35:10, 19.50s/it] 22%|██▏       | 2320/10365 [13:59:00<43:47:01, 19.59s/it]                                                          {'loss': 1.0871, 'grad_norm': 0.97265625, 'learning_rate': 8.814013933771161e-05, 'epoch': 0.22}
 22%|██▏       | 2320/10365 [13:59:00<43:47:01, 19.59s/it] 22%|██▏       | 2321/10365 [13:59:20<44:03:44, 19.72s/it] 22%|██▏       | 2322/10365 [13:59:41<44:52:09, 20.08s/it] 22%|██▏       | 2323/10365 [14:00:03<45:57:56, 20.58s/it] 22%|██▏       | 2324/10365 [14:00:21<44:43:00, 20.02s/it] 22%|██▏       | 2325/10365 [14:00:45<47:00:07, 21.05s/it] 22%|██▏       | 2326/10365 [14:01:04<45:34:47, 20.41s/it] 22%|██▏       | 2327/10365 [14:01:30<49:24:17, 22.13s/it] 22%|██▏       | 2328/10365 [14:01:53<50:15:21, 22.51s/it] 22%|██▏       | 2329/10365 [14:02:14<48:48:50, 21.87s/it] 22%|██▏       | 2330/10365 [14:02:32<46:22:27, 20.78s/it]                                                          {'loss': 1.059, 'grad_norm': 0.953125, 'learning_rate': 8.804196760081258e-05, 'epoch': 0.22}
 22%|██▏       | 2330/10365 [14:02:32<46:22:27, 20.78s/it] 22%|██▏       | 2331/10365 [14:02:50<44:51:21, 20.10s/it] 22%|██▏       | 2332/10365 [14:03:14<47:12:19, 21.16s/it] 23%|██▎       | 2333/10365 [14:03:33<45:40:41, 20.47s/it] 23%|██▎       | 2334/10365 [14:03:52<44:54:15, 20.13s/it] 23%|██▎       | 2335/10365 [14:04:11<44:09:22, 19.80s/it] 23%|██▎       | 2336/10365 [14:04:31<43:56:54, 19.71s/it] 23%|██▎       | 2337/10365 [14:04:50<43:55:10, 19.69s/it] 23%|██▎       | 2338/10365 [14:05:12<45:04:30, 20.22s/it] 23%|██▎       | 2339/10365 [14:05:32<44:39:55, 20.03s/it] 23%|██▎       | 2340/10365 [14:05:53<45:32:12, 20.43s/it]                                                          {'loss': 1.1298, 'grad_norm': 1.2265625, 'learning_rate': 8.794344637600768e-05, 'epoch': 0.23}
 23%|██▎       | 2340/10365 [14:05:53<45:32:12, 20.43s/it] 23%|██▎       | 2341/10365 [14:06:14<45:47:08, 20.54s/it] 23%|██▎       | 2342/10365 [14:06:35<46:02:34, 20.66s/it] 23%|██▎       | 2343/10365 [14:06:55<46:02:42, 20.66s/it] 23%|██▎       | 2344/10365 [14:07:16<46:23:15, 20.82s/it] 23%|██▎       | 2345/10365 [14:07:38<46:54:41, 21.06s/it] 23%|██▎       | 2346/10365 [14:07:59<46:36:53, 20.93s/it] 23%|██▎       | 2347/10365 [14:08:18<45:37:28, 20.48s/it] 23%|██▎       | 2348/10365 [14:08:43<48:31:21, 21.79s/it] 23%|██▎       | 2349/10365 [14:09:06<49:23:13, 22.18s/it] 23%|██▎       | 2350/10365 [14:09:28<49:10:22, 22.09s/it]                                                          {'loss': 1.1077, 'grad_norm': 0.9765625, 'learning_rate': 8.784457656840194e-05, 'epoch': 0.23}
 23%|██▎       | 2350/10365 [14:09:28<49:10:22, 22.09s/it] 23%|██▎       | 2351/10365 [14:09:49<48:22:00, 21.73s/it] 23%|██▎       | 2352/10365 [14:10:04<44:11:39, 19.86s/it] 23%|██▎       | 2353/10365 [14:10:24<43:58:01, 19.76s/it] 23%|██▎       | 2354/10365 [14:10:41<42:28:58, 19.09s/it] 23%|██▎       | 2355/10365 [14:10:59<41:18:14, 18.56s/it] 23%|██▎       | 2356/10365 [14:11:20<43:01:30, 19.34s/it] 23%|██▎       | 2357/10365 [14:11:38<42:26:22, 19.08s/it] 23%|██▎       | 2358/10365 [14:11:59<43:28:48, 19.55s/it] 23%|██▎       | 2359/10365 [14:12:17<42:08:04, 18.95s/it] 23%|██▎       | 2360/10365 [14:12:34<41:17:41, 18.57s/it]                                                          {'loss': 1.0563, 'grad_norm': 0.94140625, 'learning_rate': 8.774535908630281e-05, 'epoch': 0.23}
 23%|██▎       | 2360/10365 [14:12:34<41:17:41, 18.57s/it] 23%|██▎       | 2361/10365 [14:12:57<44:15:54, 19.91s/it] 23%|██▎       | 2362/10365 [14:13:15<42:30:33, 19.12s/it] 23%|██▎       | 2363/10365 [14:13:32<41:30:15, 18.67s/it] 23%|██▎       | 2364/10365 [14:13:56<45:13:41, 20.35s/it] 23%|██▎       | 2365/10365 [14:14:20<47:24:56, 21.34s/it] 23%|██▎       | 2366/10365 [14:14:42<47:50:44, 21.53s/it] 23%|██▎       | 2367/10365 [14:15:02<46:31:29, 20.94s/it] 23%|██▎       | 2368/10365 [14:15:25<48:02:35, 21.63s/it] 23%|██▎       | 2369/10365 [14:15:45<46:50:52, 21.09s/it] 23%|██▎       | 2370/10365 [14:16:07<47:36:08, 21.43s/it]                                                          {'loss': 1.0658, 'grad_norm': 1.0625, 'learning_rate': 8.764579484121177e-05, 'epoch': 0.23}
 23%|██▎       | 2370/10365 [14:16:07<47:36:08, 21.43s/it] 23%|██▎       | 2371/10365 [14:16:29<48:04:15, 21.65s/it] 23%|██▎       | 2372/10365 [14:16:49<46:55:41, 21.14s/it] 23%|██▎       | 2373/10365 [14:17:08<45:26:42, 20.47s/it] 23%|██▎       | 2374/10365 [14:17:25<42:58:19, 19.36s/it] 23%|██▎       | 2375/10365 [14:17:47<44:53:14, 20.22s/it] 23%|██▎       | 2376/10365 [14:18:07<45:06:55, 20.33s/it] 23%|██▎       | 2377/10365 [14:18:27<44:46:23, 20.18s/it] 23%|██▎       | 2378/10365 [14:18:47<44:26:11, 20.03s/it] 23%|██▎       | 2379/10365 [14:19:07<44:18:36, 19.97s/it] 23%|██▎       | 2380/10365 [14:19:23<41:37:02, 18.76s/it]                                                          {'loss': 1.1059, 'grad_norm': 0.99609375, 'learning_rate': 8.754588474781597e-05, 'epoch': 0.23}
 23%|██▎       | 2380/10365 [14:19:23<41:37:02, 18.76s/it] 23%|██▎       | 2381/10365 [14:19:45<44:03:18, 19.86s/it] 23%|██▎       | 2382/10365 [14:20:09<46:23:02, 20.92s/it] 23%|██▎       | 2383/10365 [14:20:31<47:40:20, 21.50s/it] 23%|██▎       | 2384/10365 [14:20:54<48:04:20, 21.68s/it] 23%|██▎       | 2385/10365 [14:21:19<50:40:36, 22.86s/it] 23%|██▎       | 2386/10365 [14:21:49<54:58:18, 24.80s/it] 23%|██▎       | 2387/10365 [14:22:05<49:27:55, 22.32s/it] 23%|██▎       | 2388/10365 [14:22:29<50:33:16, 22.82s/it] 23%|██▎       | 2389/10365 [14:22:50<49:11:07, 22.20s/it] 23%|██▎       | 2390/10365 [14:23:11<48:42:03, 21.98s/it]                                                          {'loss': 1.1166, 'grad_norm': 1.015625, 'learning_rate': 8.744562972397987e-05, 'epoch': 0.23}
 23%|██▎       | 2390/10365 [14:23:11<48:42:03, 21.98s/it] 23%|██▎       | 2391/10365 [14:23:29<45:58:24, 20.76s/it] 23%|██▎       | 2392/10365 [14:23:50<45:43:44, 20.65s/it] 23%|██▎       | 2393/10365 [14:24:11<46:32:40, 21.02s/it] 23%|██▎       | 2394/10365 [14:24:32<46:06:11, 20.82s/it] 23%|██▎       | 2395/10365 [14:24:55<47:39:31, 21.53s/it] 23%|██▎       | 2396/10365 [14:25:18<48:47:30, 22.04s/it] 23%|██▎       | 2397/10365 [14:25:38<47:11:01, 21.32s/it] 23%|██▎       | 2398/10365 [14:26:05<51:13:24, 23.15s/it] 23%|██▎       | 2399/10365 [14:26:26<49:51:20, 22.53s/it] 23%|██▎       | 2400/10365 [14:26:47<48:26:17, 21.89s/it]                                                          {'loss': 1.0703, 'grad_norm': 1.15625, 'learning_rate': 8.734503069073673e-05, 'epoch': 0.23}
 23%|██▎       | 2400/10365 [14:26:47<48:26:17, 21.89s/it] 23%|██▎       | 2401/10365 [14:27:04<45:19:40, 20.49s/it] 23%|██▎       | 2402/10365 [14:27:23<44:41:22, 20.20s/it] 23%|██▎       | 2403/10365 [14:27:44<44:53:30, 20.30s/it] 23%|██▎       | 2404/10365 [14:28:03<43:50:17, 19.82s/it] 23%|██▎       | 2405/10365 [14:28:24<44:35:33, 20.17s/it] 23%|██▎       | 2406/10365 [14:28:45<45:24:46, 20.54s/it] 23%|██▎       | 2407/10365 [14:29:03<43:28:01, 19.66s/it] 23%|██▎       | 2408/10365 [14:29:25<45:00:27, 20.36s/it] 23%|██▎       | 2409/10365 [14:29:48<47:00:36, 21.27s/it] 23%|██▎       | 2410/10365 [14:30:09<46:58:14, 21.26s/it]                                                          {'loss': 1.0913, 'grad_norm': 1.0625, 'learning_rate': 8.724408857228024e-05, 'epoch': 0.23}
 23%|██▎       | 2410/10365 [14:30:09<46:58:14, 21.26s/it] 23%|██▎       | 2411/10365 [14:30:28<44:59:38, 20.36s/it] 23%|██▎       | 2412/10365 [14:30:45<43:12:09, 19.56s/it] 23%|██▎       | 2413/10365 [14:31:07<44:45:07, 20.26s/it] 23%|██▎       | 2414/10365 [14:31:24<42:11:21, 19.10s/it] 23%|██▎       | 2415/10365 [14:31:49<46:21:51, 21.00s/it] 23%|██▎       | 2416/10365 [14:32:12<47:49:55, 21.66s/it] 23%|██▎       | 2417/10365 [14:32:32<46:37:19, 21.12s/it] 23%|██▎       | 2418/10365 [14:32:51<45:25:02, 20.57s/it] 23%|██▎       | 2419/10365 [14:33:11<45:03:26, 20.41s/it] 23%|██▎       | 2420/10365 [14:33:32<45:21:22, 20.55s/it]                                                          {'loss': 1.0886, 'grad_norm': 0.95703125, 'learning_rate': 8.714280429595595e-05, 'epoch': 0.23}
 23%|██▎       | 2420/10365 [14:33:32<45:21:22, 20.55s/it] 23%|██▎       | 2421/10365 [14:33:51<44:21:17, 20.10s/it] 23%|██▎       | 2422/10365 [14:34:13<45:31:21, 20.63s/it] 23%|██▎       | 2423/10365 [14:34:35<46:09:26, 20.92s/it] 23%|██▎       | 2424/10365 [14:34:57<47:15:46, 21.43s/it] 23%|██▎       | 2425/10365 [14:35:20<48:10:20, 21.84s/it] 23%|██▎       | 2426/10365 [14:35:43<48:32:19, 22.01s/it] 23%|██▎       | 2427/10365 [14:36:01<46:03:09, 20.89s/it] 23%|██▎       | 2428/10365 [14:36:19<44:31:54, 20.20s/it] 23%|██▎       | 2429/10365 [14:36:41<45:19:35, 20.56s/it] 23%|██▎       | 2430/10365 [14:37:03<46:11:08, 20.95s/it]                                                          {'loss': 1.0618, 'grad_norm': 0.9453125, 'learning_rate': 8.704117879225278e-05, 'epoch': 0.23}
 23%|██▎       | 2430/10365 [14:37:03<46:11:08, 20.95s/it] 23%|██▎       | 2431/10365 [14:37:25<46:47:59, 21.24s/it] 23%|██▎       | 2432/10365 [14:37:47<47:17:04, 21.46s/it] 23%|██▎       | 2433/10365 [14:38:22<56:28:12, 25.63s/it] 23%|██▎       | 2434/10365 [14:38:46<55:34:06, 25.22s/it] 23%|██▎       | 2435/10365 [14:39:06<52:04:33, 23.64s/it] 24%|██▎       | 2436/10365 [14:39:32<53:30:06, 24.29s/it] 24%|██▎       | 2437/10365 [14:39:50<49:19:18, 22.40s/it] 24%|██▎       | 2438/10365 [14:40:12<48:53:34, 22.20s/it] 24%|██▎       | 2439/10365 [14:40:31<46:39:12, 21.19s/it] 24%|██▎       | 2440/10365 [14:40:57<50:12:11, 22.81s/it]                                                          {'loss': 1.0616, 'grad_norm': 1.0234375, 'learning_rate': 8.693921299479448e-05, 'epoch': 0.24}
 24%|██▎       | 2440/10365 [14:40:57<50:12:11, 22.81s/it] 24%|██▎       | 2441/10365 [14:41:21<50:57:22, 23.15s/it] 24%|██▎       | 2442/10365 [14:41:45<51:38:46, 23.47s/it] 24%|██▎       | 2443/10365 [14:42:09<52:02:34, 23.65s/it] 24%|██▎       | 2444/10365 [14:42:27<48:09:30, 21.89s/it] 24%|██▎       | 2445/10365 [14:42:51<49:31:22, 22.51s/it] 24%|██▎       | 2446/10365 [14:43:11<47:42:48, 21.69s/it] 24%|██▎       | 2447/10365 [14:43:33<47:57:27, 21.80s/it] 24%|██▎       | 2448/10365 [14:43:57<49:21:47, 22.45s/it] 24%|██▎       | 2449/10365 [14:44:16<46:50:52, 21.31s/it] 24%|██▎       | 2450/10365 [14:44:38<47:51:43, 21.77s/it]                                                          {'loss': 1.07, 'grad_norm': 1.015625, 'learning_rate': 8.683690784033106e-05, 'epoch': 0.24}
 24%|██▎       | 2450/10365 [14:44:38<47:51:43, 21.77s/it] 24%|██▎       | 2451/10365 [14:45:02<49:17:56, 22.43s/it] 24%|██▎       | 2452/10365 [14:45:19<45:20:50, 20.63s/it] 24%|██▎       | 2453/10365 [14:45:41<46:23:53, 21.11s/it] 24%|██▎       | 2454/10365 [14:46:01<45:39:56, 20.78s/it] 24%|██▎       | 2455/10365 [14:46:20<44:11:07, 20.11s/it] 24%|██▎       | 2456/10365 [14:46:38<43:07:49, 19.63s/it] 24%|██▎       | 2457/10365 [14:46:57<42:36:32, 19.40s/it] 24%|██▎       | 2458/10365 [14:47:22<46:16:47, 21.07s/it] 24%|██▎       | 2459/10365 [14:47:43<46:01:38, 20.96s/it] 24%|██▎       | 2460/10365 [14:47:59<43:12:47, 19.68s/it]                                                          {'loss': 1.0654, 'grad_norm': 0.9296875, 'learning_rate': 8.673426426873015e-05, 'epoch': 0.24}
 24%|██▎       | 2460/10365 [14:47:59<43:12:47, 19.68s/it] 24%|██▎       | 2461/10365 [14:48:18<42:34:02, 19.39s/it] 24%|██▍       | 2462/10365 [14:48:39<43:21:45, 19.75s/it] 24%|██▍       | 2463/10365 [14:48:58<43:11:49, 19.68s/it] 24%|██▍       | 2464/10365 [14:49:21<45:15:04, 20.62s/it] 24%|██▍       | 2465/10365 [14:49:43<46:07:59, 21.02s/it] 24%|██▍       | 2466/10365 [14:50:05<46:47:39, 21.33s/it] 24%|██▍       | 2467/10365 [14:50:26<46:17:17, 21.10s/it] 24%|██▍       | 2468/10365 [14:50:46<46:01:54, 20.98s/it] 24%|██▍       | 2469/10365 [14:51:09<47:16:34, 21.55s/it] 24%|██▍       | 2470/10365 [14:51:39<52:53:38, 24.12s/it]                                                          {'loss': 1.1098, 'grad_norm': 1.15625, 'learning_rate': 8.663128322296838e-05, 'epoch': 0.24}
 24%|██▍       | 2470/10365 [14:51:39<52:53:38, 24.12s/it] 24%|██▍       | 2471/10365 [14:51:57<48:40:40, 22.20s/it] 24%|██▍       | 2472/10365 [14:52:18<48:04:11, 21.92s/it] 24%|██▍       | 2473/10365 [14:52:41<48:56:15, 22.32s/it] 24%|██▍       | 2474/10365 [14:53:03<48:31:06, 22.13s/it] 24%|██▍       | 2475/10365 [14:53:26<48:47:26, 22.26s/it] 24%|██▍       | 2476/10365 [14:53:44<46:21:15, 21.15s/it] 24%|██▍       | 2477/10365 [14:54:06<46:24:12, 21.18s/it] 24%|██▍       | 2478/10365 [14:54:25<45:25:04, 20.73s/it] 24%|██▍       | 2479/10365 [14:54:45<44:47:42, 20.45s/it] 24%|██▍       | 2480/10365 [14:55:07<45:53:13, 20.95s/it]                                                          {'loss': 1.0786, 'grad_norm': 1.1015625, 'learning_rate': 8.652796564912275e-05, 'epoch': 0.24}
 24%|██▍       | 2480/10365 [14:55:07<45:53:13, 20.95s/it] 24%|██▍       | 2481/10365 [14:55:28<46:02:35, 21.02s/it] 24%|██▍       | 2482/10365 [14:55:51<46:53:09, 21.41s/it] 24%|██▍       | 2483/10365 [14:56:13<47:48:17, 21.83s/it] 24%|██▍       | 2484/10365 [14:56:37<48:39:52, 22.23s/it] 24%|██▍       | 2485/10365 [14:57:00<49:27:09, 22.59s/it] 24%|██▍       | 2486/10365 [14:57:27<52:24:01, 23.94s/it] 24%|██▍       | 2487/10365 [14:57:48<50:27:46, 23.06s/it] 24%|██▍       | 2488/10365 [14:58:09<49:17:36, 22.53s/it] 24%|██▍       | 2489/10365 [14:58:30<47:44:34, 21.82s/it] 24%|██▍       | 2490/10365 [14:58:53<48:57:47, 22.38s/it]                                                          {'loss': 1.1037, 'grad_norm': 1.1015625, 'learning_rate': 8.642431249636191e-05, 'epoch': 0.24}
 24%|██▍       | 2490/10365 [14:58:53<48:57:47, 22.38s/it] 24%|██▍       | 2491/10365 [14:59:12<46:38:46, 21.33s/it] 24%|██▍       | 2492/10365 [14:59:40<51:09:17, 23.39s/it] 24%|██▍       | 2493/10365 [14:59:59<47:44:06, 21.83s/it] 24%|██▍       | 2494/10365 [15:00:19<46:45:04, 21.38s/it] 24%|██▍       | 2495/10365 [15:00:43<48:24:23, 22.14s/it] 24%|██▍       | 2496/10365 [15:01:04<48:03:55, 21.99s/it] 24%|██▍       | 2497/10365 [15:01:26<47:55:59, 21.93s/it] 24%|██▍       | 2498/10365 [15:01:48<47:58:54, 21.96s/it] 24%|██▍       | 2499/10365 [15:02:10<48:03:44, 22.00s/it] 24%|██▍       | 2500/10365 [15:02:31<46:52:13, 21.45s/it]                                                          {'loss': 1.0718, 'grad_norm': 1.0, 'learning_rate': 8.632032471693741e-05, 'epoch': 0.24}
 24%|██▍       | 2500/10365 [15:02:31<46:52:13, 21.45s/it][INFO|trainer.py:3719] 2024-05-31 01:56:56,432 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-31 01:56:56,432 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-31 01:56:56,432 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:47,  1.77s/it][A
  5%|▍         | 3/63 [00:08<03:16,  3.27s/it][A
  6%|▋         | 4/63 [00:13<03:47,  3.86s/it][A
  8%|▊         | 5/63 [00:18<04:06,  4.26s/it][A
 10%|▉         | 6/63 [00:23<04:11,  4.41s/it][A
 11%|█         | 7/63 [00:28<04:16,  4.58s/it][A
 13%|█▎        | 8/63 [00:33<04:14,  4.62s/it][A
 14%|█▍        | 9/63 [00:38<04:16,  4.76s/it][A
 16%|█▌        | 10/63 [00:43<04:25,  5.01s/it][A
 17%|█▋        | 11/63 [00:49<04:34,  5.28s/it][A
 19%|█▉        | 12/63 [00:54<04:20,  5.11s/it][A
 21%|██        | 13/63 [00:59<04:15,  5.11s/it][A
 22%|██▏       | 14/63 [01:04<04:02,  4.95s/it][A
 24%|██▍       | 15/63 [01:09<04:00,  5.00s/it][A
 25%|██▌       | 16/63 [01:14<03:54,  4.99s/it][A
 27%|██▋       | 17/63 [01:19<03:50,  5.02s/it][A
 29%|██▊       | 18/63 [01:24<03:51,  5.14s/it][A
 30%|███       | 19/63 [01:30<03:52,  5.28s/it][A
 32%|███▏      | 20/63 [01:35<03:51,  5.38s/it][A
 33%|███▎      | 21/63 [01:40<03:34,  5.11s/it][A
 35%|███▍      | 22/63 [01:46<03:44,  5.47s/it][A
 37%|███▋      | 23/63 [01:50<03:17,  4.93s/it][A
 38%|███▊      | 24/63 [01:55<03:20,  5.14s/it][A
 40%|███▉      | 25/63 [02:01<03:21,  5.30s/it][A
 41%|████▏     | 26/63 [02:06<03:11,  5.17s/it][A
 43%|████▎     | 27/63 [02:12<03:11,  5.33s/it][A
 44%|████▍     | 28/63 [02:18<03:13,  5.54s/it][A
 46%|████▌     | 29/63 [02:25<03:27,  6.12s/it][A
 48%|████▊     | 30/63 [02:30<03:04,  5.60s/it][A
 49%|████▉     | 31/63 [02:35<02:54,  5.44s/it][A
 51%|█████     | 32/63 [02:39<02:35,  5.03s/it][A
 52%|█████▏    | 33/63 [02:45<02:38,  5.29s/it][A
 54%|█████▍    | 34/63 [02:48<02:18,  4.78s/it][A
 56%|█████▌    | 35/63 [02:53<02:13,  4.77s/it][A
 57%|█████▋    | 36/63 [02:57<02:04,  4.61s/it][A
 59%|█████▊    | 37/63 [03:04<02:15,  5.19s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.30s/it][A
 62%|██████▏   | 39/63 [03:14<02:01,  5.07s/it][A
 63%|██████▎   | 40/63 [03:19<01:57,  5.10s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.15s/it][A
 67%|██████▋   | 42/63 [03:31<01:59,  5.68s/it][A
 68%|██████▊   | 43/63 [03:37<01:53,  5.67s/it][A
 70%|██████▉   | 44/63 [03:42<01:42,  5.39s/it][A
 71%|███████▏  | 45/63 [03:49<01:45,  5.86s/it][A
 73%|███████▎  | 46/63 [03:54<01:38,  5.81s/it][A
 75%|███████▍  | 47/63 [04:00<01:32,  5.78s/it][A
 76%|███████▌  | 48/63 [04:07<01:31,  6.11s/it][A
 78%|███████▊  | 49/63 [04:11<01:18,  5.64s/it][A
 79%|███████▉  | 50/63 [04:18<01:16,  5.90s/it][A
 81%|████████  | 51/63 [04:23<01:09,  5.79s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.13s/it][A
 84%|████████▍ | 53/63 [04:36<00:59,  5.92s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.81s/it][A
 87%|████████▋ | 55/63 [04:46<00:42,  5.37s/it][A
 89%|████████▉ | 56/63 [04:51<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.30s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.20s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.15s/it][A
 95%|█████████▌| 60/63 [05:10<00:14,  4.88s/it][A
 97%|█████████▋| 61/63 [05:17<00:10,  5.40s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.66s/it][A
100%|██████████| 63/63 [05:29<00:00,  5.82s/it][A                                                          
                                               [A{'eval_loss': 1.0940170288085938, 'eval_runtime': 336.32, 'eval_samples_per_second': 14.867, 'eval_steps_per_second': 0.187, 'epoch': 0.24}
 24%|██▍       | 2500/10365 [15:08:07<46:52:13, 21.45s/it]
100%|██████████| 63/63 [05:29<00:00,  5.82s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-31 02:02:35,054 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-2500
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-31 02:02:35,101 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-31 02:02:35,101 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-2500/special_tokens_map.json
 24%|██▍       | 2501/10365 [15:08:32<269:41:30, 123.46s/it] 24%|██▍       | 2502/10365 [15:08:58<205:37:45, 94.15s/it]  24%|██▍       | 2503/10365 [15:09:21<159:15:57, 72.93s/it] 24%|██▍       | 2504/10365 [15:09:46<127:54:33, 58.58s/it] 24%|██▍       | 2505/10365 [15:10:06<102:37:23, 47.00s/it] 24%|██▍       | 2506/10365 [15:10:25<83:50:25, 38.41s/it]  24%|██▍       | 2507/10365 [15:10:50<75:05:16, 34.40s/it] 24%|██▍       | 2508/10365 [15:11:09<65:03:32, 29.81s/it] 24%|██▍       | 2509/10365 [15:11:30<59:09:56, 27.11s/it] 24%|██▍       | 2510/10365 [15:11:50<54:45:31, 25.10s/it]                                                          {'loss': 1.0633, 'grad_norm': 0.9453125, 'learning_rate': 8.621600326617498e-05, 'epoch': 0.24}
 24%|██▍       | 2510/10365 [15:11:50<54:45:31, 25.10s/it] 24%|██▍       | 2511/10365 [15:12:10<51:42:01, 23.70s/it] 24%|██▍       | 2512/10365 [15:12:33<50:59:30, 23.38s/it] 24%|██▍       | 2513/10365 [15:12:56<50:30:52, 23.16s/it] 24%|██▍       | 2514/10365 [15:13:17<49:20:53, 22.63s/it] 24%|██▍       | 2515/10365 [15:13:38<48:02:37, 22.03s/it] 24%|██▍       | 2516/10365 [15:14:04<50:41:47, 23.25s/it] 24%|██▍       | 2517/10365 [15:14:21<46:54:25, 21.52s/it] 24%|██▍       | 2518/10365 [15:14:43<46:59:38, 21.56s/it] 24%|██▍       | 2519/10365 [15:15:10<50:49:13, 23.32s/it] 24%|██▍       | 2520/10365 [15:15:29<47:36:15, 21.85s/it]                                                          {'loss': 1.0486, 'grad_norm': 1.046875, 'learning_rate': 8.611134910246581e-05, 'epoch': 0.24}
 24%|██▍       | 2520/10365 [15:15:29<47:36:15, 21.85s/it] 24%|██▍       | 2521/10365 [15:15:47<45:32:31, 20.90s/it] 24%|██▍       | 2522/10365 [15:16:08<45:34:54, 20.92s/it] 24%|██▍       | 2523/10365 [15:16:27<44:07:55, 20.26s/it] 24%|██▍       | 2524/10365 [15:16:51<46:30:14, 21.35s/it] 24%|██▍       | 2525/10365 [15:17:13<46:36:12, 21.40s/it] 24%|██▍       | 2526/10365 [15:17:33<45:49:55, 21.05s/it] 24%|██▍       | 2527/10365 [15:17:54<45:48:30, 21.04s/it] 24%|██▍       | 2528/10365 [15:18:15<46:11:55, 21.22s/it] 24%|██▍       | 2529/10365 [15:18:36<45:52:44, 21.08s/it] 24%|██▍       | 2530/10365 [15:19:05<50:35:24, 23.24s/it]                                                          {'loss': 1.0644, 'grad_norm': 0.94140625, 'learning_rate': 8.600636318725766e-05, 'epoch': 0.24}
 24%|██▍       | 2530/10365 [15:19:05<50:35:24, 23.24s/it] 24%|██▍       | 2531/10365 [15:19:27<50:08:41, 23.04s/it] 24%|██▍       | 2532/10365 [15:19:50<49:57:10, 22.96s/it] 24%|██▍       | 2533/10365 [15:20:13<50:00:47, 22.99s/it] 24%|██▍       | 2534/10365 [15:20:35<49:25:49, 22.72s/it] 24%|██▍       | 2535/10365 [15:20:58<49:16:13, 22.65s/it] 24%|██▍       | 2536/10365 [15:21:23<50:51:25, 23.39s/it] 24%|██▍       | 2537/10365 [15:21:39<46:09:02, 21.22s/it] 24%|██▍       | 2538/10365 [15:21:59<45:34:03, 20.96s/it] 24%|██▍       | 2539/10365 [15:22:21<46:10:15, 21.24s/it] 25%|██▍       | 2540/10365 [15:22:44<47:03:07, 21.65s/it]                                                          {'loss': 1.1037, 'grad_norm': 0.984375, 'learning_rate': 8.590104648504603e-05, 'epoch': 0.25}
 25%|██▍       | 2540/10365 [15:22:44<47:03:07, 21.65s/it] 25%|██▍       | 2541/10365 [15:23:10<50:19:58, 23.16s/it] 25%|██▍       | 2542/10365 [15:23:39<53:45:19, 24.74s/it] 25%|██▍       | 2543/10365 [15:24:01<52:16:30, 24.06s/it] 25%|██▍       | 2544/10365 [15:24:18<47:24:26, 21.82s/it] 25%|██▍       | 2545/10365 [15:24:37<45:28:33, 20.94s/it] 25%|██▍       | 2546/10365 [15:24:58<45:50:00, 21.10s/it] 25%|██▍       | 2547/10365 [15:25:19<45:41:22, 21.04s/it] 25%|██▍       | 2548/10365 [15:25:38<44:09:27, 20.34s/it] 25%|██▍       | 2549/10365 [15:26:00<45:38:23, 21.02s/it] 25%|██▍       | 2550/10365 [15:26:22<45:44:53, 21.07s/it]                                                          {'loss': 1.0981, 'grad_norm': 1.0546875, 'learning_rate': 8.579539996336538e-05, 'epoch': 0.25}
 25%|██▍       | 2550/10365 [15:26:22<45:44:53, 21.07s/it] 25%|██▍       | 2551/10365 [15:26:45<47:17:08, 21.79s/it] 25%|██▍       | 2552/10365 [15:27:05<46:04:37, 21.23s/it] 25%|██▍       | 2553/10365 [15:27:26<45:40:09, 21.05s/it] 25%|██▍       | 2554/10365 [15:27:46<45:14:50, 20.85s/it] 25%|██▍       | 2555/10365 [15:28:11<47:45:29, 22.01s/it] 25%|██▍       | 2556/10365 [15:28:39<51:37:21, 23.80s/it] 25%|██▍       | 2557/10365 [15:29:01<50:22:50, 23.23s/it] 25%|██▍       | 2558/10365 [15:29:18<46:50:52, 21.60s/it] 25%|██▍       | 2559/10365 [15:29:39<46:14:33, 21.33s/it] 25%|██▍       | 2560/10365 [15:30:05<49:02:14, 22.62s/it]                                                          {'loss': 1.0817, 'grad_norm': 0.984375, 'learning_rate': 8.568942459278016e-05, 'epoch': 0.25}
 25%|██▍       | 2560/10365 [15:30:05<49:02:14, 22.62s/it] 25%|██▍       | 2561/10365 [15:30:21<44:39:29, 20.60s/it] 25%|██▍       | 2562/10365 [15:30:39<43:29:01, 20.06s/it] 25%|██▍       | 2563/10365 [15:30:57<42:09:55, 19.46s/it] 25%|██▍       | 2564/10365 [15:31:26<48:20:57, 22.31s/it] 25%|██▍       | 2565/10365 [15:31:51<49:46:50, 22.98s/it] 25%|██▍       | 2566/10365 [15:32:12<48:49:33, 22.54s/it] 25%|██▍       | 2567/10365 [15:32:30<45:27:01, 20.98s/it] 25%|██▍       | 2568/10365 [15:32:50<44:51:28, 20.71s/it] 25%|██▍       | 2569/10365 [15:33:12<45:36:57, 21.06s/it] 25%|██▍       | 2570/10365 [15:33:33<45:41:36, 21.10s/it]                                                          {'loss': 1.0874, 'grad_norm': 1.0078125, 'learning_rate': 8.558312134687594e-05, 'epoch': 0.25}
 25%|██▍       | 2570/10365 [15:33:33<45:41:36, 21.10s/it] 25%|██▍       | 2571/10365 [15:33:54<45:32:45, 21.04s/it] 25%|██▍       | 2572/10365 [15:34:17<46:41:15, 21.57s/it] 25%|██▍       | 2573/10365 [15:34:40<47:38:05, 22.01s/it] 25%|██▍       | 2574/10365 [15:35:01<47:22:15, 21.89s/it] 25%|██▍       | 2575/10365 [15:35:22<46:52:56, 21.67s/it] 25%|██▍       | 2576/10365 [15:35:44<46:43:18, 21.59s/it] 25%|██▍       | 2577/10365 [15:36:00<43:00:31, 19.88s/it] 25%|██▍       | 2578/10365 [15:36:19<42:27:30, 19.63s/it] 25%|██▍       | 2579/10365 [15:36:45<46:38:36, 21.57s/it] 25%|██▍       | 2580/10365 [15:37:05<45:33:39, 21.07s/it]                                                          {'loss': 1.0498, 'grad_norm': 1.1328125, 'learning_rate': 8.547649120225043e-05, 'epoch': 0.25}
 25%|██▍       | 2580/10365 [15:37:05<45:33:39, 21.07s/it] 25%|██▍       | 2581/10365 [15:37:28<46:51:17, 21.67s/it] 25%|██▍       | 2582/10365 [15:37:51<47:58:56, 22.19s/it] 25%|██▍       | 2583/10365 [15:38:07<44:07:02, 20.41s/it] 25%|██▍       | 2584/10365 [15:38:26<42:53:11, 19.84s/it] 25%|██▍       | 2585/10365 [15:38:44<41:55:01, 19.40s/it] 25%|██▍       | 2586/10365 [15:39:02<40:51:33, 18.91s/it] 25%|██▍       | 2587/10365 [15:39:25<43:21:26, 20.07s/it] 25%|██▍       | 2588/10365 [15:39:45<43:11:43, 20.00s/it] 25%|██▍       | 2589/10365 [15:40:06<44:00:21, 20.37s/it] 25%|██▍       | 2590/10365 [15:40:23<42:06:54, 19.50s/it]                                                          {'loss': 1.0946, 'grad_norm': 0.95703125, 'learning_rate': 8.536953513850454e-05, 'epoch': 0.25}
 25%|██▍       | 2590/10365 [15:40:23<42:06:54, 19.50s/it] 25%|██▍       | 2591/10365 [15:40:38<38:41:37, 17.92s/it] 25%|██▌       | 2592/10365 [15:40:55<38:24:58, 17.79s/it] 25%|██▌       | 2593/10365 [15:41:16<40:31:38, 18.77s/it] 25%|██▌       | 2594/10365 [15:41:36<41:19:12, 19.14s/it] 25%|██▌       | 2595/10365 [15:41:55<41:00:19, 19.00s/it] 25%|██▌       | 2596/10365 [15:42:16<42:13:38, 19.57s/it] 25%|██▌       | 2597/10365 [15:42:38<44:07:16, 20.45s/it] 25%|██▌       | 2598/10365 [15:42:59<44:31:08, 20.63s/it] 25%|██▌       | 2599/10365 [15:43:17<42:23:57, 19.65s/it] 25%|██▌       | 2600/10365 [15:43:36<42:12:44, 19.57s/it]                                                          {'loss': 1.0866, 'grad_norm': 1.125, 'learning_rate': 8.526225413823335e-05, 'epoch': 0.25}
 25%|██▌       | 2600/10365 [15:43:36<42:12:44, 19.57s/it] 25%|██▌       | 2601/10365 [15:43:57<43:19:11, 20.09s/it] 25%|██▌       | 2602/10365 [15:44:13<40:25:23, 18.75s/it] 25%|██▌       | 2603/10365 [15:44:32<40:48:59, 18.93s/it] 25%|██▌       | 2604/10365 [15:44:54<42:15:10, 19.60s/it] 25%|██▌       | 2605/10365 [15:45:16<43:53:45, 20.36s/it] 25%|██▌       | 2606/10365 [15:45:40<46:33:04, 21.60s/it] 25%|██▌       | 2607/10365 [15:46:00<45:41:15, 21.20s/it] 25%|██▌       | 2608/10365 [15:46:20<44:44:34, 20.77s/it] 25%|██▌       | 2609/10365 [15:46:39<43:40:46, 20.27s/it] 25%|██▌       | 2610/10365 [15:46:59<43:11:10, 20.05s/it]                                                          {'loss': 1.0964, 'grad_norm': 0.94921875, 'learning_rate': 8.515464918701715e-05, 'epoch': 0.25}
 25%|██▌       | 2610/10365 [15:46:59<43:11:10, 20.05s/it] 25%|██▌       | 2611/10365 [15:47:17<41:49:08, 19.42s/it] 25%|██▌       | 2612/10365 [15:47:40<44:08:30, 20.50s/it] 25%|██▌       | 2613/10365 [15:48:01<44:43:24, 20.77s/it] 25%|██▌       | 2614/10365 [15:48:25<46:20:54, 21.53s/it] 25%|██▌       | 2615/10365 [15:48:46<46:00:17, 21.37s/it] 25%|██▌       | 2616/10365 [15:49:09<47:05:28, 21.88s/it] 25%|██▌       | 2617/10365 [15:49:33<48:37:20, 22.59s/it] 25%|██▌       | 2618/10365 [15:49:56<49:04:04, 22.80s/it] 25%|██▌       | 2619/10365 [15:50:17<47:48:01, 22.22s/it] 25%|██▌       | 2620/10365 [15:50:39<47:30:06, 22.08s/it]                                                          {'loss': 1.0984, 'grad_norm': 0.9453125, 'learning_rate': 8.504672127341224e-05, 'epoch': 0.25}
 25%|██▌       | 2620/10365 [15:50:39<47:30:06, 22.08s/it] 25%|██▌       | 2621/10365 [15:51:00<46:50:41, 21.78s/it] 25%|██▌       | 2622/10365 [15:51:20<45:54:49, 21.35s/it] 25%|██▌       | 2623/10365 [15:51:43<47:01:36, 21.87s/it] 25%|██▌       | 2624/10365 [15:52:03<45:41:15, 21.25s/it] 25%|██▌       | 2625/10365 [15:52:22<43:58:13, 20.45s/it] 25%|██▌       | 2626/10365 [15:52:40<42:48:09, 19.91s/it] 25%|██▌       | 2627/10365 [15:52:59<41:57:59, 19.52s/it] 25%|██▌       | 2628/10365 [15:53:22<44:30:05, 20.71s/it] 25%|██▌       | 2629/10365 [15:53:42<43:56:57, 20.45s/it] 25%|██▌       | 2630/10365 [15:54:04<45:01:11, 20.95s/it]                                                          {'loss': 1.0602, 'grad_norm': 1.0234375, 'learning_rate': 8.493847138894209e-05, 'epoch': 0.25}
 25%|██▌       | 2630/10365 [15:54:04<45:01:11, 20.95s/it] 25%|██▌       | 2631/10365 [15:54:27<46:20:43, 21.57s/it] 25%|██▌       | 2632/10365 [15:54:47<45:12:03, 21.04s/it] 25%|██▌       | 2633/10365 [15:55:10<46:34:52, 21.69s/it] 25%|██▌       | 2634/10365 [15:55:30<45:19:56, 21.11s/it] 25%|██▌       | 2635/10365 [15:55:53<46:20:00, 21.58s/it] 25%|██▌       | 2636/10365 [15:56:15<46:56:00, 21.86s/it] 25%|██▌       | 2637/10365 [15:56:36<46:13:35, 21.53s/it] 25%|██▌       | 2638/10365 [15:56:55<44:31:27, 20.74s/it] 25%|██▌       | 2639/10365 [15:57:13<43:02:36, 20.06s/it] 25%|██▌       | 2640/10365 [15:57:33<43:01:44, 20.05s/it]                                                          {'loss': 1.0424, 'grad_norm': 0.9453125, 'learning_rate': 8.482990052808793e-05, 'epoch': 0.25}
 25%|██▌       | 2640/10365 [15:57:33<43:01:44, 20.05s/it] 25%|██▌       | 2641/10365 [15:57:53<42:52:46, 19.99s/it] 25%|██▌       | 2642/10365 [15:58:20<47:05:06, 21.95s/it] 25%|██▌       | 2643/10365 [15:58:46<49:46:44, 23.21s/it] 26%|██▌       | 2644/10365 [15:59:08<49:17:28, 22.98s/it] 26%|██▌       | 2645/10365 [15:59:30<48:07:45, 22.44s/it] 26%|██▌       | 2646/10365 [15:59:50<46:40:15, 21.77s/it] 26%|██▌       | 2647/10365 [16:00:10<45:20:37, 21.15s/it] 26%|██▌       | 2648/10365 [16:00:30<45:11:42, 21.08s/it] 26%|██▌       | 2649/10365 [16:00:51<44:58:47, 20.99s/it] 26%|██▌       | 2650/10365 [16:01:08<42:24:55, 19.79s/it]                                                          {'loss': 1.0262, 'grad_norm': 0.9609375, 'learning_rate': 8.472100968827987e-05, 'epoch': 0.26}
 26%|██▌       | 2650/10365 [16:01:08<42:24:55, 19.79s/it] 26%|██▌       | 2651/10365 [16:01:31<44:11:21, 20.62s/it] 26%|██▌       | 2652/10365 [16:01:54<45:44:04, 21.35s/it] 26%|██▌       | 2653/10365 [16:02:20<48:32:51, 22.66s/it] 26%|██▌       | 2654/10365 [16:02:41<47:34:22, 22.21s/it] 26%|██▌       | 2655/10365 [16:02:59<45:08:28, 21.08s/it] 26%|██▌       | 2656/10365 [16:03:19<44:24:18, 20.74s/it] 26%|██▌       | 2657/10365 [16:03:44<47:20:13, 22.11s/it] 26%|██▌       | 2658/10365 [16:04:07<47:20:17, 22.11s/it] 26%|██▌       | 2659/10365 [16:04:31<48:35:01, 22.70s/it] 26%|██▌       | 2660/10365 [16:04:50<46:17:09, 21.63s/it]                                                          {'loss': 1.0573, 'grad_norm': 1.0703125, 'learning_rate': 8.46117998698876e-05, 'epoch': 0.26}
 26%|██▌       | 2660/10365 [16:04:50<46:17:09, 21.63s/it] 26%|██▌       | 2661/10365 [16:05:14<47:49:33, 22.35s/it] 26%|██▌       | 2662/10365 [16:05:37<48:30:22, 22.67s/it] 26%|██▌       | 2663/10365 [16:05:59<48:00:21, 22.44s/it] 26%|██▌       | 2664/10365 [16:06:25<50:00:17, 23.38s/it] 26%|██▌       | 2665/10365 [16:06:49<50:26:51, 23.59s/it] 26%|██▌       | 2666/10365 [16:07:11<49:18:21, 23.06s/it] 26%|██▌       | 2667/10365 [16:07:28<45:57:33, 21.49s/it] 26%|██▌       | 2668/10365 [16:07:49<45:39:08, 21.35s/it] 26%|██▌       | 2669/10365 [16:08:09<44:43:47, 20.92s/it] 26%|██▌       | 2670/10365 [16:08:30<44:53:37, 21.00s/it]                                                          {'loss': 1.0768, 'grad_norm': 0.96484375, 'learning_rate': 8.450227207621124e-05, 'epoch': 0.26}
 26%|██▌       | 2670/10365 [16:08:30<44:53:37, 21.00s/it] 26%|██▌       | 2671/10365 [16:08:59<49:27:29, 23.14s/it] 26%|██▌       | 2672/10365 [16:09:21<48:46:39, 22.83s/it] 26%|██▌       | 2673/10365 [16:09:41<47:02:47, 22.02s/it] 26%|██▌       | 2674/10365 [16:10:01<45:55:26, 21.50s/it] 26%|██▌       | 2675/10365 [16:10:21<44:55:46, 21.03s/it] 26%|██▌       | 2676/10365 [16:10:44<46:05:18, 21.58s/it] 26%|██▌       | 2677/10365 [16:11:00<42:48:56, 20.05s/it] 26%|██▌       | 2678/10365 [16:11:22<44:01:18, 20.62s/it] 26%|██▌       | 2679/10365 [16:11:45<45:06:41, 21.13s/it] 26%|██▌       | 2680/10365 [16:12:07<45:43:38, 21.42s/it]                                                          {'loss': 1.0467, 'grad_norm': 1.0703125, 'learning_rate': 8.439242731347214e-05, 'epoch': 0.26}
 26%|██▌       | 2680/10365 [16:12:07<45:43:38, 21.42s/it] 26%|██▌       | 2681/10365 [16:12:31<47:26:02, 22.22s/it] 26%|██▌       | 2682/10365 [16:12:51<45:53:22, 21.50s/it] 26%|██▌       | 2683/10365 [16:13:09<43:45:22, 20.51s/it] 26%|██▌       | 2684/10365 [16:13:29<43:33:28, 20.42s/it] 26%|██▌       | 2685/10365 [16:13:54<46:23:31, 21.75s/it] 26%|██▌       | 2686/10365 [16:14:13<44:59:47, 21.09s/it] 26%|██▌       | 2687/10365 [16:14:34<44:51:50, 21.04s/it] 26%|██▌       | 2688/10365 [16:14:56<44:55:02, 21.06s/it] 26%|██▌       | 2689/10365 [16:15:15<43:37:04, 20.46s/it] 26%|██▌       | 2690/10365 [16:15:41<47:14:10, 22.16s/it]                                                          {'loss': 1.0724, 'grad_norm': 0.8984375, 'learning_rate': 8.428226659080355e-05, 'epoch': 0.26}
 26%|██▌       | 2690/10365 [16:15:41<47:14:10, 22.16s/it] 26%|██▌       | 2691/10365 [16:16:05<48:33:29, 22.78s/it] 26%|██▌       | 2692/10365 [16:16:22<45:12:49, 21.21s/it] 26%|██▌       | 2693/10365 [16:16:39<42:17:30, 19.84s/it] 26%|██▌       | 2694/10365 [16:17:05<46:18:47, 21.73s/it] 26%|██▌       | 2695/10365 [16:17:24<44:32:13, 20.90s/it] 26%|██▌       | 2696/10365 [16:17:48<46:11:56, 21.69s/it] 26%|██▌       | 2697/10365 [16:18:08<45:02:51, 21.15s/it] 26%|██▌       | 2698/10365 [16:18:32<46:50:46, 22.00s/it] 26%|██▌       | 2699/10365 [16:18:52<45:53:30, 21.55s/it] 26%|██▌       | 2700/10365 [16:19:13<45:16:14, 21.26s/it]                                                          {'loss': 1.0645, 'grad_norm': 0.99609375, 'learning_rate': 8.417179092024151e-05, 'epoch': 0.26}
 26%|██▌       | 2700/10365 [16:19:13<45:16:14, 21.26s/it] 26%|██▌       | 2701/10365 [16:19:31<43:20:35, 20.36s/it] 26%|██▌       | 2702/10365 [16:19:56<46:04:59, 21.65s/it] 26%|██▌       | 2703/10365 [16:20:15<44:43:04, 21.01s/it] 26%|██▌       | 2704/10365 [16:20:37<45:29:43, 21.38s/it] 26%|██▌       | 2705/10365 [16:20:58<44:53:58, 21.10s/it] 26%|██▌       | 2706/10365 [16:21:24<47:57:49, 22.54s/it] 26%|██▌       | 2707/10365 [16:21:48<49:05:11, 23.08s/it] 26%|██▌       | 2708/10365 [16:22:08<47:05:34, 22.14s/it] 26%|██▌       | 2709/10365 [16:22:33<48:46:41, 22.94s/it] 26%|██▌       | 2710/10365 [16:22:50<45:08:00, 21.23s/it]                                                          {'loss': 1.0977, 'grad_norm': 0.94140625, 'learning_rate': 8.406100131671537e-05, 'epoch': 0.26}
 26%|██▌       | 2710/10365 [16:22:50<45:08:00, 21.23s/it] 26%|██▌       | 2711/10365 [16:23:13<45:55:56, 21.60s/it] 26%|██▌       | 2712/10365 [16:23:30<43:03:41, 20.26s/it] 26%|██▌       | 2713/10365 [16:23:52<44:41:55, 21.03s/it] 26%|██▌       | 2714/10365 [16:24:12<43:37:47, 20.53s/it] 26%|██▌       | 2715/10365 [16:24:32<43:26:21, 20.44s/it] 26%|██▌       | 2716/10365 [16:24:51<42:35:58, 20.05s/it] 26%|██▌       | 2717/10365 [16:25:11<42:16:08, 19.90s/it] 26%|██▌       | 2718/10365 [16:25:33<43:34:40, 20.52s/it] 26%|██▌       | 2719/10365 [16:25:58<46:45:47, 22.02s/it] 26%|██▌       | 2720/10365 [16:26:16<44:09:12, 20.79s/it]                                                          {'loss': 1.0694, 'grad_norm': 1.0, 'learning_rate': 8.39498987980386e-05, 'epoch': 0.26}
 26%|██▌       | 2720/10365 [16:26:16<44:09:12, 20.79s/it] 26%|██▋       | 2721/10365 [16:26:37<44:10:11, 20.80s/it] 26%|██▋       | 2722/10365 [16:26:56<43:04:20, 20.29s/it] 26%|██▋       | 2723/10365 [16:27:17<43:39:40, 20.57s/it] 26%|██▋       | 2724/10365 [16:27:47<49:22:28, 23.26s/it] 26%|██▋       | 2725/10365 [16:28:11<49:38:24, 23.39s/it] 26%|██▋       | 2726/10365 [16:28:31<47:34:18, 22.42s/it] 26%|██▋       | 2727/10365 [16:28:52<47:03:39, 22.18s/it] 26%|██▋       | 2728/10365 [16:29:16<47:42:14, 22.49s/it] 26%|██▋       | 2729/10365 [16:29:37<46:44:07, 22.03s/it] 26%|██▋       | 2730/10365 [16:29:58<46:31:15, 21.94s/it]                                                          {'loss': 1.0563, 'grad_norm': 1.015625, 'learning_rate': 8.383848438489938e-05, 'epoch': 0.26}
 26%|██▋       | 2730/10365 [16:29:58<46:31:15, 21.94s/it] 26%|██▋       | 2731/10365 [16:30:19<45:43:32, 21.56s/it] 26%|██▋       | 2732/10365 [16:30:41<46:21:36, 21.87s/it] 26%|██▋       | 2733/10365 [16:30:55<40:45:19, 19.22s/it] 26%|██▋       | 2734/10365 [16:31:12<39:50:01, 18.79s/it] 26%|██▋       | 2735/10365 [16:31:36<43:02:56, 20.31s/it] 26%|██▋       | 2736/10365 [16:31:56<42:55:28, 20.26s/it] 26%|██▋       | 2737/10365 [16:32:15<41:49:22, 19.74s/it] 26%|██▋       | 2738/10365 [16:32:34<41:24:51, 19.55s/it] 26%|██▋       | 2739/10365 [16:32:54<41:43:18, 19.70s/it] 26%|██▋       | 2740/10365 [16:33:17<44:02:49, 20.80s/it]                                                          {'loss': 1.0647, 'grad_norm': 1.140625, 'learning_rate': 8.372675910085123e-05, 'epoch': 0.26}
 26%|██▋       | 2740/10365 [16:33:17<44:02:49, 20.80s/it] 26%|██▋       | 2741/10365 [16:33:38<43:42:02, 20.64s/it] 26%|██▋       | 2742/10365 [16:34:00<44:29:44, 21.01s/it] 26%|██▋       | 2743/10365 [16:34:24<46:50:39, 22.13s/it] 26%|██▋       | 2744/10365 [16:34:43<44:37:00, 21.08s/it] 26%|██▋       | 2745/10365 [16:35:03<44:19:30, 20.94s/it] 26%|██▋       | 2746/10365 [16:35:23<43:36:24, 20.60s/it] 27%|██▋       | 2747/10365 [16:35:47<45:20:34, 21.43s/it] 27%|██▋       | 2748/10365 [16:36:07<44:41:04, 21.12s/it] 27%|██▋       | 2749/10365 [16:36:34<48:15:04, 22.81s/it] 27%|██▋       | 2750/10365 [16:36:59<49:43:04, 23.50s/it]                                                          {'loss': 1.0965, 'grad_norm': 1.0546875, 'learning_rate': 8.36147239723036e-05, 'epoch': 0.27}
 27%|██▋       | 2750/10365 [16:36:59<49:43:04, 23.50s/it] 27%|██▋       | 2751/10365 [16:37:18<47:03:03, 22.25s/it] 27%|██▋       | 2752/10365 [16:37:38<45:38:39, 21.58s/it] 27%|██▋       | 2753/10365 [16:37:59<45:08:31, 21.35s/it] 27%|██▋       | 2754/10365 [16:38:20<44:49:42, 21.20s/it] 27%|██▋       | 2755/10365 [16:38:45<47:33:12, 22.50s/it] 27%|██▋       | 2756/10365 [16:39:08<47:28:20, 22.46s/it] 27%|██▋       | 2757/10365 [16:39:27<45:16:53, 21.43s/it] 27%|██▋       | 2758/10365 [16:39:46<44:08:25, 20.89s/it] 27%|██▋       | 2759/10365 [16:40:10<46:04:05, 21.80s/it] 27%|██▋       | 2760/10365 [16:40:30<44:28:19, 21.05s/it]                                                          {'loss': 1.0944, 'grad_norm': 1.1640625, 'learning_rate': 8.35023800285125e-05, 'epoch': 0.27}
 27%|██▋       | 2760/10365 [16:40:30<44:28:19, 21.05s/it] 27%|██▋       | 2761/10365 [16:40:51<44:27:42, 21.05s/it] 27%|██▋       | 2762/10365 [16:41:14<45:36:15, 21.59s/it] 27%|██▋       | 2763/10365 [16:41:37<46:50:39, 22.18s/it] 27%|██▋       | 2764/10365 [16:41:58<46:14:34, 21.90s/it] 27%|██▋       | 2765/10365 [16:42:18<45:01:56, 21.33s/it] 27%|██▋       | 2766/10365 [16:42:43<47:04:53, 22.30s/it] 27%|██▋       | 2767/10365 [16:43:05<46:53:39, 22.22s/it] 27%|██▋       | 2768/10365 [16:43:22<43:19:23, 20.53s/it] 27%|██▋       | 2769/10365 [16:43:38<40:34:34, 19.23s/it] 27%|██▋       | 2770/10365 [16:44:01<42:59:29, 20.38s/it]                                                          {'loss': 1.1013, 'grad_norm': 1.0078125, 'learning_rate': 8.33897283015709e-05, 'epoch': 0.27}
 27%|██▋       | 2770/10365 [16:44:01<42:59:29, 20.38s/it] 27%|██▋       | 2771/10365 [16:44:24<44:37:10, 21.15s/it] 27%|██▋       | 2772/10365 [16:44:42<42:44:27, 20.26s/it] 27%|██▋       | 2773/10365 [16:45:05<44:24:00, 21.05s/it] 27%|██▋       | 2774/10365 [16:45:26<44:29:32, 21.10s/it] 27%|██▋       | 2775/10365 [16:45:43<41:59:00, 19.91s/it] 27%|██▋       | 2776/10365 [16:46:06<43:49:55, 20.79s/it] 27%|██▋       | 2777/10365 [16:46:31<46:19:28, 21.98s/it] 27%|██▋       | 2778/10365 [16:46:50<44:22:58, 21.06s/it] 27%|██▋       | 2779/10365 [16:47:09<43:19:12, 20.56s/it] 27%|██▋       | 2780/10365 [16:47:38<48:24:19, 22.97s/it]                                                          {'loss': 1.0791, 'grad_norm': 1.0390625, 'learning_rate': 8.327676982639947e-05, 'epoch': 0.27}
 27%|██▋       | 2780/10365 [16:47:38<48:24:19, 22.97s/it] 27%|██▋       | 2781/10365 [16:48:01<48:45:40, 23.15s/it] 27%|██▋       | 2782/10365 [16:48:22<47:22:15, 22.49s/it] 27%|██▋       | 2783/10365 [16:48:46<47:51:25, 22.72s/it] 27%|██▋       | 2784/10365 [16:49:00<42:46:18, 20.31s/it] 27%|██▋       | 2785/10365 [16:49:18<41:19:20, 19.63s/it] 27%|██▋       | 2786/10365 [16:49:37<41:03:19, 19.50s/it] 27%|██▋       | 2787/10365 [16:49:55<40:02:20, 19.02s/it] 27%|██▋       | 2788/10365 [16:50:17<41:57:00, 19.93s/it] 27%|██▋       | 2789/10365 [16:50:39<42:42:18, 20.29s/it] 27%|██▋       | 2790/10365 [16:51:00<43:20:48, 20.60s/it]                                                          {'loss': 1.0899, 'grad_norm': 1.0625, 'learning_rate': 8.316350564073684e-05, 'epoch': 0.27}
 27%|██▋       | 2790/10365 [16:51:00<43:20:48, 20.60s/it] 27%|██▋       | 2791/10365 [16:51:21<43:28:02, 20.66s/it] 27%|██▋       | 2792/10365 [16:51:42<43:46:38, 20.81s/it] 27%|██▋       | 2793/10365 [16:52:01<42:49:23, 20.36s/it] 27%|██▋       | 2794/10365 [16:52:22<43:05:34, 20.49s/it] 27%|██▋       | 2795/10365 [16:52:49<47:01:44, 22.37s/it] 27%|██▋       | 2796/10365 [16:53:10<46:17:10, 22.01s/it] 27%|██▋       | 2797/10365 [16:53:29<44:29:29, 21.16s/it] 27%|██▋       | 2798/10365 [16:53:48<43:08:44, 20.53s/it] 27%|██▋       | 2799/10365 [16:54:05<40:40:48, 19.36s/it] 27%|██▋       | 2800/10365 [16:54:24<40:49:32, 19.43s/it]                                                          {'loss': 1.0657, 'grad_norm': 1.09375, 'learning_rate': 8.304993678513025e-05, 'epoch': 0.27}
 27%|██▋       | 2800/10365 [16:54:24<40:49:32, 19.43s/it] 27%|██▋       | 2801/10365 [16:54:49<43:50:30, 20.87s/it] 27%|██▋       | 2802/10365 [16:55:15<47:11:31, 22.46s/it] 27%|██▋       | 2803/10365 [16:55:31<43:35:40, 20.75s/it] 27%|██▋       | 2804/10365 [16:55:53<43:51:18, 20.88s/it] 27%|██▋       | 2805/10365 [16:56:09<41:15:35, 19.65s/it] 27%|██▋       | 2806/10365 [16:56:30<42:07:11, 20.06s/it] 27%|██▋       | 2807/10365 [16:56:49<41:13:14, 19.63s/it] 27%|██▋       | 2808/10365 [16:57:11<42:54:25, 20.44s/it] 27%|██▋       | 2809/10365 [16:57:38<46:55:33, 22.36s/it] 27%|██▋       | 2810/10365 [16:57:59<45:45:05, 21.80s/it]                                                          {'loss': 1.0755, 'grad_norm': 1.03125, 'learning_rate': 8.293606430292584e-05, 'epoch': 0.27}
 27%|██▋       | 2810/10365 [16:57:59<45:45:05, 21.80s/it] 27%|██▋       | 2811/10365 [16:58:21<46:09:06, 21.99s/it] 27%|██▋       | 2812/10365 [16:58:46<47:46:59, 22.77s/it] 27%|██▋       | 2813/10365 [16:59:04<44:50:33, 21.38s/it] 27%|██▋       | 2814/10365 [16:59:27<45:56:18, 21.90s/it] 27%|██▋       | 2815/10365 [16:59:42<41:40:35, 19.87s/it] 27%|██▋       | 2816/10365 [17:00:03<42:10:52, 20.12s/it] 27%|██▋       | 2817/10365 [17:00:24<43:05:15, 20.55s/it] 27%|██▋       | 2818/10365 [17:00:49<45:34:02, 21.74s/it] 27%|██▋       | 2819/10365 [17:01:09<44:48:16, 21.38s/it] 27%|██▋       | 2820/10365 [17:01:31<44:50:55, 21.40s/it]                                                          {'loss': 1.0691, 'grad_norm': 1.0, 'learning_rate': 8.28218892402592e-05, 'epoch': 0.27}
 27%|██▋       | 2820/10365 [17:01:31<44:50:55, 21.40s/it] 27%|██▋       | 2821/10365 [17:01:58<48:30:35, 23.15s/it] 27%|██▋       | 2822/10365 [17:02:16<45:03:41, 21.51s/it] 27%|██▋       | 2823/10365 [17:02:35<43:20:23, 20.69s/it] 27%|██▋       | 2824/10365 [17:02:53<42:07:26, 20.11s/it] 27%|██▋       | 2825/10365 [17:03:14<42:28:52, 20.28s/it] 27%|██▋       | 2826/10365 [17:03:34<42:30:17, 20.30s/it] 27%|██▋       | 2827/10365 [17:03:54<41:53:31, 20.01s/it] 27%|██▋       | 2828/10365 [17:04:22<47:13:47, 22.56s/it] 27%|██▋       | 2829/10365 [17:04:46<48:03:57, 22.96s/it] 27%|██▋       | 2830/10365 [17:05:06<46:10:06, 22.06s/it]                                                          {'loss': 1.0981, 'grad_norm': 1.0859375, 'learning_rate': 8.270741264604566e-05, 'epoch': 0.27}
 27%|██▋       | 2830/10365 [17:05:06<46:10:06, 22.06s/it] 27%|██▋       | 2831/10365 [17:05:29<46:37:46, 22.28s/it] 27%|██▋       | 2832/10365 [17:05:49<45:21:38, 21.68s/it] 27%|██▋       | 2833/10365 [17:06:09<44:19:51, 21.19s/it] 27%|██▋       | 2834/10365 [17:06:27<42:09:21, 20.15s/it] 27%|██▋       | 2835/10365 [17:06:47<41:48:23, 19.99s/it] 27%|██▋       | 2836/10365 [17:07:07<42:17:12, 20.22s/it] 27%|██▋       | 2837/10365 [17:07:27<41:59:58, 20.08s/it] 27%|██▋       | 2838/10365 [17:07:45<40:26:44, 19.34s/it] 27%|██▋       | 2839/10365 [17:08:01<38:51:15, 18.59s/it] 27%|██▋       | 2840/10365 [17:08:19<38:02:50, 18.20s/it]                                                          {'loss': 1.0732, 'grad_norm': 1.1015625, 'learning_rate': 8.259263557197073e-05, 'epoch': 0.27}
 27%|██▋       | 2840/10365 [17:08:19<38:02:50, 18.20s/it] 27%|██▋       | 2841/10365 [17:08:37<37:54:05, 18.13s/it] 27%|██▋       | 2842/10365 [17:08:53<36:40:44, 17.55s/it] 27%|██▋       | 2843/10365 [17:09:13<38:14:58, 18.31s/it] 27%|██▋       | 2844/10365 [17:09:33<39:34:57, 18.95s/it] 27%|██▋       | 2845/10365 [17:09:59<43:36:20, 20.88s/it] 27%|██▋       | 2846/10365 [17:10:20<43:57:34, 21.05s/it] 27%|██▋       | 2847/10365 [17:10:38<41:48:14, 20.02s/it] 27%|██▋       | 2848/10365 [17:10:57<41:17:45, 19.78s/it] 27%|██▋       | 2849/10365 [17:11:16<40:45:23, 19.52s/it] 27%|██▋       | 2850/10365 [17:11:38<42:10:04, 20.20s/it]                                                          {'loss': 1.0469, 'grad_norm': 0.91015625, 'learning_rate': 8.247755907248036e-05, 'epoch': 0.27}
 27%|██▋       | 2850/10365 [17:11:38<42:10:04, 20.20s/it] 28%|██▊       | 2851/10365 [17:12:03<45:14:43, 21.68s/it] 28%|██▊       | 2852/10365 [17:12:26<45:51:40, 21.98s/it] 28%|██▊       | 2853/10365 [17:12:44<43:33:35, 20.88s/it] 28%|██▊       | 2854/10365 [17:13:02<42:01:32, 20.14s/it] 28%|██▊       | 2855/10365 [17:13:22<41:33:23, 19.92s/it] 28%|██▊       | 2856/10365 [17:13:45<43:36:39, 20.91s/it] 28%|██▊       | 2857/10365 [17:14:06<43:40:14, 20.94s/it] 28%|██▊       | 2858/10365 [17:14:28<44:06:07, 21.15s/it] 28%|██▊       | 2859/10365 [17:14:50<44:37:19, 21.40s/it] 28%|██▊       | 2860/10365 [17:15:08<42:52:07, 20.56s/it]                                                          {'loss': 1.0379, 'grad_norm': 1.0625, 'learning_rate': 8.23621842047713e-05, 'epoch': 0.28}
 28%|██▊       | 2860/10365 [17:15:08<42:52:07, 20.56s/it] 28%|██▊       | 2861/10365 [17:15:27<41:31:28, 19.92s/it] 28%|██▊       | 2862/10365 [17:15:48<42:21:33, 20.32s/it] 28%|██▊       | 2863/10365 [17:16:11<44:09:10, 21.19s/it] 28%|██▊       | 2864/10365 [17:16:31<43:36:59, 20.93s/it] 28%|██▊       | 2865/10365 [17:16:53<44:07:42, 21.18s/it] 28%|██▊       | 2866/10365 [17:17:13<43:00:54, 20.65s/it] 28%|██▊       | 2867/10365 [17:17:31<41:44:18, 20.04s/it] 28%|██▊       | 2868/10365 [17:17:54<43:29:56, 20.89s/it] 28%|██▊       | 2869/10365 [17:18:12<41:52:18, 20.11s/it] 28%|██▊       | 2870/10365 [17:18:32<41:35:12, 19.98s/it]                                                          {'loss': 1.1006, 'grad_norm': 0.95703125, 'learning_rate': 8.224651202878139e-05, 'epoch': 0.28}
 28%|██▊       | 2870/10365 [17:18:32<41:35:12, 19.98s/it] 28%|██▊       | 2871/10365 [17:18:53<42:02:35, 20.20s/it] 28%|██▊       | 2872/10365 [17:19:12<41:16:20, 19.83s/it] 28%|██▊       | 2873/10365 [17:19:38<45:18:36, 21.77s/it] 28%|██▊       | 2874/10365 [17:19:54<41:41:33, 20.04s/it] 28%|██▊       | 2875/10365 [17:20:15<42:26:05, 20.40s/it] 28%|██▊       | 2876/10365 [17:20:39<44:18:47, 21.30s/it] 28%|██▊       | 2877/10365 [17:20:58<43:03:16, 20.70s/it] 28%|██▊       | 2878/10365 [17:21:18<42:48:36, 20.58s/it] 28%|██▊       | 2879/10365 [17:21:44<45:41:45, 21.98s/it] 28%|██▊       | 2880/10365 [17:22:07<46:25:48, 22.33s/it]                                                          {'loss': 1.0654, 'grad_norm': 1.03125, 'learning_rate': 8.213054360717985e-05, 'epoch': 0.28}
 28%|██▊       | 2880/10365 [17:22:07<46:25:48, 22.33s/it] 28%|██▊       | 2881/10365 [17:22:27<45:21:49, 21.82s/it] 28%|██▊       | 2882/10365 [17:22:48<44:30:05, 21.41s/it] 28%|██▊       | 2883/10365 [17:23:10<45:03:13, 21.68s/it] 28%|██▊       | 2884/10365 [17:23:28<42:45:23, 20.58s/it] 28%|██▊       | 2885/10365 [17:23:52<45:04:01, 21.69s/it] 28%|██▊       | 2886/10365 [17:24:15<45:32:45, 21.92s/it] 28%|██▊       | 2887/10365 [17:24:42<48:57:01, 23.57s/it] 28%|██▊       | 2888/10365 [17:25:03<47:12:37, 22.73s/it] 28%|██▊       | 2889/10365 [17:25:23<45:37:04, 21.97s/it] 28%|██▊       | 2890/10365 [17:25:38<41:16:11, 19.88s/it]                                                          {'loss': 1.0851, 'grad_norm': 1.03125, 'learning_rate': 8.201428000535739e-05, 'epoch': 0.28}
 28%|██▊       | 2890/10365 [17:25:38<41:16:11, 19.88s/it] 28%|██▊       | 2891/10365 [17:25:58<41:13:37, 19.86s/it] 28%|██▊       | 2892/10365 [17:26:23<44:09:40, 21.27s/it] 28%|██▊       | 2893/10365 [17:26:43<43:25:14, 20.92s/it] 28%|██▊       | 2894/10365 [17:27:07<45:25:57, 21.89s/it] 28%|██▊       | 2895/10365 [17:27:29<45:21:53, 21.86s/it] 28%|██▊       | 2896/10365 [17:27:48<44:05:00, 21.25s/it] 28%|██▊       | 2897/10365 [17:28:06<41:52:18, 20.18s/it] 28%|██▊       | 2898/10365 [17:28:23<39:39:48, 19.12s/it] 28%|██▊       | 2899/10365 [17:28:42<39:32:24, 19.07s/it] 28%|██▊       | 2900/10365 [17:29:01<39:27:16, 19.03s/it]                                                          {'loss': 1.0913, 'grad_norm': 1.078125, 'learning_rate': 8.189772229141658e-05, 'epoch': 0.28}
 28%|██▊       | 2900/10365 [17:29:01<39:27:16, 19.03s/it] 28%|██▊       | 2901/10365 [17:29:20<39:21:47, 18.99s/it] 28%|██▊       | 2902/10365 [17:29:42<41:23:02, 19.96s/it] 28%|██▊       | 2903/10365 [17:30:01<41:04:30, 19.82s/it] 28%|██▊       | 2904/10365 [17:30:24<42:36:33, 20.56s/it] 28%|██▊       | 2905/10365 [17:30:39<39:36:09, 19.11s/it] 28%|██▊       | 2906/10365 [17:31:00<40:53:23, 19.73s/it] 28%|██▊       | 2907/10365 [17:31:23<42:19:32, 20.43s/it] 28%|██▊       | 2908/10365 [17:31:45<43:36:10, 21.05s/it] 28%|██▊       | 2909/10365 [17:32:02<41:10:11, 19.88s/it] 28%|██▊       | 2910/10365 [17:32:26<43:52:07, 21.18s/it]                                                          {'loss': 1.0447, 'grad_norm': 0.98828125, 'learning_rate': 8.178087153616196e-05, 'epoch': 0.28}
 28%|██▊       | 2910/10365 [17:32:26<43:52:07, 21.18s/it] 28%|██▊       | 2911/10365 [17:32:47<43:38:50, 21.08s/it] 28%|██▊       | 2912/10365 [17:33:11<45:21:30, 21.91s/it] 28%|██▊       | 2913/10365 [17:33:30<43:44:01, 21.13s/it] 28%|██▊       | 2914/10365 [17:33:54<45:00:53, 21.75s/it] 28%|██▊       | 2915/10365 [17:34:09<41:19:49, 19.97s/it] 28%|██▊       | 2916/10365 [17:34:29<40:55:23, 19.78s/it] 28%|██▊       | 2917/10365 [17:34:51<42:27:27, 20.52s/it] 28%|██▊       | 2918/10365 [17:35:16<45:22:11, 21.93s/it] 28%|██▊       | 2919/10365 [17:35:36<44:08:35, 21.34s/it] 28%|██▊       | 2920/10365 [17:35:58<44:20:32, 21.44s/it]                                                          {'loss': 1.0428, 'grad_norm': 1.0234375, 'learning_rate': 8.166372881309021e-05, 'epoch': 0.28}
 28%|██▊       | 2920/10365 [17:35:58<44:20:32, 21.44s/it] 28%|██▊       | 2921/10365 [17:36:19<44:06:06, 21.33s/it] 28%|██▊       | 2922/10365 [17:36:42<45:15:02, 21.89s/it] 28%|██▊       | 2923/10365 [17:37:05<45:49:34, 22.17s/it] 28%|██▊       | 2924/10365 [17:37:21<42:06:06, 20.37s/it] 28%|██▊       | 2925/10365 [17:37:49<46:44:25, 22.62s/it] 28%|██▊       | 2926/10365 [17:38:12<46:46:37, 22.64s/it] 28%|██▊       | 2927/10365 [17:38:34<46:20:34, 22.43s/it] 28%|██▊       | 2928/10365 [17:38:53<44:19:58, 21.46s/it] 28%|██▊       | 2929/10365 [17:39:18<46:37:55, 22.58s/it] 28%|██▊       | 2930/10365 [17:39:43<47:57:32, 23.22s/it]                                                          {'loss': 1.0489, 'grad_norm': 1.2421875, 'learning_rate': 8.154629519838027e-05, 'epoch': 0.28}
 28%|██▊       | 2930/10365 [17:39:43<47:57:32, 23.22s/it] 28%|██▊       | 2931/10365 [17:40:04<46:48:21, 22.67s/it] 28%|██▊       | 2932/10365 [17:40:22<44:06:23, 21.36s/it] 28%|██▊       | 2933/10365 [17:40:46<45:46:22, 22.17s/it] 28%|██▊       | 2934/10365 [17:41:09<46:00:01, 22.29s/it] 28%|██▊       | 2935/10365 [17:41:28<44:08:28, 21.39s/it] 28%|██▊       | 2936/10365 [17:41:47<42:45:02, 20.72s/it] 28%|██▊       | 2937/10365 [17:42:12<44:51:05, 21.74s/it] 28%|██▊       | 2938/10365 [17:42:32<43:56:52, 21.30s/it] 28%|██▊       | 2939/10365 [17:42:49<41:37:17, 20.18s/it] 28%|██▊       | 2940/10365 [17:43:08<40:24:33, 19.59s/it]                                                          {'loss': 1.0513, 'grad_norm': 1.1328125, 'learning_rate': 8.14285717708835e-05, 'epoch': 0.28}
 28%|██▊       | 2940/10365 [17:43:08<40:24:33, 19.59s/it] 28%|██▊       | 2941/10365 [17:43:25<38:58:14, 18.90s/it] 28%|██▊       | 2942/10365 [17:43:49<42:26:01, 20.58s/it] 28%|██▊       | 2943/10365 [17:44:10<42:08:16, 20.44s/it] 28%|██▊       | 2944/10365 [17:44:29<41:24:44, 20.09s/it] 28%|██▊       | 2945/10365 [17:44:48<40:36:15, 19.70s/it] 28%|██▊       | 2946/10365 [17:45:08<40:46:08, 19.78s/it] 28%|██▊       | 2947/10365 [17:45:36<46:17:20, 22.46s/it] 28%|██▊       | 2948/10365 [17:45:58<46:04:42, 22.37s/it] 28%|██▊       | 2949/10365 [17:46:25<48:23:25, 23.49s/it] 28%|██▊       | 2950/10365 [17:46:45<46:26:26, 22.55s/it]                                                          {'loss': 1.0846, 'grad_norm': 0.96484375, 'learning_rate': 8.131055961211373e-05, 'epoch': 0.28}
 28%|██▊       | 2950/10365 [17:46:45<46:26:26, 22.55s/it] 28%|██▊       | 2951/10365 [17:47:07<46:21:10, 22.51s/it] 28%|██▊       | 2952/10365 [17:47:32<47:39:15, 23.14s/it] 28%|██▊       | 2953/10365 [17:47:55<47:36:56, 23.13s/it] 28%|██▊       | 2954/10365 [17:48:17<46:51:01, 22.76s/it] 29%|██▊       | 2955/10365 [17:48:43<48:41:05, 23.65s/it] 29%|██▊       | 2956/10365 [17:49:02<45:57:30, 22.33s/it] 29%|██▊       | 2957/10365 [17:49:21<43:52:18, 21.32s/it] 29%|██▊       | 2958/10365 [17:49:38<41:32:37, 20.19s/it] 29%|██▊       | 2959/10365 [17:50:01<42:47:45, 20.80s/it] 29%|██▊       | 2960/10365 [17:50:19<41:00:10, 19.93s/it]                                                          {'loss': 1.0558, 'grad_norm': 0.953125, 'learning_rate': 8.119225980623733e-05, 'epoch': 0.29}
 29%|██▊       | 2960/10365 [17:50:19<41:00:10, 19.93s/it] 29%|██▊       | 2961/10365 [17:50:38<40:38:15, 19.76s/it] 29%|██▊       | 2962/10365 [17:50:56<39:25:05, 19.17s/it] 29%|██▊       | 2963/10365 [17:51:11<37:07:29, 18.06s/it] 29%|██▊       | 2964/10365 [17:51:33<39:13:00, 19.08s/it] 29%|██▊       | 2965/10365 [17:51:56<41:41:08, 20.28s/it] 29%|██▊       | 2966/10365 [17:52:15<41:09:41, 20.03s/it] 29%|██▊       | 2967/10365 [17:52:33<39:32:48, 19.24s/it] 29%|██▊       | 2968/10365 [17:53:02<45:59:22, 22.38s/it] 29%|██▊       | 2969/10365 [17:53:23<44:47:17, 21.80s/it] 29%|██▊       | 2970/10365 [17:53:51<48:58:10, 23.84s/it]                                                          {'loss': 1.0637, 'grad_norm': 0.9453125, 'learning_rate': 8.107367344006329e-05, 'epoch': 0.29}
 29%|██▊       | 2970/10365 [17:53:51<48:58:10, 23.84s/it] 29%|██▊       | 2971/10365 [17:54:13<47:30:27, 23.13s/it] 29%|██▊       | 2972/10365 [17:54:28<42:42:59, 20.80s/it] 29%|██▊       | 2973/10365 [17:54:50<43:10:23, 21.03s/it] 29%|██▊       | 2974/10365 [17:55:12<44:06:35, 21.48s/it] 29%|██▊       | 2975/10365 [17:55:30<42:00:16, 20.46s/it] 29%|██▊       | 2976/10365 [17:55:55<44:38:23, 21.75s/it] 29%|██▊       | 2977/10365 [17:56:15<43:18:48, 21.11s/it] 29%|██▊       | 2978/10365 [17:56:41<46:12:49, 22.52s/it] 29%|██▊       | 2979/10365 [17:57:02<45:50:02, 22.34s/it] 29%|██▉       | 2980/10365 [17:57:29<48:19:09, 23.55s/it]                                                          {'loss': 1.036, 'grad_norm': 1.0859375, 'learning_rate': 8.095480160303315e-05, 'epoch': 0.29}
 29%|██▉       | 2980/10365 [17:57:29<48:19:09, 23.55s/it] 29%|██▉       | 2981/10365 [17:57:53<48:53:48, 23.84s/it] 29%|██▉       | 2982/10365 [17:58:18<49:10:38, 23.98s/it] 29%|██▉       | 2983/10365 [17:58:33<43:52:13, 21.39s/it] 29%|██▉       | 2984/10365 [17:58:59<46:53:32, 22.87s/it] 29%|██▉       | 2985/10365 [17:59:25<48:26:10, 23.63s/it] 29%|██▉       | 2986/10365 [17:59:43<45:22:38, 22.14s/it] 29%|██▉       | 2987/10365 [17:59:59<41:17:04, 20.14s/it] 29%|██▉       | 2988/10365 [18:00:18<40:41:31, 19.86s/it] 29%|██▉       | 2989/10365 [18:00:49<47:35:22, 23.23s/it] 29%|██▉       | 2990/10365 [18:01:13<48:07:10, 23.49s/it]                                                          {'loss': 1.0779, 'grad_norm': 0.98828125, 'learning_rate': 8.083564538721106e-05, 'epoch': 0.29}
 29%|██▉       | 2990/10365 [18:01:13<48:07:10, 23.49s/it] 29%|██▉       | 2991/10365 [18:01:34<46:44:17, 22.82s/it] 29%|██▉       | 2992/10365 [18:02:02<49:30:35, 24.17s/it] 29%|██▉       | 2993/10365 [18:02:20<45:50:33, 22.39s/it] 29%|██▉       | 2994/10365 [18:02:40<44:23:54, 21.68s/it] 29%|██▉       | 2995/10365 [18:03:02<44:15:04, 21.62s/it] 29%|██▉       | 2996/10365 [18:03:29<47:47:16, 23.35s/it] 29%|██▉       | 2997/10365 [18:03:53<47:58:05, 23.44s/it] 29%|██▉       | 2998/10365 [18:04:13<46:16:43, 22.61s/it] 29%|██▉       | 2999/10365 [18:04:37<47:12:25, 23.07s/it] 29%|██▉       | 3000/10365 [18:04:57<45:10:05, 22.08s/it]                                                          {'loss': 1.0787, 'grad_norm': 0.97265625, 'learning_rate': 8.071620588727377e-05, 'epoch': 0.29}
 29%|██▉       | 3000/10365 [18:04:57<45:10:05, 22.08s/it][INFO|trainer.py:3719] 2024-05-31 04:59:23,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3721] 2024-05-31 04:59:23,047 >>   Num examples = 5000
[INFO|trainer.py:3724] 2024-05-31 04:59:23,047 >>   Batch size = 40

  0%|          | 0/63 [00:00<?, ?it/s][A
  3%|▎         | 2/63 [00:03<01:47,  1.77s/it][A
  5%|▍         | 3/63 [00:08<03:16,  3.28s/it][A
  6%|▋         | 4/63 [00:13<03:48,  3.87s/it][A
  8%|▊         | 5/63 [00:18<04:07,  4.27s/it][A
 10%|▉         | 6/63 [00:23<04:12,  4.42s/it][A
 11%|█         | 7/63 [00:28<04:17,  4.60s/it][A
 13%|█▎        | 8/63 [00:33<04:15,  4.64s/it][A
 14%|█▍        | 9/63 [00:38<04:17,  4.77s/it][A
 16%|█▌        | 10/63 [00:43<04:26,  5.03s/it][A
 17%|█▋        | 11/63 [00:49<04:35,  5.30s/it][A
 19%|█▉        | 12/63 [00:54<04:21,  5.13s/it][A
 21%|██        | 13/63 [00:59<04:16,  5.13s/it][A
 22%|██▏       | 14/63 [01:04<04:03,  4.96s/it][A
 24%|██▍       | 15/63 [01:09<04:01,  5.02s/it][A
 25%|██▌       | 16/63 [01:14<03:55,  5.01s/it][A
 27%|██▋       | 17/63 [01:19<03:51,  5.03s/it][A
 29%|██▊       | 18/63 [01:24<03:52,  5.16s/it][A
 30%|███       | 19/63 [01:30<03:53,  5.30s/it][A
 32%|███▏      | 20/63 [01:36<03:51,  5.39s/it][A
 33%|███▎      | 21/63 [01:40<03:35,  5.12s/it][A
 35%|███▍      | 22/63 [01:47<03:44,  5.48s/it][A
 37%|███▋      | 23/63 [01:50<03:17,  4.94s/it][A
 38%|███▊      | 24/63 [01:56<03:20,  5.14s/it][A
 40%|███▉      | 25/63 [02:01<03:21,  5.31s/it][A
 41%|████▏     | 26/63 [02:06<03:11,  5.19s/it][A
 43%|████▎     | 27/63 [02:12<03:12,  5.35s/it][A
 44%|████▍     | 28/63 [02:18<03:14,  5.55s/it][A
 46%|████▌     | 29/63 [02:25<03:23,  5.97s/it][A
 48%|████▊     | 30/63 [02:29<03:01,  5.49s/it][A
 49%|████▉     | 31/63 [02:35<02:52,  5.38s/it][A
 51%|█████     | 32/63 [02:39<02:34,  4.98s/it][A
 52%|█████▏    | 33/63 [02:45<02:37,  5.25s/it][A
 54%|█████▍    | 34/63 [02:48<02:17,  4.75s/it][A
 56%|█████▌    | 35/63 [02:53<02:13,  4.76s/it][A
 57%|█████▋    | 36/63 [02:57<02:04,  4.60s/it][A
 59%|█████▊    | 37/63 [03:04<02:14,  5.18s/it][A
 60%|██████    | 38/63 [03:09<02:12,  5.29s/it][A
 62%|██████▏   | 39/63 [03:14<02:01,  5.06s/it][A
 63%|██████▎   | 40/63 [03:19<01:57,  5.09s/it][A
 65%|██████▌   | 41/63 [03:24<01:53,  5.14s/it][A
 67%|██████▋   | 42/63 [03:31<02:01,  5.77s/it][A
 68%|██████▊   | 43/63 [03:37<01:54,  5.74s/it][A
 70%|██████▉   | 44/63 [03:42<01:43,  5.44s/it][A
 71%|███████▏  | 45/63 [03:49<01:45,  5.88s/it][A
 73%|███████▎  | 46/63 [03:54<01:39,  5.83s/it][A
 75%|███████▍  | 47/63 [04:00<01:32,  5.78s/it][A
 76%|███████▌  | 48/63 [04:07<01:31,  6.12s/it][A
 78%|███████▊  | 49/63 [04:11<01:18,  5.64s/it][A
 79%|███████▉  | 50/63 [04:18<01:16,  5.91s/it][A
 81%|████████  | 51/63 [04:24<01:09,  5.80s/it][A
 83%|████████▎ | 52/63 [04:30<01:07,  6.14s/it][A
 84%|████████▍ | 53/63 [04:36<00:59,  5.93s/it][A
 86%|████████▌ | 54/63 [04:41<00:52,  5.82s/it][A
 87%|████████▋ | 55/63 [04:46<00:42,  5.37s/it][A
 89%|████████▉ | 56/63 [04:51<00:36,  5.26s/it][A
 90%|█████████ | 57/63 [04:56<00:31,  5.31s/it][A
 92%|█████████▏| 58/63 [05:01<00:26,  5.21s/it][A
 94%|█████████▎| 59/63 [05:06<00:20,  5.15s/it][A
 95%|█████████▌| 60/63 [05:11<00:14,  4.89s/it][A
 97%|█████████▋| 61/63 [05:17<00:10,  5.41s/it][A
 98%|█████████▊| 62/63 [05:23<00:05,  5.68s/it][A
100%|██████████| 63/63 [05:30<00:00,  5.83s/it][A                                                          
                                               [A{'eval_loss': 1.0776293277740479, 'eval_runtime': 336.569, 'eval_samples_per_second': 14.856, 'eval_steps_per_second': 0.187, 'epoch': 0.29}
 29%|██▉       | 3000/10365 [18:10:34<45:10:05, 22.08s/it]
100%|██████████| 63/63 [05:30<00:00,  5.83s/it][A
                                               [A[INFO|trainer.py:3410] 2024-05-31 05:05:02,086 >> Saving model checkpoint to saves/mistral/fsdp_qlora_sft/checkpoint-3000
/home/xiaoyukou/anaconda3/envs/py3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /data/xiaoyukou/ckpts/Mistral-7B-Instruct-v0.2 - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2513] 2024-05-31 05:05:02,136 >> tokenizer config file saved in saves/mistral/fsdp_qlora_sft/checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-05-31 05:05:02,136 >> Special tokens file saved in saves/mistral/fsdp_qlora_sft/checkpoint-3000/special_tokens_map.json
 29%|██▉       | 3001/10365 [18:11:00<254:13:01, 124.28s/it] 29%|██▉       | 3002/10365 [18:11:20<190:18:07, 93.04s/it]  29%|██▉       | 3003/10365 [18:11:41<146:03:01, 71.42s/it] 29%|██▉       | 3004/10365 [18:12:03<115:33:50, 56.52s/it] 29%|██▉       | 3005/10365 [18:12:23<93:00:22, 45.49s/it]  29%|██▉       | 3006/10365 [18:12:47<80:02:47, 39.16s/it] 29%|██▉       | 3007/10365 [18:13:08<68:52:28, 33.70s/it] 29%|██▉       | 3008/10365 [18:13:31<62:10:07, 30.42s/it] 29%|██▉       | 3009/10365 [18:13:49<54:42:04, 26.77s/it] 29%|██▉       | 3010/10365 [18:14:08<50:00:29, 24.48s/it]                                                          {'loss': 1.0615, 'grad_norm': 1.1328125, 'learning_rate': 8.05964842005005e-05, 'epoch': 0.29}
 29%|██▉       | 3010/10365 [18:14:08<50:00:29, 24.48s/it] 29%|██▉       | 3011/10365 [18:14:29<47:54:28, 23.45s/it] 29%|██▉       | 3012/10365 [18:14:49<45:47:30, 22.42s/it] 29%|██▉       | 3013/10365 [18:15:09<44:31:08, 21.80s/it] 29%|██▉       | 3014/10365 [18:15:33<45:29:10, 22.28s/it] 29%|██▉       | 3015/10365 [18:15:54<45:02:42, 22.06s/it] 29%|██▉       | 3016/10365 [18:16:10<41:20:12, 20.25s/it] 29%|██▉       | 3017/10365 [18:16:34<43:24:30, 21.27s/it] 29%|██▉       | 3018/10365 [18:16:55<43:27:52, 21.30s/it] 29%|██▉       | 3019/10365 [18:17:19<44:38:34, 21.88s/it] 29%|██▉       | 3020/10365 [18:17:47<48:16:58, 23.66s/it]                                                          {'loss': 1.1019, 'grad_norm': 0.97265625, 'learning_rate': 8.04764814267629e-05, 'epoch': 0.29}
 29%|██▉       | 3020/10365 [18:17:47<48:16:58, 23.66s/it] 29%|██▉       | 3021/10365 [18:18:04<44:45:52, 21.94s/it] 29%|██▉       | 3022/10365 [18:18:22<41:46:48, 20.48s/it] 29%|██▉       | 3023/10365 [18:18:46<43:59:49, 21.57s/it] 29%|██▉       | 3024/10365 [18:19:08<44:25:34, 21.79s/it] 29%|██▉       | 3025/10365 [18:19:29<44:11:20, 21.67s/it] 29%|██▉       | 3026/10365 [18:19:50<43:34:06, 21.37s/it] 29%|██▉       | 3027/10365 [18:20:13<44:36:35, 21.89s/it] 29%|██▉       | 3028/10365 [18:20:32<42:49:52, 21.02s/it] 29%|██▉       | 3029/10365 [18:20:51<41:22:23, 20.30s/it] 29%|██▉       | 3030/10365 [18:21:11<41:17:34, 20.27s/it]                                                          {'loss': 1.0599, 'grad_norm': 1.0859375, 'learning_rate': 8.035619866851491e-05, 'epoch': 0.29}
 29%|██▉       | 3030/10365 [18:21:11<41:17:34, 20.27s/it] 29%|██▉       | 3031/10365 [18:21:32<41:39:32, 20.45s/it] 29%|██▉       | 3032/10365 [18:21:48<39:10:51, 19.24s/it] 29%|██▉       | 3033/10365 [18:22:10<40:38:42, 19.96s/it] 29%|██▉       | 3034/10365 [18:22:33<42:34:22, 20.91s/it] 29%|██▉       | 3035/10365 [18:22:55<43:26:35, 21.34s/it] 29%|██▉       | 3036/10365 [18:23:12<40:22:05, 19.83s/it] 29%|██▉       | 3037/10365 [18:23:32<40:42:34, 20.00s/it] 29%|██▉       | 3038/10365 [18:23:57<43:31:39, 21.39s/it] 29%|██▉       | 3039/10365 [18:24:20<44:47:57, 22.01s/it] 29%|██▉       | 3040/10365 [18:24:46<46:54:56, 23.06s/it]                                                          {'loss': 1.0818, 'grad_norm': 0.93359375, 'learning_rate': 8.023563703078273e-05, 'epoch': 0.29}
 29%|██▉       | 3040/10365 [18:24:46<46:54:56, 23.06s/it] 29%|██▉       | 3041/10365 [18:25:08<46:29:18, 22.85s/it] 29%|██▉       | 3042/10365 [18:25:29<45:30:52, 22.38s/it] 29%|██▉       | 3043/10365 [18:25:56<48:09:17, 23.68s/it] 29%|██▉       | 3044/10365 [18:26:16<45:59:22, 22.61s/it] 29%|██▉       | 3045/10365 [18:26:37<45:07:42, 22.19s/it] 29%|██▉       | 3046/10365 [18:26:59<44:36:22, 21.94s/it] 29%|██▉       | 3047/10365 [18:27:16<42:02:32, 20.68s/it] 29%|██▉       | 3048/10365 [18:27:36<41:13:51, 20.29s/it] 29%|██▉       | 3049/10365 [18:27:53<39:38:46, 19.51s/it] 29%|██▉       | 3050/10365 [18:28:11<38:25:52, 18.91s/it]                                                          {'loss': 1.0615, 'grad_norm': 0.97265625, 'learning_rate': 8.011479762115451e-05, 'epoch': 0.29}
 29%|██▉       | 3050/10365 [18:28:11<38:25:52, 18.91s/it] 29%|██▉       | 3051/10365 [18:28:30<38:13:38, 18.82s/it] 29%|██▉       | 3052/10365 [18:28:46<37:03:42, 18.24s/it] 29%|██▉       | 3053/10365 [18:29:08<38:59:31, 19.20s/it] 29%|██▉       | 3054/10365 [18:29:32<42:10:39, 20.77s/it] 29%|██▉       | 3055/10365 [18:29:54<42:45:22, 21.06s/it] 29%|██▉       | 3056/10365 [18:30:17<43:54:08, 21.62s/it] 29%|██▉       | 3057/10365 [18:30:47<48:57:22, 24.12s/it] 30%|██▉       | 3058/10365 [18:31:01<42:47:13, 21.08s/it] 30%|██▉       | 3059/10365 [18:31:24<44:16:31, 21.82s/it] 30%|██▉       | 3060/10365 [18:31:46<44:11:03, 21.77s/it]                                                          {'loss': 1.0645, 'grad_norm': 1.078125, 'learning_rate': 7.999368154977036e-05, 'epoch': 0.3}
 30%|██▉       | 3060/10365 [18:31:46<44:11:03, 21.77s/it] 30%|██▉       | 3061/10365 [18:32:08<44:18:10, 21.84s/it] 30%|██▉       | 3062/10365 [18:32:30<44:05:14, 21.73s/it] 30%|██▉       | 3063/10365 [18:32:48<42:00:27, 20.71s/it] 30%|██▉       | 3064/10365 [18:33:09<42:28:23, 20.94s/it] 30%|██▉       | 3065/10365 [18:33:33<44:05:05, 21.74s/it] 30%|██▉       | 3066/10365 [18:34:02<48:13:58, 23.79s/it] 30%|██▉       | 3067/10365 [18:34:21<45:29:25, 22.44s/it] 30%|██▉       | 3068/10365 [18:34:40<43:15:17, 21.34s/it] 30%|██▉       | 3069/10365 [18:35:02<43:41:19, 21.56s/it] 30%|██▉       | 3070/10365 [18:35:25<44:54:37, 22.16s/it]                                                          {'loss': 1.0446, 'grad_norm': 1.0078125, 'learning_rate': 7.987228992931195e-05, 'epoch': 0.3}
 30%|██▉       | 3070/10365 [18:35:25<44:54:37, 22.16s/it] 30%|██▉       | 3071/10365 [18:35:46<43:47:00, 21.61s/it] 30%|██▉       | 3072/10365 [18:36:09<44:49:12, 22.12s/it] 30%|██▉       | 3073/10365 [18:36:29<43:21:01, 21.40s/it] 30%|██▉       | 3074/10365 [18:36:44<39:23:58, 19.45s/it] 30%|██▉       | 3075/10365 [18:37:08<42:33:32, 21.02s/it] 30%|██▉       | 3076/10365 [18:37:30<42:52:20, 21.17s/it] 30%|██▉       | 3077/10365 [18:37:50<42:02:12, 20.76s/it] 30%|██▉       | 3078/10365 [18:38:07<40:10:41, 19.85s/it] 30%|██▉       | 3079/10365 [18:38:29<41:09:17, 20.33s/it] 30%|██▉       | 3080/10365 [18:38:50<41:59:11, 20.75s/it]                                                          {'loss': 1.0926, 'grad_norm': 1.0, 'learning_rate': 7.97506238749925e-05, 'epoch': 0.3}
 30%|██▉       | 3080/10365 [18:38:50<41:59:11, 20.75s/it] 30%|██▉       | 3081/10365 [18:39:17<45:33:29, 22.52s/it] 30%|██▉       | 3082/10365 [18:39:37<43:42:04, 21.60s/it] 30%|██▉       | 3083/10365 [18:39:56<42:26:21, 20.98s/it] 30%|██▉       | 3084/10365 [18:40:16<41:50:14, 20.69s/it] 30%|██▉       | 3085/10365 [18:40:39<43:12:33, 21.37s/it] 30%|██▉       | 3086/10365 [18:41:04<45:28:14, 22.49s/it] 30%|██▉       | 3087/10365 [18:41:25<44:19:29, 21.92s/it] 30%|██▉       | 3088/10365 [18:41:48<44:57:39, 22.24s/it] 30%|██▉       | 3089/10365 [18:42:10<44:48:08, 22.17s/it] 30%|██▉       | 3090/10365 [18:42:25<40:26:24, 20.01s/it]                                                          {'loss': 1.0282, 'grad_norm': 0.953125, 'learning_rate': 7.962868450454635e-05, 'epoch': 0.3}
 30%|██▉       | 3090/10365 [18:42:25<40:26:24, 20.01s/it] 30%|██▉       | 3091/10365 [18:42:41<38:05:38, 18.85s/it] 30%|██▉       | 3092/10365 [18:43:00<38:30:43, 19.06s/it] 30%|██▉       | 3093/10365 [18:43:27<43:19:45, 21.45s/it] 30%|██▉       | 3094/10365 [18:43:49<43:15:18, 21.42s/it] 30%|██▉       | 3095/10365 [18:44:08<42:01:27, 20.81s/it] 30%|██▉       | 3096/10365 [18:44:27<41:05:38, 20.35s/it] 30%|██▉       | 3097/10365 [18:44:50<42:38:34, 21.12s/it] 30%|██▉       | 3098/10365 [18:45:09<41:13:36, 20.42s/it] 30%|██▉       | 3099/10365 [18:45:30<41:27:13, 20.54s/it] 30%|██▉       | 3100/10365 [18:45:52<42:36:23, 21.11s/it]                                                          {'loss': 1.0813, 'grad_norm': 0.9453125, 'learning_rate': 7.950647293821879e-05, 'epoch': 0.3}
 30%|██▉       | 3100/10365 [18:45:52<42:36:23, 21.11s/it] 30%|██▉       | 3101/10365 [18:46:13<42:22:16, 21.00s/it] 30%|██▉       | 3102/10365 [18:46:30<39:46:04, 19.71s/it] 30%|██▉       | 3103/10365 [18:46:56<43:39:45, 21.64s/it] 30%|██▉       | 3104/10365 [18:47:15<42:12:28, 20.93s/it] 30%|██▉       | 3105/10365 [18:47:32<39:40:12, 19.67s/it] 30%|██▉       | 3106/10365 [18:47:56<42:20:36, 21.00s/it] 30%|██▉       | 3107/10365 [18:48:16<41:57:09, 20.81s/it] 30%|██▉       | 3108/10365 [18:48:37<42:00:09, 20.84s/it] 30%|██▉       | 3109/10365 [18:48:58<41:56:04, 20.81s/it] 30%|███       | 3110/10365 [18:49:19<42:00:42, 20.85s/it]                                                          {'loss': 1.0585, 'grad_norm': 1.1015625, 'learning_rate': 7.938399029875577e-05, 'epoch': 0.3}
 30%|███       | 3110/10365 [18:49:19<42:00:42, 20.85s/it] 30%|███       | 3111/10365 [18:49:40<42:06:22, 20.90s/it] 30%|███       | 3112/10365 [18:50:01<42:10:09, 20.93s/it] 30%|███       | 3113/10365 [18:50:23<42:46:35, 21.23s/it] 30%|███       | 3114/10365 [18:50:42<41:31:06, 20.61s/it] 30%|███       | 3115/10365 [18:51:06<43:42:23, 21.70s/it] 30%|███       | 3116/10365 [18:51:26<42:07:33, 20.92s/it] 30%|███       | 3117/10365 [18:51:47<42:22:07, 21.04s/it] 30%|███       | 3118/10365 [18:52:07<41:45:05, 20.74s/it] 30%|███       | 3119/10365 [18:52:27<41:05:45, 20.42s/it] 30%|███       | 3120/10365 [18:52:47<41:24:02, 20.57s/it]                                                          {'loss': 1.0368, 'grad_norm': 1.03125, 'learning_rate': 7.926123771139354e-05, 'epoch': 0.3}
 30%|███       | 3120/10365 [18:52:47<41:24:02, 20.57s/it] 30%|███       | 3121/10365 [18:53:08<41:25:55, 20.59s/it] 30%|███       | 3122/10365 [18:53:29<41:29:46, 20.63s/it] 30%|███       | 3123/10365 [18:53:48<40:21:38, 20.06s/it] 30%|███       | 3124/10365 [18:54:07<39:56:26, 19.86s/it] 30%|███       | 3125/10365 [18:54:26<39:43:37, 19.75s/it] 30%|███       | 3126/10365 [18:54:50<41:52:13, 20.82s/it] 30%|███       | 3127/10365 [18:55:13<43:25:25, 21.60s/it] 30%|███       | 3128/10365 [18:55:31<41:12:27, 20.50s/it] 30%|███       | 3129/10365 [18:55:52<41:19:50, 20.56s/it] 30%|███       | 3130/10365 [18:56:13<41:31:21, 20.66s/it]                                                          {'loss': 1.064, 'grad_norm': 0.9921875, 'learning_rate': 7.913821630384833e-05, 'epoch': 0.3}
 30%|███       | 3130/10365 [18:56:13<41:31:21, 20.66s/it] 30%|███       | 3131/10365 [18:56:33<41:09:35, 20.48s/it] 30%|███       | 3132/10365 [18:57:01<45:38:45, 22.72s/it] 30%|███       | 3133/10365 [18:57:20<43:22:16, 21.59s/it] 30%|███       | 3134/10365 [18:57:37<40:39:31, 20.24s/it] 30%|███       | 3135/10365 [18:57:58<41:09:53, 20.50s/it] 30%|███       | 3136/10365 [18:58:16<39:48:41, 19.83s/it] 30%|███       | 3137/10365 [18:58:40<42:26:55, 21.14s/it] 30%|███       | 3138/10365 [18:59:04<43:40:31, 21.76s/it] 30%|███       | 3139/10365 [18:59:26<44:04:22, 21.96s/it] 30%|███       | 3140/10365 [18:59:43<41:18:04, 20.58s/it]                                                          {'loss': 1.048, 'grad_norm': 1.0234375, 'learning_rate': 7.901492720630602e-05, 'epoch': 0.3}
 30%|███       | 3140/10365 [18:59:43<41:18:04, 20.58s/it] 30%|███       | 3141/10365 [19:00:02<40:09:00, 20.01s/it] 30%|███       | 3142/10365 [19:00:18<37:31:12, 18.70s/it] 30%|███       | 3143/10365 [19:00:38<38:13:20, 19.05s/it] 30%|███       | 3144/10365 [19:00:58<39:17:05, 19.59s/it] 30%|███       | 3145/10365 [19:01:17<38:59:36, 19.44s/it] 30%|███       | 3146/10365 [19:01:35<37:42:45, 18.81s/it] 30%|███       | 3147/10365 [19:01:55<38:20:00, 19.12s/it] 30%|███       | 3148/10365 [19:02:13<37:54:36, 18.91s/it] 30%|███       | 3149/10365 [19:02:33<38:43:25, 19.32s/it] 30%|███       | 3150/10365 [19:02:57<41:32:08, 20.72s/it]                                                          {'loss': 1.059, 'grad_norm': 1.0703125, 'learning_rate': 7.889137155141171e-05, 'epoch': 0.3}
 30%|███       | 3150/10365 [19:02:57<41:32:08, 20.72s/it] 30%|███       | 3151/10365 [19:03:14<39:17:59, 19.61s/it] 30%|███       | 3152/10365 [19:03:35<39:57:05, 19.94s/it] 30%|███       | 3153/10365 [19:03:59<42:27:27, 21.19s/it] 30%|███       | 3154/10365 [19:04:19<41:46:55, 20.86s/it] 30%|███       | 3155/10365 [19:04:46<45:04:26, 22.51s/it] 30%|███       | 3156/10365 [19:05:04<42:42:33, 21.33s/it] 30%|███       | 3157/10365 [19:05:19<39:02:13, 19.50s/it] 30%|███       | 3158/10365 [19:05:38<38:45:11, 19.36s/it] 30%|███       | 3159/10365 [19:06:02<41:02:52, 20.51s/it] 30%|███       | 3160/10365 [19:06:21<40:23:31, 20.18s/it]                                                          {'loss': 1.0545, 'grad_norm': 1.0859375, 'learning_rate': 7.876755047425934e-05, 'epoch': 0.3}
 30%|███       | 3160/10365 [19:06:21<40:23:31, 20.18s/it] 30%|███       | 3161/10365 [19:06:43<41:17:47, 20.64s/it] 31%|███       | 3162/10365 [19:07:02<40:32:33, 20.26s/it] 31%|███       | 3163/10365 [19:07:21<39:59:14, 19.99s/it] 31%|███       | 3164/10365 [19:07:44<41:41:18, 20.84s/it] 31%|███       | 3165/10365 [19:08:05<41:34:25, 20.79s/it] 31%|███       | 3166/10365 [19:08:24<40:45:05, 20.38s/it] 31%|███       | 3167/10365 [19:08:44<40:19:13, 20.17s/it] 31%|███       | 3168/10365 [19:09:06<41:04:46, 20.55s/it] 31%|███       | 3169/10365 [19:09:25<40:21:38, 20.19s/it] 31%|███       | 3170/10365 [19:09:43<38:58:34, 19.50s/it]                                                          {'loss': 1.0461, 'grad_norm': 0.87109375, 'learning_rate': 7.86434651123813e-05, 'epoch': 0.31}
 31%|███       | 3170/10365 [19:09:43<38:58:34, 19.50s/it] 31%|███       | 3171/10365 [19:10:09<43:05:47, 21.57s/it] 31%|███       | 3172/10365 [19:10:25<39:56:29, 19.99s/it] 31%|███       | 3173/10365 [19:10:46<40:19:37, 20.19s/it] 31%|███       | 3174/10365 [19:11:11<43:25:19, 21.74s/it] 31%|███       | 3175/10365 [19:11:34<43:45:47, 21.91s/it] 31%|███       | 3176/10365 [19:11:54<42:52:22, 21.47s/it] 31%|███       | 3177/10365 [19:12:16<43:00:16, 21.54s/it] 31%|███       | 3178/10365 [19:12:34<40:58:41, 20.53s/it] 31%|███       | 3179/10365 [19:12:56<42:02:23, 21.06s/it] 31%|███       | 3180/10365 [19:13:19<42:58:15, 21.53s/it]                                                          {'loss': 1.0231, 'grad_norm': 0.9453125, 'learning_rate': 7.851911660573785e-05, 'epoch': 0.31}
 31%|███       | 3180/10365 [19:13:19<42:58:15, 21.53s/it] 31%|███       | 3181/10365 [19:13:39<41:53:53, 21.00s/it] 31%|███       | 3182/10365 [19:14:04<44:28:32, 22.29s/it] 31%|███       | 3183/10365 [19:14:24<42:47:11, 21.45s/it] 31%|███       | 3184/10365 [19:14:53<47:37:05, 23.87s/it] 31%|███       | 3185/10365 [19:15:11<44:05:58, 22.11s/it] 31%|███       | 3186/10365 [19:15:32<43:31:55, 21.83s/it] 31%|███       | 3187/10365 [19:15:54<43:12:34, 21.67s/it] 31%|███       | 3188/10365 [19:16:21<46:39:30, 23.40s/it] 31%|███       | 3189/10365 [19:16:40<43:56:13, 22.04s/it] 31%|███       | 3190/10365 [19:17:00<42:51:45, 21.51s/it]                                                          {'loss': 1.0395, 'grad_norm': 1.0078125, 'learning_rate': 7.839450609670681e-05, 'epoch': 0.31}
 31%|███       | 3190/10365 [19:17:00<42:51:45, 21.51s/it] 31%|███       | 3191/10365 [19:17:19<41:31:26, 20.84s/it] 31%|███       | 3192/10365 [19:17:39<40:49:03, 20.49s/it] 31%|███       | 3193/10365 [19:18:01<41:38:33, 20.90s/it]